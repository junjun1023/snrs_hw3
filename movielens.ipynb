{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "published-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, ndcg_score, recall_score\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "seven-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "\n",
    "from deepctr_torch.inputs import SparseFeat, VarLenSparseFeat, get_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "specific-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import DIN\n",
    "from deepctr_torch.models import AFM\n",
    "from deepctr_torch.models import WDL\n",
    "from deepctr_torch.models import xDeepFM\n",
    "from deepctr_torch.models import DeepFM\n",
    "from deepctr_torch.models import PNN\n",
    "from deepctr_torch.models import DCN\n",
    "from deepctr_torch.models import CCPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "turkish-thickness",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "laden-certificate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda ready...\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "use_cuda = True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    print('cuda ready...')\n",
    "    device = 'cuda:1'\n",
    "\n",
    "root = os.path.join(os.getcwd(), \"Movielens\")\n",
    "rel_p = os.path.join(root, \"user_movie.dat\")\n",
    "\n",
    "user_cnt = 943"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-diesel",
   "metadata": {},
   "source": [
    "### User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "numeric-victory",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "age, age_i, age_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"Movielens\", \"user_age.dat\"), user_cnt=user_cnt)\n",
    "occupation, occupation_i, occupation_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"Movielens\", \"user_occupation.dat\"), user_cnt=user_cnt)\n",
    "# user, user_i, user_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"Movielens\", \"user_user.dat\"), user_cnt=user_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-tomato",
   "metadata": {},
   "source": [
    "### Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "secure-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre, genre_i, genre_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"Movielens\", \"movie_genre.dat\"), user_cnt=1682)\n",
    "# publisher, publisher_i, publisher_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"Movielens\", \"book_publisher.dat\"), user_cnt=user_cnt)\n",
    "# author, author_i, author_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"Movielens\", \"book_author.dat\"), user_cnt=user_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-karma",
   "metadata": {},
   "source": [
    "### Interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "atlantic-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = [\"cols_0\", \"cols_1\"] # user_id, movie_id\n",
    "rating = \"cols_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "color-peninsula",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cols_0</th>\n",
       "      <th>cols_1</th>\n",
       "      <th>cols_2</th>\n",
       "      <th>cols_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cols_0  cols_1  cols_2     cols_3\n",
       "0     196     242       3  881250949\n",
       "1     186     302       3  891717742\n",
       "2      22     377       1  878887116\n",
       "3     244      51       2  880606923\n",
       "4     166     346       1  886397596"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel = utils.read_file(rel_p)\n",
    "rel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "moved-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "_age = age[rel.cols_0 -1]\n",
    "_occupation = occupation[rel.cols_0 -1]\n",
    "# _user = user[rel.cols_0 -1]\n",
    "\n",
    "_genre = genre[rel.cols_1 -1]\n",
    "# _publisher = publisher[rel.cols_1 -1]\n",
    "# _author = author[rel.cols_1 -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "transsexual-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Label Encoding for sparse features,and process sequence features\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    rel[feat] = lbe.fit_transform(rel[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "disciplinary-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, rel[feat].nunique(), embedding_dim=4) for feat in sparse_features]\n",
    "\n",
    "varlen_feature_columns = [\n",
    "    VarLenSparseFeat(SparseFeat('age', vocabulary_size=age_i + 1, embedding_dim=4), maxlen=age_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('occupation', vocabulary_size=occupation_i + 1, embedding_dim=4), maxlen=occupation_m, combiner='mean'),\n",
    "#     VarLenSparseFeat(SparseFeat('user', vocabulary_size=13024 + 1, embedding_dim=4), maxlen=user_m, combiner='mean'),\n",
    "    \n",
    "    VarLenSparseFeat(SparseFeat('genre', vocabulary_size=genre_i + 1, embedding_dim=4), maxlen=genre_m, combiner='mean'),\n",
    "#     VarLenSparseFeat(SparseFeat('publisher', vocabulary_size=publisher_i + 1, embedding_dim=4), maxlen=publisher_m, combiner='mean'),\n",
    "#     VarLenSparseFeat(SparseFeat('author', vocabulary_size=author_i + 1, embedding_dim=4), maxlen=author_m, combiner='mean')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "clean-tuition",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-representation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "proud-registrar",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "consecutive-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepfm_mse = 0\n",
    "ccpm_mse = 0\n",
    "ipnn_mse = 0\n",
    "opnn_mse = 0\n",
    "wdl_mse = 0\n",
    "dcn_mse = 0\n",
    "xdeepfm_mse = 0\n",
    "afm_mse = 0\n",
    "din_mse = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "clear-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepfm_recall = 0\n",
    "ccpm_recall = 0\n",
    "ipnn_recall = 0\n",
    "opnn_recall = 0\n",
    "wdl_recall = 0\n",
    "dcn_recall = 0\n",
    "xdeepfm_recall = 0\n",
    "afm_recall = 0\n",
    "din_recall = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "spare-january",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepfm_ndcg = 0\n",
    "ccpm_ndcg = 0\n",
    "ipnn_ndcg = 0\n",
    "opnn_ndcg = 0\n",
    "wdl_ndcg = 0\n",
    "dcn_ndcg = 0\n",
    "xdeepfm_ndcg = 0\n",
    "afm_ndcg = 0\n",
    "din_ndcg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-strengthening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================== 1 Fold ==============================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Training DeepFM \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "13s - loss:  2.9872 - mse:  2.9840 - val_mse:  2.0168\n",
      "Epoch 2/10\n",
      "13s - loss:  1.9481 - mse:  1.9495 - val_mse:  1.9836\n",
      "Epoch 3/10\n",
      "5s - loss:  1.9152 - mse:  1.9158 - val_mse:  1.9753\n",
      "Epoch 4/10\n",
      "12s - loss:  1.9049 - mse:  1.9044 - val_mse:  1.9740\n",
      "Epoch 5/10\n",
      "13s - loss:  1.8991 - mse:  1.8976 - val_mse:  1.9793\n",
      "Epoch 6/10\n",
      "6s - loss:  1.8964 - mse:  1.8961 - val_mse:  1.9863\n",
      "Epoch 7/10\n",
      "11s - loss:  1.8914 - mse:  1.8909 - val_mse:  1.9761\n",
      "Epoch 8/10\n",
      "13s - loss:  1.8887 - mse:  1.8893 - val_mse:  1.9783\n",
      "Epoch 9/10\n",
      "8s - loss:  1.8883 - mse:  1.8880 - val_mse:  1.9810\n",
      "Epoch 10/10\n",
      "10s - loss:  1.8868 - mse:  1.8857 - val_mse:  1.9797\n",
      "\n",
      "\n",
      " Training CCPM \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "13s - loss:  3.2502 - mse:  3.2482 - val_mse:  2.3387\n",
      "Epoch 2/10\n",
      "6s - loss:  2.0361 - mse:  2.0372 - val_mse:  1.9916\n",
      "Epoch 3/10\n",
      "11s - loss:  1.9040 - mse:  1.9052 - val_mse:  1.9624\n",
      "Epoch 4/10\n",
      "13s - loss:  1.8775 - mse:  1.8784 - val_mse:  1.9515\n",
      "Epoch 5/10\n",
      "7s - loss:  1.8629 - mse:  1.8622 - val_mse:  1.9694\n",
      "Epoch 6/10\n",
      "10s - loss:  1.8552 - mse:  1.8549 - val_mse:  1.9466\n",
      "Epoch 7/10\n",
      "13s - loss:  1.8473 - mse:  1.8479 - val_mse:  1.9445\n",
      "Epoch 8/10\n",
      "10s - loss:  1.8409 - mse:  1.8415 - val_mse:  1.9444\n",
      "Epoch 9/10\n",
      "13s - loss:  1.8384 - mse:  1.8373 - val_mse:  1.9539\n",
      "Epoch 10/10\n",
      "15s - loss:  1.8308 - mse:  1.8315 - val_mse:  1.9372\n",
      "\n",
      "\n",
      " Training IPMM \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "6s - loss:  3.3597 - mse:  3.3552 - val_mse:  2.0338\n",
      "Epoch 2/10\n",
      "8s - loss:  1.9496 - mse:  1.9499 - val_mse:  1.9837\n",
      "Epoch 3/10\n",
      "8s - loss:  1.9097 - mse:  1.9098 - val_mse:  1.9744\n",
      "Epoch 4/10\n",
      "8s - loss:  1.8979 - mse:  1.8967 - val_mse:  1.9765\n",
      "Epoch 5/10\n",
      "7s - loss:  1.8871 - mse:  1.8880 - val_mse:  1.9901\n",
      "Epoch 6/10\n",
      "7s - loss:  1.8775 - mse:  1.8779 - val_mse:  1.9637\n",
      "Epoch 7/10\n",
      "8s - loss:  1.8634 - mse:  1.8650 - val_mse:  1.9526\n",
      "Epoch 8/10\n",
      "8s - loss:  1.8397 - mse:  1.8398 - val_mse:  1.9362\n",
      "Epoch 9/10\n",
      "8s - loss:  1.8111 - mse:  1.8117 - val_mse:  1.9294\n",
      "Epoch 10/10\n",
      "6s - loss:  1.7818 - mse:  1.7811 - val_mse:  1.9320\n",
      "\n",
      "\n",
      " Training OPNN \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "8s - loss:  3.6355 - mse:  3.6299 - val_mse:  2.0347\n",
      "Epoch 2/10\n",
      "8s - loss:  1.9522 - mse:  1.9501 - val_mse:  1.9817\n",
      "Epoch 3/10\n",
      "18s - loss:  1.9104 - mse:  1.9097 - val_mse:  1.9762\n",
      "Epoch 4/10\n",
      "12s - loss:  1.8976 - mse:  1.8957 - val_mse:  1.9707\n",
      "Epoch 5/10\n",
      "17s - loss:  1.8853 - mse:  1.8860 - val_mse:  1.9586\n",
      "Epoch 6/10\n",
      "16s - loss:  1.8703 - mse:  1.8696 - val_mse:  1.9559\n",
      "Epoch 7/10\n",
      "14s - loss:  1.8532 - mse:  1.8540 - val_mse:  1.9478\n",
      "Epoch 8/10\n",
      "15s - loss:  1.8340 - mse:  1.8335 - val_mse:  1.9312\n",
      "Epoch 9/10\n",
      "15s - loss:  1.8139 - mse:  1.8143 - val_mse:  1.9199\n",
      "Epoch 10/10\n",
      "21s - loss:  1.7992 - mse:  1.8008 - val_mse:  1.9212\n",
      "\n",
      "\n",
      " Training Wide&Deep \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "51s - loss:  2.9906 - mse:  2.9873 - val_mse:  2.0162\n",
      "Epoch 2/10\n",
      "50s - loss:  1.9464 - mse:  1.9478 - val_mse:  1.9823\n",
      "Epoch 3/10\n",
      "50s - loss:  1.9130 - mse:  1.9136 - val_mse:  1.9736\n",
      "Epoch 4/10\n",
      "50s - loss:  1.9023 - mse:  1.9019 - val_mse:  1.9716\n",
      "Epoch 5/10\n",
      "42s - loss:  1.8964 - mse:  1.8949 - val_mse:  1.9767\n",
      "Epoch 6/10\n",
      "44s - loss:  1.8936 - mse:  1.8933 - val_mse:  1.9832\n",
      "Epoch 7/10\n",
      "49s - loss:  1.8885 - mse:  1.8880 - val_mse:  1.9737\n",
      "Epoch 8/10\n",
      "49s - loss:  1.8858 - mse:  1.8863 - val_mse:  1.9757\n",
      "Epoch 9/10\n",
      "54s - loss:  1.8853 - mse:  1.8850 - val_mse:  1.9779\n",
      "Epoch 10/10\n",
      "50s - loss:  1.8838 - mse:  1.8826 - val_mse:  1.9769\n",
      "\n",
      "\n",
      " Training DCN \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "40s - loss:  3.1909 - mse:  3.1892 - val_mse:  2.0275\n",
      "Epoch 2/10\n",
      "44s - loss:  1.9480 - mse:  1.9477 - val_mse:  1.9829\n",
      "Epoch 3/10\n",
      "49s - loss:  1.9130 - mse:  1.9137 - val_mse:  1.9748\n",
      "Epoch 4/10\n",
      "47s - loss:  1.8990 - mse:  1.9005 - val_mse:  1.9799\n",
      "Epoch 5/10\n",
      "53s - loss:  1.8942 - mse:  1.8939 - val_mse:  1.9755\n",
      "Epoch 6/10\n",
      "48s - loss:  1.8888 - mse:  1.8886 - val_mse:  1.9757\n",
      "Epoch 7/10\n",
      "42s - loss:  1.8862 - mse:  1.8864 - val_mse:  1.9795\n",
      "Epoch 8/10\n",
      "44s - loss:  1.8838 - mse:  1.8837 - val_mse:  1.9760\n",
      "Epoch 9/10\n",
      "50s - loss:  1.8795 - mse:  1.8816 - val_mse:  1.9897\n",
      "Epoch 10/10\n",
      "50s - loss:  1.8769 - mse:  1.8768 - val_mse:  1.9728\n",
      "\n",
      "\n",
      " Training xDeepFM \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "53s - loss:  2.5648 - mse:  2.5636 - val_mse:  1.9920\n",
      "Epoch 2/10\n",
      "50s - loss:  1.9367 - mse:  1.9360 - val_mse:  1.9681\n",
      "Epoch 3/10\n",
      "39s - loss:  1.9031 - mse:  1.9012 - val_mse:  1.9609\n",
      "Epoch 4/10\n",
      "48s - loss:  1.8889 - mse:  1.8888 - val_mse:  1.9652\n",
      "Epoch 5/10\n",
      "49s - loss:  1.8772 - mse:  1.8776 - val_mse:  1.9749\n",
      "Epoch 6/10\n",
      "50s - loss:  1.8687 - mse:  1.8700 - val_mse:  1.9544\n",
      "Epoch 7/10\n",
      "54s - loss:  1.8596 - mse:  1.8602 - val_mse:  1.9526\n",
      "Epoch 8/10\n",
      "43s - loss:  1.8550 - mse:  1.8532 - val_mse:  1.9674\n",
      "Epoch 9/10\n",
      "41s - loss:  1.8463 - mse:  1.8461 - val_mse:  1.9538\n",
      "Epoch 10/10\n",
      "47s - loss:  1.8366 - mse:  1.8378 - val_mse:  1.9462\n",
      "\n",
      "\n",
      " Training AFM \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "46s - loss:  9.2954 - mse:  9.2866 - val_mse:  5.4304\n",
      "Epoch 2/10\n",
      "50s - loss:  2.9631 - mse:  2.9613 - val_mse:  2.5517\n",
      "Epoch 3/10\n",
      "54s - loss:  2.4537 - mse:  2.4544 - val_mse:  2.4635\n",
      "Epoch 4/10\n",
      "47s - loss:  2.3645 - mse:  2.3636 - val_mse:  2.3871\n",
      "Epoch 5/10\n",
      "38s - loss:  2.2840 - mse:  2.2845 - val_mse:  2.3151\n",
      "Epoch 6/10\n",
      "25s - loss:  2.2011 - mse:  2.2014 - val_mse:  2.2262\n",
      "Epoch 7/10\n",
      "28s - loss:  2.0861 - mse:  2.0861 - val_mse:  2.0991\n",
      "Epoch 8/10\n",
      "31s - loss:  1.9822 - mse:  1.9824 - val_mse:  2.0432\n",
      "Epoch 9/10\n",
      "26s - loss:  1.9346 - mse:  1.9354 - val_mse:  2.0178\n",
      "Epoch 10/10\n",
      "32s - loss:  1.9106 - mse:  1.9103 - val_mse:  2.0110\n",
      "========================== 2 Fold ==============================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Training DeepFM \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "26s - loss:  2.9968 - mse:  2.9945 - val_mse:  2.0228\n",
      "Epoch 2/10\n",
      "22s - loss:  1.9514 - mse:  1.9519 - val_mse:  1.9891\n",
      "Epoch 3/10\n",
      "19s - loss:  1.9188 - mse:  1.9183 - val_mse:  1.9818\n",
      "Epoch 4/10\n",
      "31s - loss:  1.9067 - mse:  1.9064 - val_mse:  1.9832\n",
      "Epoch 5/10\n",
      "24s - loss:  1.9011 - mse:  1.8996 - val_mse:  1.9930\n",
      "Epoch 6/10\n",
      "15s - loss:  1.8977 - mse:  1.8969 - val_mse:  1.9929\n",
      "Epoch 7/10\n",
      "15s - loss:  1.8934 - mse:  1.8932 - val_mse:  1.9874\n",
      "Epoch 8/10\n",
      "15s - loss:  1.8920 - mse:  1.8929 - val_mse:  1.9874\n",
      "Epoch 9/10\n",
      "15s - loss:  1.8925 - mse:  1.8920 - val_mse:  1.9974\n",
      "Epoch 10/10\n",
      "22s - loss:  1.8878 - mse:  1.8865 - val_mse:  1.9919\n",
      "\n",
      "\n",
      " Training CCPM \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "20s - loss:  3.2599 - mse:  3.2606 - val_mse:  2.3234\n",
      "Epoch 2/10\n",
      "21s - loss:  2.0260 - mse:  2.0268 - val_mse:  1.9855\n",
      "Epoch 3/10\n",
      "29s - loss:  1.9040 - mse:  1.9049 - val_mse:  1.9681\n",
      "Epoch 4/10\n",
      "29s - loss:  1.8770 - mse:  1.8770 - val_mse:  1.9595\n",
      "Epoch 5/10\n",
      "29s - loss:  1.8626 - mse:  1.8620 - val_mse:  1.9747\n",
      "Epoch 6/10\n",
      "31s - loss:  1.8542 - mse:  1.8542 - val_mse:  1.9551\n",
      "Epoch 7/10\n",
      "53s - loss:  1.8469 - mse:  1.8486 - val_mse:  1.9622\n",
      "Epoch 8/10\n",
      "39s - loss:  1.8401 - mse:  1.8418 - val_mse:  1.9556\n",
      "Epoch 9/10\n",
      "39s - loss:  1.8321 - mse:  1.8325 - val_mse:  1.9646\n",
      "Epoch 10/10\n",
      "53s - loss:  1.8223 - mse:  1.8231 - val_mse:  1.9476\n",
      "\n",
      "\n",
      " Training IPMM \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "25s - loss:  3.3598 - mse:  3.3551 - val_mse:  2.0283\n",
      "Epoch 2/10\n",
      "28s - loss:  1.9530 - mse:  1.9523 - val_mse:  1.9862\n",
      "Epoch 3/10\n",
      "28s - loss:  1.9132 - mse:  1.9131 - val_mse:  1.9908\n",
      "Epoch 4/10\n",
      "26s - loss:  1.9001 - mse:  1.8991 - val_mse:  1.9836\n",
      "Epoch 5/10\n",
      "28s - loss:  1.8896 - mse:  1.8903 - val_mse:  1.9851\n",
      "Epoch 6/10\n",
      "26s - loss:  1.8803 - mse:  1.8804 - val_mse:  1.9752\n",
      "Epoch 7/10\n",
      "22s - loss:  1.8649 - mse:  1.8661 - val_mse:  1.9650\n",
      "Epoch 8/10\n",
      "23s - loss:  1.8420 - mse:  1.8419 - val_mse:  1.9515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "21s - loss:  1.8142 - mse:  1.8157 - val_mse:  1.9370\n",
      "Epoch 10/10\n",
      "26s - loss:  1.7827 - mse:  1.7823 - val_mse:  1.9332\n",
      "\n",
      "\n",
      " Training OPNN \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "28s - loss:  3.6433 - mse:  3.6388 - val_mse:  2.0420\n",
      "Epoch 2/10\n",
      "23s - loss:  1.9561 - mse:  1.9570 - val_mse:  1.9933\n",
      "Epoch 3/10\n",
      "30s - loss:  1.9135 - mse:  1.9119 - val_mse:  1.9841\n",
      "Epoch 4/10\n",
      "27s - loss:  1.9012 - mse:  1.9006 - val_mse:  1.9799\n",
      "Epoch 5/10\n",
      "25s - loss:  1.8874 - mse:  1.8879 - val_mse:  1.9679\n",
      "Epoch 6/10\n",
      "29s - loss:  1.8733 - mse:  1.8731 - val_mse:  1.9663\n",
      "Epoch 7/10\n",
      "27s - loss:  1.8548 - mse:  1.8542 - val_mse:  1.9532\n",
      "Epoch 8/10\n",
      "23s - loss:  1.8321 - mse:  1.8319 - val_mse:  1.9450\n",
      "Epoch 9/10\n",
      "22s - loss:  1.8124 - mse:  1.8115 - val_mse:  1.9334\n",
      "Epoch 10/10\n",
      "21s - loss:  1.7986 - mse:  1.7998 - val_mse:  1.9401\n",
      "\n",
      "\n",
      " Training Wide&Deep \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "46s - loss:  3.0004 - mse:  2.9981 - val_mse:  2.0221\n",
      "Epoch 2/10\n",
      "49s - loss:  1.9496 - mse:  1.9501 - val_mse:  1.9874\n",
      "Epoch 3/10\n",
      "51s - loss:  1.9166 - mse:  1.9161 - val_mse:  1.9798\n",
      "Epoch 4/10\n",
      "49s - loss:  1.9042 - mse:  1.9039 - val_mse:  1.9808\n",
      "Epoch 5/10\n",
      "44s - loss:  1.8985 - mse:  1.8970 - val_mse:  1.9903\n",
      "Epoch 6/10\n",
      "42s - loss:  1.8949 - mse:  1.8941 - val_mse:  1.9900\n",
      "Epoch 7/10\n",
      "45s - loss:  1.8906 - mse:  1.8904 - val_mse:  1.9845\n",
      "Epoch 8/10\n",
      "50s - loss:  1.8891 - mse:  1.8900 - val_mse:  1.9846\n",
      "Epoch 9/10\n",
      "51s - loss:  1.8896 - mse:  1.8890 - val_mse:  1.9942\n",
      "Epoch 10/10\n",
      "50s - loss:  1.8850 - mse:  1.8837 - val_mse:  1.9891\n",
      "\n",
      "\n",
      " Training DCN \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "46s - loss:  3.1960 - mse:  3.1939 - val_mse:  2.0270\n",
      "Epoch 2/10\n",
      "41s - loss:  1.9510 - mse:  1.9520 - val_mse:  1.9839\n",
      "Epoch 3/10\n",
      "48s - loss:  1.9155 - mse:  1.9170 - val_mse:  1.9808\n",
      "Epoch 4/10\n",
      "49s - loss:  1.9029 - mse:  1.9041 - val_mse:  1.9989\n",
      "Epoch 5/10\n",
      "52s - loss:  1.8975 - mse:  1.8975 - val_mse:  1.9991\n",
      "Epoch 6/10\n",
      "47s - loss:  1.8918 - mse:  1.8927 - val_mse:  1.9865\n",
      "Epoch 7/10\n",
      "48s - loss:  1.8889 - mse:  1.8882 - val_mse:  1.9938\n",
      "Epoch 8/10\n",
      "43s - loss:  1.8861 - mse:  1.8866 - val_mse:  1.9889\n",
      "Epoch 9/10\n",
      "45s - loss:  1.8832 - mse:  1.8850 - val_mse:  1.9836\n",
      "Epoch 10/10\n",
      "32s - loss:  1.8783 - mse:  1.8779 - val_mse:  1.9821\n",
      "\n",
      "\n",
      " Training xDeepFM \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "29s - loss:  2.5756 - mse:  2.5753 - val_mse:  2.0059\n",
      "Epoch 2/10\n",
      "29s - loss:  1.9388 - mse:  1.9379 - val_mse:  1.9776\n",
      "Epoch 3/10\n",
      "31s - loss:  1.9051 - mse:  1.9038 - val_mse:  1.9741\n",
      "Epoch 4/10\n",
      "25s - loss:  1.8895 - mse:  1.8890 - val_mse:  1.9708\n",
      "Epoch 5/10\n",
      "21s - loss:  1.8786 - mse:  1.8783 - val_mse:  2.0020\n",
      "Epoch 6/10\n",
      "25s - loss:  1.8688 - mse:  1.8697 - val_mse:  1.9647\n",
      "Epoch 7/10\n",
      "32s - loss:  1.8602 - mse:  1.8601 - val_mse:  1.9636\n",
      "Epoch 8/10\n",
      "27s - loss:  1.8532 - mse:  1.8512 - val_mse:  1.9660\n",
      "Epoch 9/10\n",
      "32s - loss:  1.8469 - mse:  1.8466 - val_mse:  1.9807\n",
      "Epoch 10/10\n",
      "26s - loss:  1.8357 - mse:  1.8368 - val_mse:  1.9585\n",
      "\n",
      "\n",
      " Training AFM \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "29s - loss:  9.3102 - mse:  9.3015 - val_mse:  5.4984\n",
      "Epoch 2/10\n",
      "19s - loss:  3.0119 - mse:  3.0099 - val_mse:  2.5538\n",
      "Epoch 3/10\n",
      "22s - loss:  2.4682 - mse:  2.4670 - val_mse:  2.4683\n",
      "Epoch 4/10\n",
      "26s - loss:  2.3718 - mse:  2.3716 - val_mse:  2.3756\n",
      "Epoch 5/10\n",
      "32s - loss:  2.2504 - mse:  2.2511 - val_mse:  2.2454\n",
      "Epoch 6/10\n",
      "26s - loss:  2.1197 - mse:  2.1197 - val_mse:  2.1365\n",
      "Epoch 7/10\n",
      "33s - loss:  2.0259 - mse:  2.0260 - val_mse:  2.0827\n",
      "Epoch 8/10\n",
      "25s - loss:  1.9712 - mse:  1.9718 - val_mse:  2.0579\n",
      "Epoch 9/10\n",
      "28s - loss:  1.9373 - mse:  1.9368 - val_mse:  2.0392\n",
      "Epoch 10/10\n",
      "20s - loss:  1.9128 - mse:  1.9137 - val_mse:  2.0334\n",
      "========================== 3 Fold ==============================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Training DeepFM \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "28s - loss:  3.0071 - mse:  3.0043 - val_mse:  2.0324\n",
      "Epoch 2/10\n",
      "25s - loss:  1.9497 - mse:  1.9502 - val_mse:  1.9977\n",
      "Epoch 3/10\n",
      "33s - loss:  1.9170 - mse:  1.9172 - val_mse:  1.9894\n",
      "Epoch 4/10\n",
      "24s - loss:  1.9062 - mse:  1.9072 - val_mse:  1.9947\n",
      "Epoch 5/10\n",
      "31s - loss:  1.8997 - mse:  1.8988 - val_mse:  1.9961\n",
      "Epoch 6/10\n",
      "26s - loss:  1.8967 - mse:  1.8968 - val_mse:  2.0020\n",
      "Epoch 7/10\n",
      "23s - loss:  1.8928 - mse:  1.8922 - val_mse:  1.9935\n",
      "Epoch 8/10\n",
      "20s - loss:  1.8929 - mse:  1.8941 - val_mse:  1.9965\n",
      "Epoch 9/10\n",
      "31s - loss:  1.8898 - mse:  1.8892 - val_mse:  2.0100\n",
      "Epoch 10/10\n",
      "25s - loss:  1.8869 - mse:  1.8853 - val_mse:  1.9999\n",
      "\n",
      "\n",
      " Training CCPM \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "30s - loss:  3.2660 - mse:  3.2669 - val_mse:  2.3243\n",
      "Epoch 2/10\n",
      "27s - loss:  2.0285 - mse:  2.0310 - val_mse:  2.0002\n",
      "Epoch 3/10\n",
      "30s - loss:  1.9046 - mse:  1.9037 - val_mse:  1.9741\n",
      "Epoch 4/10\n",
      "25s - loss:  1.8750 - mse:  1.8759 - val_mse:  1.9657\n",
      "Epoch 5/10\n",
      "21s - loss:  1.8596 - mse:  1.8593 - val_mse:  1.9950\n",
      "Epoch 6/10\n",
      "20s - loss:  1.8510 - mse:  1.8510 - val_mse:  1.9622\n",
      "Epoch 7/10\n",
      "34s - loss:  1.8420 - mse:  1.8428 - val_mse:  1.9612\n",
      "Epoch 8/10\n",
      "25s - loss:  1.8368 - mse:  1.8376 - val_mse:  1.9654\n",
      "Epoch 9/10\n",
      "31s - loss:  1.8257 - mse:  1.8265 - val_mse:  1.9635\n",
      "Epoch 10/10\n",
      "27s - loss:  1.8152 - mse:  1.8150 - val_mse:  1.9613\n",
      "\n",
      "\n",
      " Training IPMM \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "18s - loss:  3.3501 - mse:  3.3462 - val_mse:  2.0373\n",
      "Epoch 2/10\n",
      "12s - loss:  1.9516 - mse:  1.9511 - val_mse:  1.9975\n",
      "Epoch 3/10\n",
      "14s - loss:  1.9123 - mse:  1.9122 - val_mse:  1.9948\n",
      "Epoch 4/10\n",
      "13s - loss:  1.8998 - mse:  1.8993 - val_mse:  1.9916\n",
      "Epoch 5/10\n",
      "13s - loss:  1.8890 - mse:  1.8902 - val_mse:  1.9848\n",
      "Epoch 6/10\n",
      "11s - loss:  1.8775 - mse:  1.8763 - val_mse:  1.9810\n",
      "Epoch 7/10\n",
      "16s - loss:  1.8619 - mse:  1.8631 - val_mse:  1.9682\n",
      "Epoch 8/10\n",
      "19s - loss:  1.8354 - mse:  1.8356 - val_mse:  1.9555\n",
      "Epoch 9/10\n",
      "14s - loss:  1.8022 - mse:  1.8047 - val_mse:  1.9490\n",
      "Epoch 10/10\n",
      "19s - loss:  1.7676 - mse:  1.7688 - val_mse:  1.9543\n",
      "\n",
      "\n",
      " Training OPNN \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "19s - loss:  3.6739 - mse:  3.6692 - val_mse:  2.0513\n",
      "Epoch 2/10\n",
      "14s - loss:  1.9554 - mse:  1.9568 - val_mse:  2.0001\n",
      "Epoch 3/10\n",
      "19s - loss:  1.9134 - mse:  1.9128 - val_mse:  1.9902\n",
      "Epoch 4/10\n",
      "19s - loss:  1.8984 - mse:  1.8981 - val_mse:  1.9922\n",
      "Epoch 5/10\n",
      "14s - loss:  1.8843 - mse:  1.8837 - val_mse:  1.9751\n",
      "Epoch 6/10\n",
      "17s - loss:  1.8697 - mse:  1.8699 - val_mse:  1.9742\n",
      "Epoch 7/10\n",
      "14s - loss:  1.8522 - mse:  1.8517 - val_mse:  1.9579\n",
      "Epoch 8/10\n",
      "13s - loss:  1.8294 - mse:  1.8283 - val_mse:  1.9532\n",
      "Epoch 9/10\n",
      "12s - loss:  1.8117 - mse:  1.8102 - val_mse:  1.9416\n",
      "Epoch 10/10\n",
      "20s - loss:  1.7986 - mse:  1.8001 - val_mse:  1.9426\n",
      "\n",
      "\n",
      " Training Wide&Deep \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "25s - loss:  3.0115 - mse:  3.0088 - val_mse:  2.0313\n",
      "Epoch 2/10\n",
      "15s - loss:  1.9479 - mse:  1.9483 - val_mse:  1.9958\n",
      "Epoch 3/10\n",
      "13s - loss:  1.9147 - mse:  1.9150 - val_mse:  1.9875\n",
      "Epoch 4/10\n",
      "14s - loss:  1.9036 - mse:  1.9046 - val_mse:  1.9920\n",
      "Epoch 5/10\n",
      "15s - loss:  1.8969 - mse:  1.8960 - val_mse:  1.9934\n",
      "Epoch 6/10\n",
      "15s - loss:  1.8938 - mse:  1.8939 - val_mse:  1.9988\n",
      "Epoch 7/10\n",
      "12s - loss:  1.8897 - mse:  1.8891 - val_mse:  1.9908\n",
      "Epoch 8/10\n",
      "9s - loss:  1.8898 - mse:  1.8909 - val_mse:  1.9938\n",
      "Epoch 9/10\n",
      "9s - loss:  1.8867 - mse:  1.8860 - val_mse:  2.0069\n",
      "Epoch 10/10\n",
      "11s - loss:  1.8836 - mse:  1.8821 - val_mse:  1.9969\n",
      "\n",
      "\n",
      " Training DCN \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "15s - loss:  3.2085 - mse:  3.2076 - val_mse:  2.0382\n",
      "Epoch 2/10\n",
      "15s - loss:  1.9510 - mse:  1.9519 - val_mse:  1.9984\n",
      "Epoch 3/10\n",
      "15s - loss:  1.9140 - mse:  1.9151 - val_mse:  1.9896\n",
      "Epoch 4/10\n",
      "15s - loss:  1.9019 - mse:  1.9042 - val_mse:  2.0181\n",
      "Epoch 5/10\n",
      "15s - loss:  1.8970 - mse:  1.8967 - val_mse:  1.9992\n",
      "Epoch 6/10\n",
      "15s - loss:  1.8914 - mse:  1.8912 - val_mse:  1.9968\n",
      "Epoch 7/10\n",
      "14s - loss:  1.8890 - mse:  1.8884 - val_mse:  2.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "9s - loss:  1.8858 - mse:  1.8864 - val_mse:  1.9917\n",
      "Epoch 9/10\n",
      "9s - loss:  1.8820 - mse:  1.8837 - val_mse:  1.9905\n",
      "Epoch 10/10\n",
      "9s - loss:  1.8763 - mse:  1.8757 - val_mse:  1.9873\n",
      "\n",
      "\n",
      " Training xDeepFM \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "15s - loss:  2.5725 - mse:  2.5703 - val_mse:  2.0129\n",
      "Epoch 2/10\n",
      "16s - loss:  1.9369 - mse:  1.9361 - val_mse:  1.9843\n",
      "Epoch 3/10\n",
      "15s - loss:  1.9036 - mse:  1.9032 - val_mse:  1.9817\n",
      "Epoch 4/10\n",
      "15s - loss:  1.8879 - mse:  1.8876 - val_mse:  1.9862\n",
      "Epoch 5/10\n",
      "15s - loss:  1.8808 - mse:  1.8812 - val_mse:  2.0140\n",
      "Epoch 6/10\n",
      "16s - loss:  1.8674 - mse:  1.8698 - val_mse:  1.9684\n",
      "Epoch 7/10\n",
      "15s - loss:  1.8611 - mse:  1.8632 - val_mse:  1.9731\n",
      "Epoch 8/10\n",
      "11s - loss:  1.8535 - mse:  1.8516 - val_mse:  1.9745\n",
      "Epoch 9/10\n",
      "10s - loss:  1.8500 - mse:  1.8487 - val_mse:  1.9816\n",
      "Epoch 10/10\n",
      "10s - loss:  1.8397 - mse:  1.8397 - val_mse:  1.9902\n",
      "\n",
      "\n",
      " Training AFM \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "14s - loss:  9.3072 - mse:  9.2982 - val_mse:  5.2835\n",
      "Epoch 2/10\n",
      "15s - loss:  2.9891 - mse:  2.9869 - val_mse:  2.5583\n",
      "Epoch 3/10\n",
      "15s - loss:  2.4587 - mse:  2.4564 - val_mse:  2.4651\n",
      "Epoch 4/10\n",
      "15s - loss:  2.3597 - mse:  2.3595 - val_mse:  2.3733\n",
      "Epoch 5/10\n",
      "14s - loss:  2.2293 - mse:  2.2289 - val_mse:  2.1991\n",
      "Epoch 6/10\n",
      "15s - loss:  2.0463 - mse:  2.0469 - val_mse:  2.0783\n",
      "Epoch 7/10\n",
      "15s - loss:  1.9654 - mse:  1.9653 - val_mse:  2.0486\n",
      "Epoch 8/10\n",
      "14s - loss:  1.9322 - mse:  1.9315 - val_mse:  2.0381\n",
      "Epoch 9/10\n",
      "9s - loss:  1.9125 - mse:  1.9115 - val_mse:  2.0296\n",
      "Epoch 10/10\n",
      "9s - loss:  1.8962 - mse:  1.8965 - val_mse:  2.0304\n",
      "========================== 4 Fold ==============================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Training DeepFM \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "11s - loss:  2.9961 - mse:  2.9951 - val_mse:  2.0316\n",
      "Epoch 2/10\n",
      "15s - loss:  1.9408 - mse:  1.9401 - val_mse:  2.0031\n",
      "Epoch 3/10\n",
      "15s - loss:  1.9081 - mse:  1.9082 - val_mse:  1.9835\n",
      "Epoch 4/10\n",
      "15s - loss:  1.8962 - mse:  1.8968 - val_mse:  1.9841\n",
      "Epoch 5/10\n",
      "14s - loss:  1.8898 - mse:  1.8895 - val_mse:  1.9899\n",
      "Epoch 6/10\n",
      "14s - loss:  1.8857 - mse:  1.8854 - val_mse:  1.9920\n",
      "Epoch 7/10\n",
      "15s - loss:  1.8835 - mse:  1.8828 - val_mse:  1.9926\n",
      "Epoch 8/10\n",
      "14s - loss:  1.8843 - mse:  1.8849 - val_mse:  1.9871\n",
      "Epoch 9/10\n",
      "11s - loss:  1.8787 - mse:  1.8777 - val_mse:  1.9911\n",
      "Epoch 10/10\n",
      "9s - loss:  1.8772 - mse:  1.8778 - val_mse:  1.9904\n",
      "\n",
      "\n",
      " Training CCPM \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "9s - loss:  3.2516 - mse:  3.2538 - val_mse:  2.3346\n",
      "Epoch 2/10\n",
      "14s - loss:  2.0235 - mse:  2.0262 - val_mse:  2.0004\n",
      "Epoch 3/10\n",
      "15s - loss:  1.8976 - mse:  1.8958 - val_mse:  1.9682\n",
      "Epoch 4/10\n",
      "15s - loss:  1.8701 - mse:  1.8713 - val_mse:  1.9693\n",
      "Epoch 5/10\n",
      "14s - loss:  1.8539 - mse:  1.8541 - val_mse:  1.9695\n",
      "Epoch 6/10\n",
      "15s - loss:  1.8461 - mse:  1.8472 - val_mse:  1.9620\n",
      "Epoch 7/10\n",
      "15s - loss:  1.8345 - mse:  1.8335 - val_mse:  1.9653\n",
      "Epoch 8/10\n",
      "15s - loss:  1.8273 - mse:  1.8278 - val_mse:  1.9623\n",
      "Epoch 9/10\n",
      "14s - loss:  1.8166 - mse:  1.8171 - val_mse:  1.9565\n",
      "Epoch 10/10\n",
      "9s - loss:  1.8044 - mse:  1.8048 - val_mse:  1.9548\n",
      "\n",
      "\n",
      " Training IPMM \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "6s - loss:  3.3506 - mse:  3.3481 - val_mse:  2.0287\n",
      "Epoch 2/10\n",
      "6s - loss:  1.9440 - mse:  1.9445 - val_mse:  1.9920\n",
      "Epoch 3/10\n",
      "7s - loss:  1.9050 - mse:  1.9054 - val_mse:  1.9863\n",
      "Epoch 4/10\n",
      "8s - loss:  1.8912 - mse:  1.8909 - val_mse:  1.9910\n",
      "Epoch 5/10\n",
      "8s - loss:  1.8823 - mse:  1.8823 - val_mse:  1.9796\n",
      "Epoch 6/10\n",
      "8s - loss:  1.8728 - mse:  1.8720 - val_mse:  1.9741\n",
      "Epoch 7/10\n",
      "8s - loss:  1.8612 - mse:  1.8612 - val_mse:  1.9659\n",
      "Epoch 8/10\n",
      "8s - loss:  1.8407 - mse:  1.8406 - val_mse:  1.9608\n",
      "Epoch 9/10\n",
      "8s - loss:  1.8123 - mse:  1.8129 - val_mse:  1.9542\n",
      "Epoch 10/10\n",
      "8s - loss:  1.7798 - mse:  1.7795 - val_mse:  1.9467\n",
      "\n",
      "\n",
      " Training OPNN \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "8s - loss:  3.6770 - mse:  3.6730 - val_mse:  2.0559\n",
      "Epoch 2/10\n",
      "8s - loss:  1.9474 - mse:  1.9505 - val_mse:  1.9951\n",
      "Epoch 3/10\n",
      "8s - loss:  1.9043 - mse:  1.9035 - val_mse:  1.9813\n",
      "Epoch 4/10\n",
      "8s - loss:  1.8893 - mse:  1.8884 - val_mse:  1.9877\n",
      "Epoch 5/10\n",
      "8s - loss:  1.8781 - mse:  1.8772 - val_mse:  1.9689\n",
      "Epoch 6/10\n",
      "8s - loss:  1.8622 - mse:  1.8623 - val_mse:  1.9630\n",
      "Epoch 7/10\n",
      "6s - loss:  1.8466 - mse:  1.8460 - val_mse:  1.9573\n",
      "Epoch 8/10\n",
      "6s - loss:  1.8221 - mse:  1.8212 - val_mse:  1.9451\n",
      "Epoch 9/10\n",
      "6s - loss:  1.8043 - mse:  1.8028 - val_mse:  1.9345\n",
      "Epoch 10/10\n",
      "6s - loss:  1.7899 - mse:  1.7910 - val_mse:  1.9346\n",
      "\n",
      "\n",
      " Training Wide&Deep \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "11s - loss:  3.0012 - mse:  3.0002 - val_mse:  2.0314\n",
      "Epoch 2/10\n",
      "15s - loss:  1.9391 - mse:  1.9384 - val_mse:  2.0007\n",
      "Epoch 3/10\n",
      "15s - loss:  1.9061 - mse:  1.9061 - val_mse:  1.9824\n",
      "Epoch 4/10\n",
      "15s - loss:  1.8939 - mse:  1.8944 - val_mse:  1.9817\n",
      "Epoch 5/10\n",
      "15s - loss:  1.8872 - mse:  1.8869 - val_mse:  1.9868\n",
      "Epoch 6/10\n",
      "15s - loss:  1.8830 - mse:  1.8827 - val_mse:  1.9890\n",
      "Epoch 7/10\n",
      "14s - loss:  1.8806 - mse:  1.8799 - val_mse:  1.9898\n",
      "Epoch 8/10\n",
      "15s - loss:  1.8814 - mse:  1.8820 - val_mse:  1.9839\n",
      "Epoch 9/10\n",
      "10s - loss:  1.8758 - mse:  1.8748 - val_mse:  1.9875\n",
      "Epoch 10/10\n",
      "9s - loss:  1.8743 - mse:  1.8748 - val_mse:  1.9876\n",
      "\n",
      "\n",
      " Training DCN \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "9s - loss:  3.1931 - mse:  3.1898 - val_mse:  2.0410\n",
      "Epoch 2/10\n",
      "15s - loss:  1.9425 - mse:  1.9426 - val_mse:  1.9863\n",
      "Epoch 3/10\n",
      "15s - loss:  1.9050 - mse:  1.9057 - val_mse:  1.9805\n",
      "Epoch 4/10\n",
      "15s - loss:  1.8929 - mse:  1.8946 - val_mse:  2.0015\n",
      "Epoch 5/10\n",
      "15s - loss:  1.8869 - mse:  1.8867 - val_mse:  2.0020\n",
      "Epoch 6/10\n",
      "15s - loss:  1.8816 - mse:  1.8820 - val_mse:  1.9886\n",
      "Epoch 7/10\n",
      "15s - loss:  1.8786 - mse:  1.8784 - val_mse:  1.9860\n",
      "Epoch 8/10\n",
      "15s - loss:  1.8752 - mse:  1.8754 - val_mse:  1.9854\n",
      "Epoch 9/10\n",
      "11s - loss:  1.8733 - mse:  1.8748 - val_mse:  1.9857\n",
      "Epoch 10/10\n",
      "9s - loss:  1.8673 - mse:  1.8675 - val_mse:  1.9845\n",
      "\n",
      "\n",
      " Training xDeepFM \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "9s - loss:  2.5670 - mse:  2.5647 - val_mse:  2.0069\n",
      "Epoch 2/10\n",
      "9s - loss:  1.9287 - mse:  1.9285 - val_mse:  1.9829\n",
      "Epoch 3/10\n",
      "16s - loss:  1.8973 - mse:  1.8974 - val_mse:  1.9812\n",
      "Epoch 4/10\n",
      "15s - loss:  1.8804 - mse:  1.8802 - val_mse:  1.9875\n",
      "Epoch 5/10\n",
      "14s - loss:  1.8705 - mse:  1.8710 - val_mse:  1.9732\n",
      "Epoch 6/10\n",
      "15s - loss:  1.8592 - mse:  1.8607 - val_mse:  1.9702\n",
      "Epoch 7/10\n",
      "15s - loss:  1.8519 - mse:  1.8530 - val_mse:  1.9658\n",
      "Epoch 8/10\n",
      "15s - loss:  1.8429 - mse:  1.8418 - val_mse:  1.9685\n",
      "Epoch 9/10\n",
      "14s - loss:  1.8364 - mse:  1.8346 - val_mse:  1.9918\n",
      "Epoch 10/10\n",
      "12s - loss:  1.8274 - mse:  1.8276 - val_mse:  1.9976\n",
      "\n",
      "\n",
      " Training AFM \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "9s - loss:  9.3251 - mse:  9.3160 - val_mse:  5.3698\n",
      "Epoch 2/10\n",
      "9s - loss:  3.0043 - mse:  3.0036 - val_mse:  2.5667\n",
      "Epoch 3/10\n",
      "12s - loss:  2.4601 - mse:  2.4573 - val_mse:  2.4778\n",
      "Epoch 4/10\n",
      "15s - loss:  2.3635 - mse:  2.3628 - val_mse:  2.3991\n",
      "Epoch 5/10\n",
      "15s - loss:  2.2782 - mse:  2.2780 - val_mse:  2.3242\n",
      "Epoch 6/10\n",
      "15s - loss:  2.1956 - mse:  2.1967 - val_mse:  2.2432\n",
      "Epoch 7/10\n",
      "15s - loss:  2.0959 - mse:  2.0943 - val_mse:  2.1299\n",
      "Epoch 8/10\n",
      "15s - loss:  1.9822 - mse:  1.9821 - val_mse:  2.0556\n",
      "Epoch 9/10\n",
      "15s - loss:  1.9290 - mse:  1.9279 - val_mse:  2.0355\n",
      "Epoch 10/10\n",
      "15s - loss:  1.9019 - mse:  1.9032 - val_mse:  2.0235\n",
      "========================== 5 Fold ==============================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Training DeepFM \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "9s - loss:  3.0028 - mse:  3.0025 - val_mse:  2.0416\n",
      "Epoch 2/10\n",
      "8s - loss:  1.9408 - mse:  1.9404 - val_mse:  2.0146\n",
      "Epoch 3/10\n",
      "8s - loss:  1.9087 - mse:  1.9086 - val_mse:  2.0081\n",
      "Epoch 4/10\n",
      "15s - loss:  1.8969 - mse:  1.8971 - val_mse:  2.0046\n",
      "Epoch 5/10\n",
      "14s - loss:  1.8904 - mse:  1.8904 - val_mse:  2.0130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "15s - loss:  1.8885 - mse:  1.8882 - val_mse:  2.0082\n",
      "Epoch 7/10\n",
      "15s - loss:  1.8850 - mse:  1.8843 - val_mse:  2.0085\n",
      "Epoch 8/10\n",
      "15s - loss:  1.8845 - mse:  1.8858 - val_mse:  2.0021\n",
      "Epoch 9/10\n",
      "15s - loss:  1.8811 - mse:  1.8804 - val_mse:  2.0101\n",
      "Epoch 10/10\n",
      "15s - loss:  1.8771 - mse:  1.8768 - val_mse:  2.0106\n",
      "\n",
      "\n",
      " Training CCPM \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "12s - loss:  3.2446 - mse:  3.2464 - val_mse:  2.3378\n",
      "Epoch 2/10\n",
      "9s - loss:  2.0243 - mse:  2.0276 - val_mse:  2.0157\n",
      "Epoch 3/10\n",
      "9s - loss:  1.9000 - mse:  1.8976 - val_mse:  1.9861\n",
      "Epoch 4/10\n",
      "13s - loss:  1.8736 - mse:  1.8744 - val_mse:  1.9933\n",
      "Epoch 5/10\n",
      "15s - loss:  1.8574 - mse:  1.8570 - val_mse:  1.9810\n",
      "Epoch 6/10\n",
      "15s - loss:  1.8492 - mse:  1.8509 - val_mse:  1.9809\n",
      "Epoch 7/10\n",
      "14s - loss:  1.8402 - mse:  1.8386 - val_mse:  1.9841\n",
      "Epoch 8/10\n",
      "14s - loss:  1.8335 - mse:  1.8333 - val_mse:  1.9779\n",
      "Epoch 9/10\n",
      "13s - loss:  1.8253 - mse:  1.8259 - val_mse:  1.9748\n",
      "Epoch 10/10\n",
      "15s - loss:  1.8143 - mse:  1.8153 - val_mse:  1.9710\n",
      "\n",
      "\n",
      " Training IPMM \n",
      "\n",
      "cuda:1\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/10\n",
      "8s - loss:  3.3320 - mse:  3.3299 - val_mse:  2.0491\n",
      "Epoch 2/10\n",
      "7s - loss:  1.9436 - mse:  1.9448 - val_mse:  2.0140\n",
      "Epoch 3/10\n",
      "6s - loss:  1.9059 - mse:  1.9059 - val_mse:  1.9996\n",
      "Epoch 4/10\n",
      "6s - loss:  1.8922 - mse:  1.8918 - val_mse:  1.9999\n",
      "Epoch 5/10\n",
      "6s - loss:  1.8837 - mse:  1.8832 - val_mse:  1.9996\n",
      "Epoch 6/10\n",
      "6s - loss:  1.8750 - mse:  1.8738 - val_mse:  1.9919\n",
      "Epoch 7/10\n",
      "9s - loss:  1.8641 - mse:  1.8644 - val_mse:  1.9807\n",
      "Epoch 8/10\n",
      "9s - loss:  1.8453 - mse:  1.8450 - val_mse:  1.9651\n"
     ]
    }
   ],
   "source": [
    "fold_cnt = 0\n",
    "\n",
    "for train_index, test_index in kf.split(rel):\n",
    "    \n",
    "    fold_cnt += 1\n",
    "    print(\"========================== {} Fold ==============================\\n\\n\".format(fold_cnt))\n",
    "    \n",
    "    ### train\n",
    "    train_input = {name: rel[name][train_index] for name in sparse_features}\n",
    "    train_input[\"age\"] = _age[train_index]\n",
    "    train_input[\"occupation\"] = _occupation[train_index]\n",
    "    train_input[\"genre\"] = _genre[train_index]\n",
    "    train_target = np.array(rel[rating][train_index])\n",
    "    train_target = np.where(train_target < 3, 0, train_target)\n",
    "    \n",
    "    ### test\n",
    "    test_input = {name: rel[name][test_index] for name in sparse_features}\n",
    "    test_input[\"age\"] = _age[test_index]\n",
    "    test_input[\"occupation\"] = _occupation[test_index]\n",
    "    test_input[\"genre\"] = _genre[test_index]\n",
    "    test_target = np.array(rel[rating][test_index])\n",
    "    test_target = np.where(test_target < 3, 0, test_target)\n",
    "    binary_target = np.where(test_target >= 3, 1, 0).reshape(1, -1)\n",
    "    \n",
    "    print(\"\\n\\n Training DeepFM \\n\")\n",
    "    ### DeepFM\n",
    "    deepfm = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    deepfm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    deepfm_hist = deepfm.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = deepfm.predict(test_input, batch_size=256)\n",
    "    deepfm_mse += mean_squared_error(test_target, pred_ans)\n",
    "    \n",
    "    pred_ans = np.where(pred_ans > 3, 1, 0).reshape((1, -1))\n",
    "    deepfm_recall += recall_score(binary_target.reshape(-1, 1), pred_ans.reshape(-1, 1))\n",
    "    deepfm_ndcg += ndcg_score(binary_target, pred_ans)\n",
    "#     print(\"DeepFM MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    print(\"\\n\\n Training CCPM \\n\")\n",
    "    ### CCPM\n",
    "    ccpm = CCPM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    ccpm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    ccpm_hist = ccpm.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = ccpm.predict(test_input, batch_size=256)\n",
    "    ccpm_mse += mean_squared_error(test_target, pred_ans)\n",
    "    \n",
    "    pred_ans = np.where(pred_ans > 3, 1, 0).reshape((1, -1))\n",
    "    ccpm_recall += recall_score(binary_target.reshape(-1, 1), pred_ans.reshape(-1, 1))\n",
    "    ccpm_ndcg += ndcg_score(binary_target, pred_ans)\n",
    "#     print(\"CCPM MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    print(\"\\n\\n Training IPMM \\n\")\n",
    "    ### IPNN\n",
    "    ipnn = PNN(dnn_feature_columns, task='regression', device=device, use_inner=True, use_outter=False)\n",
    "    ipnn.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    ipnn_hist = ipnn.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = ipnn.predict(test_input, batch_size=256)\n",
    "    ipnn_mse += mean_squared_error(test_target, pred_ans)\n",
    "    \n",
    "    pred_ans = np.where(pred_ans > 3, 1, 0).reshape((1, -1))\n",
    "    ipnn_recall += recall_score(binary_target.reshape(-1, 1), pred_ans.reshape(-1, 1))\n",
    "    ipnn_ndcg += ndcg_score(binary_target, pred_ans)\n",
    "#     print(\"IPNN MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    print(\"\\n\\n Training OPNN \\n\")\n",
    "    ### OPNN\n",
    "    opnn = PNN(dnn_feature_columns, task='regression', device=device, use_inner=False, use_outter=True)\n",
    "    opnn.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    opnn_hist = opnn.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = opnn.predict(test_input, batch_size=256)\n",
    "    opnn_mse += mean_squared_error(test_target, pred_ans)\n",
    "    \n",
    "    pred_ans = np.where(pred_ans > 3, 1, 0).reshape((1, -1))\n",
    "    opnn_recall += recall_score(binary_target.reshape(-1, 1), pred_ans.reshape(-1, 1))\n",
    "    opnn_ndcg += ndcg_score(binary_target, pred_ans)\n",
    "#     print(\"OPNN MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    print(\"\\n\\n Training Wide&Deep \\n\")\n",
    "    ### Wide & Deep\n",
    "    wdl = WDL(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    wdl.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    wdl_hist = wdl.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = wdl.predict(test_input, batch_size=256)\n",
    "    wdl_mse += mean_squared_error(test_target, pred_ans)\n",
    "    \n",
    "    pred_ans = np.where(pred_ans > 3, 1, 0).reshape((1, -1))\n",
    "    wdl_recall += recall_score(binary_target.reshape(-1, 1), pred_ans.reshape(-1, 1))\n",
    "    wdl_ndcg += ndcg_score(binary_target, pred_ans)\n",
    "#     print(\"WDL MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    print(\"\\n\\n Training DCN \\n\")\n",
    "    ### DCN\n",
    "    dcn = DCN(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    dcn.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    dcn_hist = dcn.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = dcn.predict(test_input, batch_size=256)\n",
    "    dcn_mse += mean_squared_error(test_target, pred_ans)\n",
    "    \n",
    "    pred_ans = np.where(pred_ans > 3, 1, 0).reshape((1, -1))\n",
    "    dcn_recall += recall_score(binary_target.reshape(-1, 1), pred_ans.reshape(-1, 1))\n",
    "    dcn_ndcg += ndcg_score(binary_target, pred_ans)\n",
    "#     print(\"DCN MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\n Training xDeepFM \\n\")\n",
    "    ### xDeepFM\n",
    "    xdeepfm = xDeepFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    xdeepfm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    xdeepfm_hist = xdeepfm.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = xdeepfm.predict(test_input, batch_size=256)\n",
    "    xdeepfm_mse += mean_squared_error(test_target, pred_ans)\n",
    "    \n",
    "    pred_ans = np.where(pred_ans > 3, 1, 0).reshape((1, -1))\n",
    "    xdeepfm_recall += recall_score(binary_target.reshape(-1, 1), pred_ans.reshape(-1, 1))\n",
    "    xdeepfm_ndcg += ndcg_score(binary_target, pred_ans)\n",
    "#     print(\"xDeepFM MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\n Training AFM \\n\")\n",
    "    ### AFM\n",
    "    afm = AFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    afm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    afm_hist = afm.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = afm.predict(test_input, batch_size=256)\n",
    "    afm_mse += mean_squared_error(test_target, pred_ans)\n",
    "    \n",
    "    pred_ans = np.where(pred_ans > 3, 1, 0).reshape((1, -1))\n",
    "    afm_recall += recall_score(binary_target.reshape(-1, 1), pred_ans.reshape(-1, 1))\n",
    "    afm_ndcg += ndcg_score(binary_target, pred_ans)\n",
    "#     print(\"AFM MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"\\n Training DIN \\n\")\n",
    "    ### DIN\n",
    "    din = DIN(dnn_feature_columns, [], task='regression', device=device)\n",
    "    din.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    din_hist = din.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = din.predict(test_input, batch_size=256)\n",
    "    din_mse += mean_squared_error(test_target, pred_ans)\n",
    "    print(\"DIN MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-crawford",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-louisiana",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepfm_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-genius",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccpm_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipnn_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-glass",
   "metadata": {},
   "outputs": [],
   "source": [
    "opnn_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-progressive",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdl_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-actress",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcn_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdeepfm_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "afm_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-lightweight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-fundamentals",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deepfm_recall /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-triumph",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccpm_recall /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipnn_recall /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-russia",
   "metadata": {},
   "outputs": [],
   "source": [
    "opnn_recall /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-bulletin",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcn_recall /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdl_recall /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdeepfm_recall /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "afm_recall /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-printing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepfm_ndcg /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccpm_ndcg /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipnn_ndcg /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "opnn_ndcg /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdl_ndcg /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcn_ndcg /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdeepfm_ndcg /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-green",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "afm_ndcg /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-header",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-locator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-singles",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-revelation",
   "metadata": {},
   "source": [
    "# Test single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "stable-selling",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p = os.path.join(root, \"train.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "laughing-result",
   "metadata": {},
   "outputs": [],
   "source": [
    "group, group_i, group_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"user_group.dat\"), user_cnt=13024)\n",
    "location, location_i, location_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"user_location.dat\"), user_cnt=13024)\n",
    "user, user_i, user_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"user_user.dat\"), user_cnt=13024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "likely-venture",
   "metadata": {},
   "outputs": [],
   "source": [
    "year, year_i, year_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"book_year.dat\"), user_cnt=22347)\n",
    "publisher, publisher_i, publisher_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"book_publisher.dat\"), user_cnt=22347)\n",
    "author, author_i, author_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"book_author.dat\"), user_cnt=22347)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "statistical-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = [\"cols_0\", \"cols_1\"] # user_id, movie_id\n",
    "rating = \"cols_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "disabled-virgin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cols_0</th>\n",
       "      <th>cols_1</th>\n",
       "      <th>cols_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9608</td>\n",
       "      <td>791</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11607</td>\n",
       "      <td>2664</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3630</td>\n",
       "      <td>712</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12070</td>\n",
       "      <td>5046</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3967</td>\n",
       "      <td>202</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cols_0  cols_1  cols_2\n",
       "0    9608     791       3\n",
       "1   11607    2664       4\n",
       "2    3630     712       4\n",
       "3   12070    5046       5\n",
       "4    3967     202       5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = utils.read_file(train_p)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "consecutive-latin",
   "metadata": {},
   "outputs": [],
   "source": [
    "_group = group[rel.cols_0 -1]\n",
    "_location = location[rel.cols_0 -1]\n",
    "_user = user[rel.cols_0 -1]\n",
    "\n",
    "_year = year[rel.cols_1 -1]\n",
    "_publisher = publisher[rel.cols_1 -1]\n",
    "_author = author[rel.cols_1 -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "scheduled-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Label Encoding for sparse features,and process sequence features\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    train[feat] = lbe.fit_transform(train[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "detailed-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, train[feat].nunique(), embedding_dim=4) for feat in sparse_features]\n",
    "\n",
    "varlen_feature_columns = [\n",
    "    VarLenSparseFeat(SparseFeat('group', vocabulary_size=group_i + 1, embedding_dim=4), maxlen=group_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('location', vocabulary_size=location_i + 1, embedding_dim=4), maxlen=location_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('user', vocabulary_size=13024 + 1, embedding_dim=4), maxlen=user_m, combiner='mean'),\n",
    "    \n",
    "    VarLenSparseFeat(SparseFeat('year', vocabulary_size=year_i + 1, embedding_dim=4), maxlen=year_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('publisher', vocabulary_size=publisher_i + 1, embedding_dim=4), maxlen=publisher_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('author', vocabulary_size=author_i + 1, embedding_dim=4), maxlen=author_m, combiner='mean')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "after-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "logical-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.generate input data for model\n",
    "model_input = {name: train[name] for name in sparse_features}  #\n",
    "model_input[\"group\"] = _group\n",
    "model_input[\"location\"] = _location\n",
    "model_input[\"user\"] = _user\n",
    "model_input[\"year\"] = _year\n",
    "model_input[\"publisher\"] = _publisher\n",
    "model_input[\"author\"] = _author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-exception",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-drill",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-public",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "female-maple",
   "metadata": {},
   "source": [
    "### DeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "wireless-boring",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import DeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "unexpected-stack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "228s - loss:  0.7947 - mse:  0.7945 - val_mse:  0.5051\n",
      "Epoch 2/10\n",
      "230s - loss:  0.4835 - mse:  0.4835 - val_mse:  0.5019\n",
      "Epoch 3/10\n",
      "228s - loss:  0.4719 - mse:  0.4718 - val_mse:  0.4993\n",
      "Epoch 4/10\n",
      "226s - loss:  0.4649 - mse:  0.4649 - val_mse:  0.5034\n",
      "Epoch 5/10\n",
      "232s - loss:  0.4600 - mse:  0.4599 - val_mse:  0.4983\n",
      "Epoch 6/10\n",
      "226s - loss:  0.4546 - mse:  0.4545 - val_mse:  0.5073\n",
      "Epoch 7/10\n",
      "228s - loss:  0.4494 - mse:  0.4492 - val_mse:  0.5018\n",
      "Epoch 8/10\n",
      "229s - loss:  0.4428 - mse:  0.4426 - val_mse:  0.5088\n",
      "Epoch 9/10\n",
      "228s - loss:  0.4335 - mse:  0.4333 - val_mse:  0.4998\n",
      "Epoch 10/10\n",
      "229s - loss:  0.4216 - mse:  0.4213 - val_mse:  0.5087\n"
     ]
    }
   ],
   "source": [
    "deepfm = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "\n",
    "deepfm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = deepfm.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-relation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "superb-greeting",
   "metadata": {},
   "source": [
    "### CCPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "grave-companion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import CCPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "static-martin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "228s - loss:  0.7249 - mse:  0.7248 - val_mse:  0.5026\n",
      "Epoch 2/10\n",
      "229s - loss:  0.4766 - mse:  0.4765 - val_mse:  0.4946\n",
      "Epoch 3/10\n",
      "224s - loss:  0.4588 - mse:  0.4588 - val_mse:  0.4915\n",
      "Epoch 4/10\n",
      "231s - loss:  0.4455 - mse:  0.4456 - val_mse:  0.4947\n",
      "Epoch 5/10\n",
      "237s - loss:  0.4302 - mse:  0.4300 - val_mse:  0.4993\n",
      "Epoch 6/10\n",
      "232s - loss:  0.4124 - mse:  0.4122 - val_mse:  0.5155\n",
      "Epoch 7/10\n",
      "207s - loss:  0.3938 - mse:  0.3936 - val_mse:  0.5194\n",
      "Epoch 8/10\n",
      "210s - loss:  0.3771 - mse:  0.3770 - val_mse:  0.5336\n",
      "Epoch 9/10\n",
      "214s - loss:  0.3616 - mse:  0.3613 - val_mse:  0.5405\n",
      "Epoch 10/10\n",
      "213s - loss:  0.3485 - mse:  0.3483 - val_mse:  0.5592\n"
     ]
    }
   ],
   "source": [
    "ccpm = CCPM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "\n",
    "ccpm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = ccpm.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-masters",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "renewable-forwarding",
   "metadata": {},
   "source": [
    "### PNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dated-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import PNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-accused",
   "metadata": {},
   "source": [
    "#### IPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "little-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipnn = PNN(dnn_feature_columns, task='regression', device=device, use_inner=True, use_outter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "celtic-qualification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "125s - loss:  0.9133 - mse:  0.9131 - val_mse:  0.5042\n",
      "Epoch 2/10\n",
      "125s - loss:  0.4784 - mse:  0.4784 - val_mse:  0.4927\n",
      "Epoch 3/10\n",
      "123s - loss:  0.4554 - mse:  0.4554 - val_mse:  0.4902\n",
      "Epoch 4/10\n",
      "124s - loss:  0.4353 - mse:  0.4353 - val_mse:  0.4972\n",
      "Epoch 5/10\n",
      "128s - loss:  0.4149 - mse:  0.4150 - val_mse:  0.5067\n",
      "Epoch 6/10\n",
      "128s - loss:  0.3920 - mse:  0.3918 - val_mse:  0.5238\n",
      "Epoch 7/10\n",
      "128s - loss:  0.3712 - mse:  0.3711 - val_mse:  0.5402\n",
      "Epoch 8/10\n",
      "136s - loss:  0.3534 - mse:  0.3532 - val_mse:  0.5562\n",
      "Epoch 9/10\n",
      "141s - loss:  0.3391 - mse:  0.3390 - val_mse:  0.5750\n",
      "Epoch 10/10\n",
      "136s - loss:  0.3282 - mse:  0.3280 - val_mse:  0.5825\n"
     ]
    }
   ],
   "source": [
    "ipnn.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = ipnn.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-swing",
   "metadata": {},
   "source": [
    "#### OPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abstract-makeup",
   "metadata": {},
   "outputs": [],
   "source": [
    "opnn = PNN(dnn_feature_columns, task='regression', device=device, use_inner=False, use_outter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "collaborative-medicine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "142s - loss:  0.8448 - mse:  0.8446 - val_mse:  0.5039\n",
      "Epoch 2/10\n",
      "143s - loss:  0.4802 - mse:  0.4802 - val_mse:  0.4969\n",
      "Epoch 3/10\n",
      "141s - loss:  0.4659 - mse:  0.4658 - val_mse:  0.4955\n",
      "Epoch 4/10\n",
      "149s - loss:  0.4523 - mse:  0.4523 - val_mse:  0.4966\n",
      "Epoch 5/10\n",
      "145s - loss:  0.4381 - mse:  0.4381 - val_mse:  0.4894\n",
      "Epoch 6/10\n",
      "148s - loss:  0.4243 - mse:  0.4242 - val_mse:  0.4984\n",
      "Epoch 7/10\n",
      "149s - loss:  0.4031 - mse:  0.4031 - val_mse:  0.5068\n",
      "Epoch 8/10\n",
      "148s - loss:  0.3811 - mse:  0.3809 - val_mse:  0.5243\n",
      "Epoch 9/10\n",
      "149s - loss:  0.3619 - mse:  0.3618 - val_mse:  0.5375\n",
      "Epoch 10/10\n",
      "150s - loss:  0.3465 - mse:  0.3463 - val_mse:  0.5589\n"
     ]
    }
   ],
   "source": [
    "opnn.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = opnn.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-airplane",
   "metadata": {},
   "source": [
    "#### PIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-bridal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-ecuador",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "relative-sustainability",
   "metadata": {},
   "source": [
    "### Wide & Deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "consistent-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import WDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "protected-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdl = WDL(linear_feature_columns, dnn_feature_columns, task='regression', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "female-tokyo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "246s - loss:  0.7961 - mse:  0.7960 - val_mse:  0.5040\n",
      "Epoch 2/10\n",
      "240s - loss:  0.4823 - mse:  0.4823 - val_mse:  0.5012\n",
      "Epoch 3/10\n",
      "246s - loss:  0.4711 - mse:  0.4710 - val_mse:  0.4985\n",
      "Epoch 4/10\n",
      "250s - loss:  0.4652 - mse:  0.4651 - val_mse:  0.5034\n",
      "Epoch 5/10\n",
      "244s - loss:  0.4620 - mse:  0.4618 - val_mse:  0.4979\n",
      "Epoch 6/10\n",
      "246s - loss:  0.4590 - mse:  0.4589 - val_mse:  0.5057\n",
      "Epoch 7/10\n",
      "227s - loss:  0.4565 - mse:  0.4564 - val_mse:  0.5003\n",
      "Epoch 8/10\n",
      "216s - loss:  0.4539 - mse:  0.4538 - val_mse:  0.5046\n",
      "Epoch 9/10\n",
      "224s - loss:  0.4500 - mse:  0.4499 - val_mse:  0.4941\n",
      "Epoch 10/10\n",
      "246s - loss:  0.4450 - mse:  0.4449 - val_mse:  0.4990\n"
     ]
    }
   ],
   "source": [
    "wdl.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = wdl.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-lounge",
   "metadata": {},
   "source": [
    "### Deep Cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "parallel-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import DCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "thorough-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcn = DCN(linear_feature_columns, dnn_feature_columns, task='regression', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "crucial-establishment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "258s - loss:  0.8089 - mse:  0.8087 - val_mse:  0.5125\n",
      "Epoch 2/10\n",
      "261s - loss:  0.4816 - mse:  0.4817 - val_mse:  0.4968\n",
      "Epoch 3/10\n",
      "261s - loss:  0.4698 - mse:  0.4698 - val_mse:  0.4977\n",
      "Epoch 4/10\n",
      "257s - loss:  0.4629 - mse:  0.4628 - val_mse:  0.4945\n",
      "Epoch 5/10\n",
      "255s - loss:  0.4569 - mse:  0.4567 - val_mse:  0.4912\n",
      "Epoch 6/10\n",
      "258s - loss:  0.4486 - mse:  0.4486 - val_mse:  0.4922\n",
      "Epoch 7/10\n",
      "252s - loss:  0.4416 - mse:  0.4415 - val_mse:  0.4916\n",
      "Epoch 8/10\n",
      "251s - loss:  0.4345 - mse:  0.4343 - val_mse:  0.4934\n",
      "Epoch 9/10\n",
      "256s - loss:  0.4284 - mse:  0.4283 - val_mse:  0.4968\n",
      "Epoch 10/10\n",
      "263s - loss:  0.4220 - mse:  0.4217 - val_mse:  0.5029\n"
     ]
    }
   ],
   "source": [
    "dcn.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = dcn.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-atlantic",
   "metadata": {},
   "source": [
    "### xDeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "electronic-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import xDeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "expanded-concrete",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdeepfm = xDeepFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "affecting-compiler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "267s - loss:  0.6677 - mse:  0.6676 - val_mse:  0.5041\n",
      "Epoch 2/10\n",
      "262s - loss:  0.4801 - mse:  0.4800 - val_mse:  0.5075\n",
      "Epoch 3/10\n",
      "260s - loss:  0.4634 - mse:  0.4634 - val_mse:  0.4897\n",
      "Epoch 4/10\n",
      "259s - loss:  0.4514 - mse:  0.4513 - val_mse:  0.4937\n",
      "Epoch 5/10\n",
      "266s - loss:  0.4428 - mse:  0.4428 - val_mse:  0.4951\n",
      "Epoch 6/10\n",
      "261s - loss:  0.4348 - mse:  0.4347 - val_mse:  0.4953\n",
      "Epoch 7/10\n",
      "262s - loss:  0.4266 - mse:  0.4264 - val_mse:  0.4972\n",
      "Epoch 8/10\n",
      "253s - loss:  0.4124 - mse:  0.4123 - val_mse:  0.5075\n",
      "Epoch 9/10\n",
      "265s - loss:  0.3919 - mse:  0.3917 - val_mse:  0.5153\n",
      "Epoch 10/10\n",
      "268s - loss:  0.3690 - mse:  0.3688 - val_mse:  0.5356\n"
     ]
    }
   ],
   "source": [
    "xdeepfm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = xdeepfm.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-collins",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "seven-doubt",
   "metadata": {},
   "source": [
    "### Attentional Factorization Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "silver-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import AFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fallen-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "afm = AFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "personalized-logistics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "255s - loss:  2.5075 - mse:  2.5064 - val_mse:  0.6100\n",
      "Epoch 2/10\n",
      "245s - loss:  0.5585 - mse:  0.5580 - val_mse:  0.5407\n",
      "Epoch 3/10\n",
      "250s - loss:  0.5036 - mse:  0.5033 - val_mse:  0.5176\n",
      "Epoch 4/10\n",
      "248s - loss:  0.4790 - mse:  0.4785 - val_mse:  0.5092\n",
      "Epoch 5/10\n",
      "255s - loss:  0.4663 - mse:  0.4658 - val_mse:  0.5048\n",
      "Epoch 6/10\n",
      "251s - loss:  0.4587 - mse:  0.4581 - val_mse:  0.5022\n",
      "Epoch 7/10\n",
      "253s - loss:  0.4536 - mse:  0.4529 - val_mse:  0.5014\n",
      "Epoch 8/10\n",
      "251s - loss:  0.4497 - mse:  0.4490 - val_mse:  0.5012\n",
      "Epoch 9/10\n",
      "256s - loss:  0.4468 - mse:  0.4461 - val_mse:  0.5005\n",
      "Epoch 10/10\n",
      "254s - loss:  0.4443 - mse:  0.4436 - val_mse:  0.5011\n"
     ]
    }
   ],
   "source": [
    "afm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = afm.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-softball",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "handled-blair",
   "metadata": {},
   "source": [
    "### Neural Factorization Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "searching-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import NFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "average-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfm = NFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "terminal-control",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "247s - loss:  0.7533 - mse:  0.7532 - val_mse:  0.5090\n",
      "Epoch 2/10\n",
      "234s - loss:  0.4786 - mse:  0.4785 - val_mse:  0.4960\n",
      "Epoch 3/10\n",
      "246s - loss:  0.4566 - mse:  0.4565 - val_mse:  0.4959\n",
      "Epoch 4/10\n",
      "246s - loss:  0.4432 - mse:  0.4432 - val_mse:  0.4988\n",
      "Epoch 5/10\n",
      "242s - loss:  0.4338 - mse:  0.4337 - val_mse:  0.5024\n",
      "Epoch 6/10\n",
      "248s - loss:  0.4259 - mse:  0.4258 - val_mse:  0.5026\n",
      "Epoch 7/10\n",
      "238s - loss:  0.4191 - mse:  0.4189 - val_mse:  0.5034\n",
      "Epoch 8/10\n",
      "248s - loss:  0.4125 - mse:  0.4123 - val_mse:  0.5059\n",
      "Epoch 9/10\n",
      "236s - loss:  0.4040 - mse:  0.4037 - val_mse:  0.5117\n",
      "Epoch 10/10\n",
      "230s - loss:  0.3946 - mse:  0.3943 - val_mse:  0.5179\n"
     ]
    }
   ],
   "source": [
    "nfm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = nfm.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-instruction",
   "metadata": {},
   "source": [
    "### Deep Interest Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "appreciated-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import DIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "chronic-peripheral",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_feature_list = np.array([\"cols_0\", \"cols_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "photographic-edmonton",
   "metadata": {},
   "outputs": [],
   "source": [
    "din = DIN(dnn_feature_columns, behavior_feature_list, task='regression', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "verbal-password",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'VarLenSparseFeat' object has no attribute 'use_hash'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-c5fe815ca6cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrating\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/deepctr_torch/models/basemodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, initial_epoch, validation_split, validation_data, shuffle, callbacks)\u001b[0m\n\u001b[1;32m    239\u001b[0m                         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/deepctr_torch/models/din.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         sequence_embed_dict = varlen_embedding_lookup(X, self.embedding_dict, self.feature_index,\n\u001b[0;32m---> 95\u001b[0;31m                                                       self.sparse_varlen_feature_columns)\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         sequence_embed_list = get_varlen_pooling_list(sequence_embed_dict, X, self.feature_index,\n",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/deepctr_torch/inputs.py\u001b[0m in \u001b[0;36mvarlen_embedding_lookup\u001b[0;34m(X, embedding_dict, sequence_input_dict, varlen_sparse_feature_columns)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mfeature_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0membedding_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_hash\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m             \u001b[0;31m# lookup_idx = Hash(fc.vocabulary_size, mask_zero=True)(sequence_input_dict[feature_name])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;31m# TODO: add hash function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VarLenSparseFeat' object has no attribute 'use_hash'"
     ]
    }
   ],
   "source": [
    "din.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = din.fit(model_input, train[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-victim",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
