{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "another-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, ndcg_score, recall_score\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "endless-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typical import cf_user_based, MF\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-massage",
   "metadata": {},
   "source": [
    "# Douban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "arbitrary-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.join(os.getcwd(), \"DoubanBook\")\n",
    "rel_p = os.path.join(root, \"user_book.dat\")\n",
    "\n",
    "user_cnt = 13024\n",
    "item_cnt = 22347"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "announced-windsor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cols_0</th>\n",
       "      <th>cols_1</th>\n",
       "      <th>cols_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10855</td>\n",
       "      <td>938</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10027</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>741</td>\n",
       "      <td>2426</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>453</td>\n",
       "      <td>1263</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11665</td>\n",
       "      <td>7717</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cols_0  cols_1  cols_2\n",
       "0   10855     938       4\n",
       "1   10027       3       3\n",
       "2     741    2426       5\n",
       "3     453    1263       4\n",
       "4   11665    7717       5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel = utils.read_file(rel_p)\n",
    "rel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "flexible-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-bidder",
   "metadata": {},
   "source": [
    "## Douban without filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "rocky-error",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 1 ==========\n",
      "Iteration: 10 ; error = 3121.5899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 2 ==========\n",
      "Iteration: 10 ; error = 3121.3403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 3 ==========\n",
      "Iteration: 10 ; error = 3121.3449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 4 ==========\n",
      "Iteration: 10 ; error = 3121.2396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 5 ==========\n",
      "Iteration: 10 ; error = 3121.2556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "fold_cnt = 0\n",
    "\n",
    "mse_list = []\n",
    "recall_list = []\n",
    "ndcg_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(rel):\n",
    "    \n",
    "    fold_cnt += 1\n",
    "    print(\"========= Fold: {} ==========\".format(fold_cnt))\n",
    "    \n",
    "    test_df = rel.iloc[test_index]\n",
    "    \n",
    "    train_index, valid_index = train_test_split(train_index, test_size=0.1)\n",
    "    train_df = rel.iloc[train_index]\n",
    "    valid_df = rel.iloc[valid_index]\n",
    "    \n",
    "    train_m = csr_matrix((train_df.cols_2, (train_df.cols_0, train_df.cols_1)), shape=(user_cnt+1, item_cnt+1))\n",
    "    train_m = utils.get_rep(train_m)\n",
    "    mf = MF(R=train_m, K=30, alpha=0.01, beta=0.001, iterations=10)\n",
    "    mf.train()\n",
    "    \n",
    "    preds = []\n",
    "    gts = []\n",
    "    for index, row in valid_df.iterrows():\n",
    "        u, i, r = row['cols_0'], row['cols_1'], row['cols_2']\n",
    "        pred = mf.get_rating(u-1, i-1)\n",
    "        preds.append(pred)\n",
    "        gts.append(r)\n",
    "        \n",
    "    preds = np.array(preds).reshape(-1, 1)\n",
    "    gts = np.array(gts).reshape(-1, 1)\n",
    "    \n",
    "    mse = mean_squared_error(gts, preds)\n",
    "    \n",
    "    preds = np.where(preds >= 3, 1, 0)\n",
    "    gts = np.where(preds >=3, 1, 0)\n",
    "    recall = recall_score(gts, preds)\n",
    "    ndcg = ndcg_score(gts.reshape(1, -1), preds.reshape(1, -1))\n",
    "    \n",
    "    mse_list.append(mse)\n",
    "    recall_list.append(recall)\n",
    "    ndcg_list.append(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "useful-movement",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "substantial-forge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "foster-jewelry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.081908049402763"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mse_list)/len(mse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "expanded-timothy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(recall_list)/len(recall_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ready-interstate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ndcg_list)/len(ndcg_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-liabilities",
   "metadata": {},
   "source": [
    "## Douban with filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "expected-granny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 1 ==========\n",
      "Iteration: 10 ; error = 3113.6718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 2 ==========\n",
      "Iteration: 10 ; error = 3113.1917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 3 ==========\n",
      "Iteration: 10 ; error = 3113.3897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 4 ==========\n",
      "Iteration: 10 ; error = 3112.9214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 5 ==========\n",
      "Iteration: 10 ; error = 3113.3379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "fold_cnt = 0\n",
    "\n",
    "mse_list = []\n",
    "recall_list = []\n",
    "ndcg_list = []\n",
    "\n",
    "rel.loc[rel['cols_2'] < 3] = 0\n",
    "\n",
    "for train_index, test_index in kf.split(rel):\n",
    "    \n",
    "    fold_cnt += 1\n",
    "    print(\"========= Fold: {} ==========\".format(fold_cnt))\n",
    "    \n",
    "    test_df = rel.iloc[test_index]\n",
    "    \n",
    "    train_index, valid_index = train_test_split(train_index, test_size=0.1)\n",
    "    train_df = rel.iloc[train_index]\n",
    "    valid_df = rel.iloc[valid_index]\n",
    "    \n",
    "    train_m = csr_matrix((train_df.cols_2, (train_df.cols_0, train_df.cols_1)), shape=(user_cnt+1, item_cnt+1))\n",
    "    train_m = utils.get_rep(train_m)\n",
    "    mf = MF(R=train_m, K=20, alpha=0.01, beta=0.001, iterations=10)\n",
    "    mf.train()\n",
    "    \n",
    "    preds = []\n",
    "    gts = []\n",
    "    for index, row in valid_df.iterrows():\n",
    "        u, i, r = row['cols_0'], row['cols_1'], row['cols_2']\n",
    "        pred = mf.get_rating(u-1, i-1)\n",
    "        preds.append(pred)\n",
    "        gts.append(r)\n",
    "    preds = np.array(preds).reshape(-1, 1)\n",
    "    gts = np.array(gts).reshape(-1, 1)\n",
    "    \n",
    "    mse = mean_squared_error(gts, preds)\n",
    "    preds = np.where(preds >= 3, 1, 0)\n",
    "    gts = np.where(preds >=3, 1, 0)\n",
    "    recall = recall_score(gts, preds)\n",
    "    ndcg = ndcg_score(gts.reshape(1, -1), preds.reshape(1, -1))\n",
    "    \n",
    "    mse_list.append(mse)\n",
    "    recall_list.append(recall)\n",
    "    ndcg_list.append(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adequate-vacuum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.00082829918236"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mse_list)/len(mse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "automatic-receptor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(recall_list)/len(recall_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "regular-enemy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ndcg_list)/len(ndcg_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-chapel",
   "metadata": {},
   "source": [
    "# Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "recorded-brighton",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.join(os.getcwd(), \"Yelp\")\n",
    "rel_p = os.path.join(root, \"user_business.dat\")\n",
    "\n",
    "user_cnt = 16239\n",
    "item_cnt = 14284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "relative-attendance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cols_0</th>\n",
       "      <th>cols_1</th>\n",
       "      <th>cols_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8391</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8971</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>186</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>205</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>209</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cols_0  cols_1  cols_2\n",
       "0       1    8391       5\n",
       "1       1    8971       5\n",
       "2       2     186       5\n",
       "3       2     205       5\n",
       "4       2     209       4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel = utils.read_file(rel_p)\n",
    "rel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "accepting-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-survival",
   "metadata": {},
   "source": [
    "## yelp without filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "together-duncan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 1 ==========\n",
      "Iteration: 10 ; error = 1487.4866\n",
      "========= Fold: 2 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; error = 1487.2711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 3 ==========\n",
      "Iteration: 10 ; error = 1487.0861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 4 ==========\n",
      "Iteration: 10 ; error = 1486.7731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 5 ==========\n",
      "Iteration: 10 ; error = 1486.2068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "fold_cnt = 0\n",
    "\n",
    "mse_list = []\n",
    "recall_list = []\n",
    "ndcg_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(rel):\n",
    "    \n",
    "    fold_cnt += 1\n",
    "    print(\"========= Fold: {} ==========\".format(fold_cnt))\n",
    "    \n",
    "    test_df = rel.iloc[test_index]\n",
    "    \n",
    "    train_index, valid_index = train_test_split(train_index, test_size=0.1)\n",
    "    train_df = rel.iloc[train_index]\n",
    "    valid_df = rel.iloc[valid_index]\n",
    "    \n",
    "    train_m = csr_matrix((train_df.cols_2, (train_df.cols_0, train_df.cols_1)), shape=(user_cnt+1, item_cnt+1))\n",
    "    train_m = utils.get_rep(train_m)\n",
    "    mf = MF(R=train_m, K=20, alpha=0.01, beta=0.001, iterations=10)\n",
    "    mf.train()\n",
    "    \n",
    "    preds = []\n",
    "    gts = []\n",
    "    for index, row in valid_df.iterrows():\n",
    "        u, i, r = row['cols_0'], row['cols_1'], row['cols_2']\n",
    "        pred = mf.get_rating(u-1, i-1)\n",
    "        preds.append(pred)\n",
    "        gts.append(r)\n",
    "    preds = np.array(preds).reshape(-1, 1)\n",
    "    gts = np.array(gts).reshape(-1, 1)\n",
    "    \n",
    "    mse = mean_squared_error(gts, preds)\n",
    "    preds = np.where(preds >= 3, 1, 0)\n",
    "    gts = np.where(preds >=3, 1, 0)\n",
    "    recall = recall_score(gts, preds)\n",
    "    ndcg = ndcg_score(gts.reshape(1, -1), preds.reshape(1, -1))\n",
    "    \n",
    "    mse_list.append(mse)\n",
    "    recall_list.append(recall)\n",
    "    ndcg_list.append(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "artistic-dairy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.47277090968501"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mse_list)/len(mse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "wrapped-direction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(recall_list)/len(recall_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "prescribed-emergency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ndcg_list)/len(ndcg_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-pendant",
   "metadata": {},
   "source": [
    "## yelp with filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "false-equilibrium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 1 ==========\n",
      "Iteration: 10 ; error = 1467.5738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 2 ==========\n",
      "Iteration: 10 ; error = 1467.6946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 3 ==========\n",
      "Iteration: 10 ; error = 1467.9586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 4 ==========\n",
      "Iteration: 10 ; error = 1466.8636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 5 ==========\n",
      "Iteration: 10 ; error = 1466.4691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "fold_cnt = 0\n",
    "\n",
    "mse_list = []\n",
    "recall_list = []\n",
    "ndcg_list = []\n",
    "\n",
    "rel.loc[rel['cols_2'] < 3] = 0\n",
    "\n",
    "for train_index, test_index in kf.split(rel):\n",
    "    \n",
    "    fold_cnt += 1\n",
    "    print(\"========= Fold: {} ==========\".format(fold_cnt))\n",
    "    \n",
    "    test_df = rel.iloc[test_index]\n",
    "    \n",
    "    train_index, valid_index = train_test_split(train_index, test_size=0.1)\n",
    "    train_df = rel.iloc[train_index]\n",
    "    valid_df = rel.iloc[valid_index]\n",
    "    \n",
    "    train_m = csr_matrix((train_df.cols_2, (train_df.cols_0, train_df.cols_1)), shape=(user_cnt+1, item_cnt+1))\n",
    "    train_m = utils.get_rep(train_m)\n",
    "    mf = MF(R=train_m, K=20, alpha=0.01, beta=0.001, iterations=10)\n",
    "    mf.train()\n",
    "    \n",
    "    preds = []\n",
    "    gts = []\n",
    "    for index, row in valid_df.iterrows():\n",
    "        u, i, r = row['cols_0'], row['cols_1'], row['cols_2']\n",
    "        pred = mf.get_rating(u-1, i-1)\n",
    "        preds.append(pred)\n",
    "        gts.append(r)\n",
    "    preds = np.array(preds).reshape(-1, 1)\n",
    "    gts = np.array(gts).reshape(-1, 1)\n",
    "    \n",
    "    mse = mean_squared_error(gts, preds)\n",
    "    preds = np.where(preds >= 3, 1, 0)\n",
    "    gts = np.where(preds >=3, 1, 0)\n",
    "    recall = recall_score(gts, preds)\n",
    "    ndcg = ndcg_score(gts.reshape(1, -1), preds.reshape(1, -1))\n",
    "    \n",
    "    mse_list.append(mse)\n",
    "    recall_list.append(recall)\n",
    "    ndcg_list.append(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "religious-generator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.053902877768191"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mse_list)/len(mse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "external-egypt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(recall_list)/len(recall_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "wrapped-bracket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ndcg_list)/len(ndcg_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-newspaper",
   "metadata": {},
   "source": [
    "# Movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "removable-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.join(os.getcwd(), \"Movielens\")\n",
    "rel_p = os.path.join(root, \"user_movie.dat\")\n",
    "\n",
    "user_cnt = 943\n",
    "item_cnt = 1682"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "comic-junction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cols_0</th>\n",
       "      <th>cols_1</th>\n",
       "      <th>cols_2</th>\n",
       "      <th>cols_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cols_0  cols_1  cols_2     cols_3\n",
       "0     196     242       3  881250949\n",
       "1     186     302       3  891717742\n",
       "2      22     377       1  878887116\n",
       "3     244      51       2  880606923\n",
       "4     166     346       1  886397596"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel = utils.read_file(rel_p)\n",
    "rel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "novel-barrel",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-interim",
   "metadata": {},
   "source": [
    "## movielens without filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "union-homeless",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 1 ==========\n",
      "Iteration: 10 ; error = 951.9534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 2 ==========\n",
      "Iteration: 10 ; error = 951.6323\n",
      "========= Fold: 3 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; error = 953.2988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 4 ==========\n",
      "Iteration: 10 ; error = 954.0300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 5 ==========\n",
      "Iteration: 10 ; error = 953.3073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "fold_cnt = 0\n",
    "\n",
    "mse_list = []\n",
    "recall_list = []\n",
    "ndcg_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(rel):\n",
    "    \n",
    "    fold_cnt += 1\n",
    "    print(\"========= Fold: {} ==========\".format(fold_cnt))\n",
    "    \n",
    "    test_df = rel.iloc[test_index]\n",
    "    \n",
    "    train_index, valid_index = train_test_split(train_index, test_size=0.1)\n",
    "    train_df = rel.iloc[train_index]\n",
    "    valid_df = rel.iloc[valid_index]\n",
    "    \n",
    "    train_m = csr_matrix((train_df.cols_2, (train_df.cols_0, train_df.cols_1)), shape=(user_cnt+1, item_cnt+1))\n",
    "    train_m = utils.get_rep(train_m)\n",
    "    mf = MF(R=train_m, K=20, alpha=0.01, beta=0.001, iterations=10)\n",
    "    mf.train()\n",
    "    \n",
    "    preds = []\n",
    "    gts = []\n",
    "    for index, row in valid_df.iterrows():\n",
    "        u, i, r = row['cols_0'], row['cols_1'], row['cols_2']\n",
    "        pred = mf.get_rating(u-1, i-1)\n",
    "        preds.append(pred)\n",
    "        gts.append(r)\n",
    "    preds = np.array(preds).reshape(-1, 1)\n",
    "    gts = np.array(gts).reshape(-1, 1)\n",
    "    \n",
    "    mse = mean_squared_error(gts, preds)\n",
    "    preds = np.where(preds >= 3, 1, 0)\n",
    "    gts = np.where(preds >=3, 1, 0)\n",
    "    recall = recall_score(gts, preds)\n",
    "    ndcg = ndcg_score(gts.reshape(1, -1), preds.reshape(1, -1))\n",
    "    \n",
    "    mse_list.append(mse)\n",
    "    recall_list.append(recall)\n",
    "    ndcg_list.append(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "brilliant-burlington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.640980773089101"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mse_list)/len(mse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "postal-first",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(recall_list)/len(recall_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "integrated-shelter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ndcg_list)/len(ndcg_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-briefing",
   "metadata": {},
   "source": [
    "## movielens with filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "protective-complaint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 1 ==========\n",
      "Iteration: 10 ; error = 938.4072\n",
      "========= Fold: 2 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; error = 938.4870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 3 ==========\n",
      "Iteration: 10 ; error = 940.0742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 4 ==========\n",
      "Iteration: 10 ; error = 940.5924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Fold: 5 ==========\n",
      "Iteration: 10 ; error = 940.4940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai2019/ne6081064/anaconda3/envs/june/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "fold_cnt = 0\n",
    "\n",
    "mse_list = []\n",
    "recall_list = []\n",
    "ndcg_list = []\n",
    "\n",
    "rel.loc[rel['cols_2'] < 3] = 0\n",
    "\n",
    "for train_index, test_index in kf.split(rel):\n",
    "    \n",
    "    fold_cnt += 1\n",
    "    print(\"========= Fold: {} ==========\".format(fold_cnt))\n",
    "    \n",
    "    test_df = rel.iloc[test_index]\n",
    "    \n",
    "    train_index, valid_index = train_test_split(train_index, test_size=0.1)\n",
    "    train_df = rel.iloc[train_index]\n",
    "    valid_df = rel.iloc[valid_index]\n",
    "    \n",
    "    train_m = csr_matrix((train_df.cols_2, (train_df.cols_0, train_df.cols_1)), shape=(user_cnt+1, item_cnt+1))\n",
    "    train_m = utils.get_rep(train_m)\n",
    "    mf = MF(R=train_m, K=20, alpha=0.01, beta=0.001, iterations=10)\n",
    "    mf.train()\n",
    "    \n",
    "    preds = []\n",
    "    gts = []\n",
    "    for index, row in valid_df.iterrows():\n",
    "        u, i, r = row['cols_0'], row['cols_1'], row['cols_2']\n",
    "        pred = mf.get_rating(u-1, i-1)\n",
    "        preds.append(pred)\n",
    "        gts.append(r)\n",
    "    preds = np.array(preds).reshape(-1, 1)\n",
    "    gts = np.array(gts).reshape(-1, 1)\n",
    "    \n",
    "    mse = mean_squared_error(gts, preds)\n",
    "    preds = np.where(preds >= 3, 1, 0)\n",
    "    gts = np.where(preds >=3, 1, 0)\n",
    "    recall = recall_score(gts, preds)\n",
    "    ndcg = ndcg_score(gts.reshape(1, -1), preds.reshape(1, -1))\n",
    "    \n",
    "    mse_list.append(mse)\n",
    "    recall_list.append(recall)\n",
    "    ndcg_list.append(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "communist-construction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.306930131242586"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mse_list)/len(mse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "committed-marketing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(recall_list)/len(recall_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "increasing-punishment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ndcg_list)/len(ndcg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-whale",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
