{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "everyday-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, ndcg_score, recall_score\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "short-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "\n",
    "from deepctr_torch.inputs import SparseFeat, VarLenSparseFeat, get_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "confidential-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import DIN\n",
    "from deepctr_torch.models import AFM\n",
    "from deepctr_torch.models import WDL\n",
    "from deepctr_torch.models import xDeepFM\n",
    "from deepctr_torch.models import DeepFM\n",
    "from deepctr_torch.models import PNN\n",
    "from deepctr_torch.models import DCN\n",
    "from deepctr_torch.models import CCPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceramic-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accepted-minority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda ready...\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "use_cuda = True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    print('cuda ready...')\n",
    "    device = 'cuda:1'\n",
    "\n",
    "root = os.path.join(os.getcwd(), \"DoubanBook\")\n",
    "rel_p = os.path.join(root, \"user_book.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-continent",
   "metadata": {},
   "source": [
    "### User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ultimate-tooth",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "group, group_i, group_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"user_group.dat\"), user_cnt=13024)\n",
    "location, location_i, location_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"user_location.dat\"), user_cnt=13024)\n",
    "user, user_i, user_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"user_user.dat\"), user_cnt=13024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-philip",
   "metadata": {},
   "source": [
    "### Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "steady-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "year, year_i, year_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"book_year.dat\"), user_cnt=22347)\n",
    "publisher, publisher_i, publisher_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"book_publisher.dat\"), user_cnt=22347)\n",
    "author, author_i, author_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"book_author.dat\"), user_cnt=22347)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-banner",
   "metadata": {},
   "source": [
    "### Interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sized-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = [\"cols_0\", \"cols_1\"] # user_id, movie_id\n",
    "rating = \"cols_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "champion-interval",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cols_0</th>\n",
       "      <th>cols_1</th>\n",
       "      <th>cols_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10855</td>\n",
       "      <td>938</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10027</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>741</td>\n",
       "      <td>2426</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>453</td>\n",
       "      <td>1263</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11665</td>\n",
       "      <td>7717</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cols_0  cols_1  cols_2\n",
       "0   10855     938       4\n",
       "1   10027       3       3\n",
       "2     741    2426       5\n",
       "3     453    1263       4\n",
       "4   11665    7717       5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel = utils.read_file(rel_p)\n",
    "rel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "motivated-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "_group = group[rel.cols_0 -1]\n",
    "_location = location[rel.cols_0 -1]\n",
    "_user = user[rel.cols_0 -1]\n",
    "\n",
    "_year = year[rel.cols_1 -1]\n",
    "_publisher = publisher[rel.cols_1 -1]\n",
    "_author = author[rel.cols_1 -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "celtic-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Label Encoding for sparse features,and process sequence features\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    rel[feat] = lbe.fit_transform(rel[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "maritime-highway",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, rel[feat].nunique(), embedding_dim=4) for feat in sparse_features]\n",
    "\n",
    "varlen_feature_columns = [\n",
    "    VarLenSparseFeat(SparseFeat('group', vocabulary_size=group_i + 1, embedding_dim=4), maxlen=group_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('location', vocabulary_size=location_i + 1, embedding_dim=4), maxlen=location_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('user', vocabulary_size=13024 + 1, embedding_dim=4), maxlen=user_m, combiner='mean'),\n",
    "    \n",
    "    VarLenSparseFeat(SparseFeat('year', vocabulary_size=year_i + 1, embedding_dim=4), maxlen=year_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('publisher', vocabulary_size=publisher_i + 1, embedding_dim=4), maxlen=publisher_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('author', vocabulary_size=author_i + 1, embedding_dim=4), maxlen=author_m, combiner='mean')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "major-vegetable",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-acting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "attached-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fuzzy-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepfm_mse = 0\n",
    "ccpm_mse = 0\n",
    "ipnn_mse = 0\n",
    "opnn_mse = 0\n",
    "wdl_mse = 0\n",
    "dcn_mse = 0\n",
    "xdeepfm_mse = 0\n",
    "afm_mse = 0\n",
    "din_mse = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "found-designation",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepfm_recall = 0\n",
    "ccpm_recall = 0\n",
    "ipnn_recall = 0\n",
    "opnn_recall = 0\n",
    "wdl_recall = 0\n",
    "dcn_recall = 0\n",
    "xdeepfm_recall = 0\n",
    "afm_recall = 0\n",
    "din_recall = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "terminal-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepfm_ndcg = 0\n",
    "ccpm_ndcg = 0\n",
    "ipnn_ndcg = 0\n",
    "opnn_ndcg = 0\n",
    "wdl_ndcg = 0\n",
    "dcn_ndcg = 0\n",
    "xdeepfm_ndcg = 0\n",
    "afm_ndcg = 0\n",
    "din_ndcg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "front-vermont",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================== 1 Fold ==============================\n",
      "\n",
      "\n",
      "\n",
      " Training DeepFM \n",
      "\n",
      "cuda:1\n",
      "Train on 570284 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "135s - loss:  0.7355 - mse:  0.7354 - val_mse:  0.4965\n",
      "Epoch 2/10\n",
      "149s - loss:  0.4834 - mse:  0.4834 - val_mse:  0.4935\n",
      "Epoch 3/10\n",
      "146s - loss:  0.4734 - mse:  0.4733 - val_mse:  0.4899\n",
      "Epoch 4/10\n",
      "147s - loss:  0.4672 - mse:  0.4672 - val_mse:  0.4881\n",
      "Epoch 5/10\n",
      "148s - loss:  0.4614 - mse:  0.4613 - val_mse:  0.4903\n",
      "Epoch 6/10\n",
      "147s - loss:  0.4553 - mse:  0.4552 - val_mse:  0.4886\n",
      "Epoch 7/10\n",
      "126s - loss:  0.4470 - mse:  0.4469 - val_mse:  0.4873\n",
      "Epoch 8/10\n",
      "115s - loss:  0.4363 - mse:  0.4361 - val_mse:  0.4893\n",
      "Epoch 9/10\n",
      "125s - loss:  0.4219 - mse:  0.4216 - val_mse:  0.4982\n",
      "Epoch 10/10\n",
      "116s - loss:  0.4049 - mse:  0.4045 - val_mse:  0.5070\n",
      "\n",
      "\n",
      " Training CCPM \n",
      "\n",
      "cuda:1\n",
      "Train on 570284 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "118s - loss:  0.6663 - mse:  0.6663 - val_mse:  0.4957\n",
      "Epoch 2/10\n",
      "126s - loss:  0.4787 - mse:  0.4787 - val_mse:  0.4878\n",
      "Epoch 3/10\n",
      "146s - loss:  0.4668 - mse:  0.4667 - val_mse:  0.4868\n",
      "Epoch 4/10\n",
      "150s - loss:  0.4601 - mse:  0.4600 - val_mse:  0.4835\n",
      "Epoch 5/10\n",
      "155s - loss:  0.4531 - mse:  0.4530 - val_mse:  0.4927\n",
      "Epoch 6/10\n",
      "152s - loss:  0.4431 - mse:  0.4429 - val_mse:  0.4857\n",
      "Epoch 7/10\n",
      "145s - loss:  0.4291 - mse:  0.4288 - val_mse:  0.4921\n",
      "Epoch 8/10\n",
      "115s - loss:  0.4137 - mse:  0.4134 - val_mse:  0.4954\n",
      "Epoch 9/10\n",
      "128s - loss:  0.3979 - mse:  0.3977 - val_mse:  0.5048\n",
      "Epoch 10/10\n",
      "125s - loss:  0.3846 - mse:  0.3843 - val_mse:  0.5157\n",
      "\n",
      "\n",
      " Training IPMM \n",
      "\n",
      "cuda:1\n",
      "Train on 570284 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "81s - loss:  0.7734 - mse:  0.7733 - val_mse:  0.4927\n",
      "Epoch 2/10\n",
      "70s - loss:  0.4722 - mse:  0.4721 - val_mse:  0.4844\n",
      "Epoch 3/10\n",
      "81s - loss:  0.4526 - mse:  0.4525 - val_mse:  0.4855\n",
      "Epoch 4/10\n",
      "82s - loss:  0.4356 - mse:  0.4355 - val_mse:  0.4930\n",
      "Epoch 5/10\n",
      "70s - loss:  0.4175 - mse:  0.4174 - val_mse:  0.5008\n",
      "Epoch 6/10\n",
      "81s - loss:  0.3973 - mse:  0.3972 - val_mse:  0.5136\n",
      "Epoch 7/10\n",
      "76s - loss:  0.3789 - mse:  0.3787 - val_mse:  0.5226\n",
      "Epoch 8/10\n",
      "77s - loss:  0.3641 - mse:  0.3639 - val_mse:  0.5357\n",
      "Epoch 9/10\n",
      "82s - loss:  0.3521 - mse:  0.3519 - val_mse:  0.5451\n",
      "Epoch 10/10\n",
      "70s - loss:  0.3417 - mse:  0.3415 - val_mse:  0.5587\n",
      "\n",
      "\n",
      " Training OPNN \n",
      "\n",
      "cuda:1\n",
      "Train on 570284 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "71s - loss:  0.7865 - mse:  0.7865 - val_mse:  0.4965\n",
      "Epoch 2/10\n",
      "81s - loss:  0.4793 - mse:  0.4792 - val_mse:  0.4827\n",
      "Epoch 3/10\n",
      "82s - loss:  0.4604 - mse:  0.4604 - val_mse:  0.4797\n",
      "Epoch 4/10\n",
      "70s - loss:  0.4465 - mse:  0.4465 - val_mse:  0.4795\n",
      "Epoch 5/10\n",
      "80s - loss:  0.4352 - mse:  0.4351 - val_mse:  0.4844\n",
      "Epoch 6/10\n",
      "78s - loss:  0.4218 - mse:  0.4217 - val_mse:  0.4908\n",
      "Epoch 7/10\n",
      "75s - loss:  0.4067 - mse:  0.4065 - val_mse:  0.5039\n",
      "Epoch 8/10\n",
      "82s - loss:  0.3900 - mse:  0.3899 - val_mse:  0.5114\n",
      "Epoch 9/10\n",
      "74s - loss:  0.3746 - mse:  0.3744 - val_mse:  0.5206\n",
      "Epoch 10/10\n",
      "78s - loss:  0.3622 - mse:  0.3619 - val_mse:  0.5327\n",
      "\n",
      "\n",
      " Training Wide&Deep \n",
      "\n",
      "cuda:1\n",
      "Train on 570284 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "124s - loss:  0.7364 - mse:  0.7363 - val_mse:  0.4953\n",
      "Epoch 2/10\n",
      "116s - loss:  0.4824 - mse:  0.4823 - val_mse:  0.4919\n",
      "Epoch 3/10\n",
      "122s - loss:  0.4730 - mse:  0.4730 - val_mse:  0.4891\n",
      "Epoch 4/10\n",
      "119s - loss:  0.4685 - mse:  0.4685 - val_mse:  0.4871\n",
      "Epoch 5/10\n",
      "119s - loss:  0.4653 - mse:  0.4652 - val_mse:  0.4888\n",
      "Epoch 6/10\n",
      "118s - loss:  0.4631 - mse:  0.4630 - val_mse:  0.4876\n",
      "Epoch 7/10\n",
      "121s - loss:  0.4611 - mse:  0.4610 - val_mse:  0.4860\n",
      "Epoch 8/10\n",
      "122s - loss:  0.4593 - mse:  0.4591 - val_mse:  0.4850\n",
      "Epoch 9/10\n",
      "116s - loss:  0.4561 - mse:  0.4559 - val_mse:  0.4841\n",
      "Epoch 10/10\n",
      "124s - loss:  0.4491 - mse:  0.4489 - val_mse:  0.4806\n",
      "\n",
      "\n",
      " Training DCN \n",
      "\n",
      "cuda:1\n",
      "Train on 570284 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "129s - loss:  0.7690 - mse:  0.7690 - val_mse:  0.4966\n",
      "Epoch 2/10\n",
      "117s - loss:  0.4820 - mse:  0.4820 - val_mse:  0.4897\n",
      "Epoch 3/10\n",
      "128s - loss:  0.4718 - mse:  0.4718 - val_mse:  0.4876\n",
      "Epoch 4/10\n",
      "125s - loss:  0.4649 - mse:  0.4648 - val_mse:  0.4958\n",
      "Epoch 5/10\n",
      "123s - loss:  0.4564 - mse:  0.4563 - val_mse:  0.4816\n",
      "Epoch 6/10\n",
      "130s - loss:  0.4486 - mse:  0.4485 - val_mse:  0.4817\n",
      "Epoch 7/10\n",
      "130s - loss:  0.4419 - mse:  0.4417 - val_mse:  0.4863\n",
      "Epoch 8/10\n",
      "118s - loss:  0.4358 - mse:  0.4356 - val_mse:  0.4847\n",
      "Epoch 9/10\n",
      "130s - loss:  0.4299 - mse:  0.4297 - val_mse:  0.4874\n",
      "Epoch 10/10\n",
      "130s - loss:  0.4235 - mse:  0.4232 - val_mse:  0.4914\n",
      "\n",
      "\n",
      " Training xDeepFM \n",
      "\n",
      "cuda:1\n",
      "Train on 570284 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "131s - loss:  0.6400 - mse:  0.6400 - val_mse:  0.4955\n",
      "Epoch 2/10\n",
      "120s - loss:  0.4796 - mse:  0.4795 - val_mse:  0.4849\n",
      "Epoch 3/10\n",
      "131s - loss:  0.4633 - mse:  0.4632 - val_mse:  0.4834\n",
      "Epoch 4/10\n",
      "131s - loss:  0.4528 - mse:  0.4528 - val_mse:  0.4877\n",
      "Epoch 5/10\n",
      "130s - loss:  0.4447 - mse:  0.4446 - val_mse:  0.4846\n",
      "Epoch 6/10\n",
      "123s - loss:  0.4358 - mse:  0.4356 - val_mse:  0.4869\n",
      "Epoch 7/10\n",
      "132s - loss:  0.4213 - mse:  0.4211 - val_mse:  0.4925\n",
      "Epoch 8/10\n",
      "132s - loss:  0.4013 - mse:  0.4011 - val_mse:  0.5075\n",
      "Epoch 9/10\n",
      "123s - loss:  0.3802 - mse:  0.3799 - val_mse:  0.5187\n",
      "Epoch 10/10\n",
      "130s - loss:  0.3614 - mse:  0.3612 - val_mse:  0.5310\n",
      "\n",
      "\n",
      " Training AFM \n",
      "\n",
      "cuda:1\n",
      "Train on 570284 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "120s - loss:  2.0517 - mse:  2.0512 - val_mse:  0.5813\n",
      "Epoch 2/10\n",
      "128s - loss:  0.5418 - mse:  0.5415 - val_mse:  0.5226\n",
      "Epoch 3/10\n",
      "117s - loss:  0.4967 - mse:  0.4963 - val_mse:  0.5024\n",
      "Epoch 4/10\n",
      "129s - loss:  0.4767 - mse:  0.4762 - val_mse:  0.4932\n",
      "Epoch 5/10\n",
      "128s - loss:  0.4659 - mse:  0.4654 - val_mse:  0.4898\n",
      "Epoch 6/10\n",
      "117s - loss:  0.4596 - mse:  0.4591 - val_mse:  0.4879\n",
      "Epoch 7/10\n",
      "127s - loss:  0.4558 - mse:  0.4553 - val_mse:  0.4882\n",
      "Epoch 8/10\n",
      "116s - loss:  0.4533 - mse:  0.4527 - val_mse:  0.4879\n",
      "Epoch 9/10\n",
      "128s - loss:  0.4515 - mse:  0.4509 - val_mse:  0.4881\n",
      "Epoch 10/10\n",
      "128s - loss:  0.4503 - mse:  0.4497 - val_mse:  0.4880\n",
      "========================== 2 Fold ==============================\n",
      "\n",
      "\n",
      "\n",
      " Training DeepFM \n",
      "\n",
      "cuda:1\n",
      "Train on 570284 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "127s - loss:  0.7337 - mse:  0.7337 - val_mse:  0.4967\n",
      "Epoch 2/10\n",
      "114s - loss:  0.4830 - mse:  0.4830 - val_mse:  0.4922\n",
      "Epoch 3/10\n",
      "127s - loss:  0.4732 - mse:  0.4731 - val_mse:  0.4895\n",
      "Epoch 4/10\n",
      "121s - loss:  0.4670 - mse:  0.4669 - val_mse:  0.4883\n",
      "Epoch 5/10\n",
      "128s - loss:  0.4611 - mse:  0.4610 - val_mse:  0.4909\n",
      "Epoch 6/10\n",
      "147s - loss:  0.4552 - mse:  0.4551 - val_mse:  0.4891\n",
      "Epoch 7/10\n",
      "155s - loss:  0.4469 - mse:  0.4467 - val_mse:  0.4889\n",
      "Epoch 8/10\n",
      "151s - loss:  0.4364 - mse:  0.4362 - val_mse:  0.4893\n",
      "Epoch 9/10\n",
      "148s - loss:  0.4220 - mse:  0.4217 - val_mse:  0.4985\n",
      "Epoch 10/10\n",
      "137s - loss:  0.4043 - mse:  0.4039 - val_mse:  0.5073\n",
      "\n",
      "\n",
      " Training CCPM \n",
      "\n",
      "cuda:1\n",
      "Train on 570284 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "128s - loss:  0.6654 - mse:  0.6653 - val_mse:  0.4976\n",
      "Epoch 2/10\n",
      "130s - loss:  0.4780 - mse:  0.4779 - val_mse:  0.4868\n",
      "Epoch 3/10\n",
      "117s - loss:  0.4660 - mse:  0.4659 - val_mse:  0.4875\n",
      "Epoch 4/10\n",
      "130s - loss:  0.4588 - mse:  0.4587 - val_mse:  0.4888\n",
      "Epoch 5/10\n",
      "128s - loss:  0.4527 - mse:  0.4526 - val_mse:  0.4891\n",
      "Epoch 6/10\n",
      "117s - loss:  0.4441 - mse:  0.4439 - val_mse:  0.4847\n",
      "Epoch 7/10\n",
      "138s - loss:  0.4323 - mse:  0.4321 - val_mse:  0.4882\n",
      "Epoch 8/10\n",
      "158s - loss:  0.4169 - mse:  0.4167 - val_mse:  0.4974\n",
      "Epoch 9/10\n",
      "151s - loss:  0.4011 - mse:  0.4008 - val_mse:  0.5052\n",
      "Epoch 10/10\n",
      "149s - loss:  0.3861 - mse:  0.3858 - val_mse:  0.5129\n",
      "\n",
      "\n",
      " Training IPMM \n",
      "\n",
      "cuda:1\n",
      "Train on 570284 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "93s - loss:  0.7743 - mse:  0.7743 - val_mse:  0.4916\n",
      "Epoch 2/10\n",
      "93s - loss:  0.4725 - mse:  0.4724 - val_mse:  0.4842\n",
      "Epoch 3/10\n",
      "92s - loss:  0.4530 - mse:  0.4529 - val_mse:  0.4839\n",
      "Epoch 4/10\n",
      "92s - loss:  0.4353 - mse:  0.4352 - val_mse:  0.4941\n",
      "Epoch 5/10\n",
      "93s - loss:  0.4163 - mse:  0.4162 - val_mse:  0.5063\n",
      "Epoch 6/10\n",
      "92s - loss:  0.3967 - mse:  0.3965 - val_mse:  0.5141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "92s - loss:  0.3785 - mse:  0.3783 - val_mse:  0.5253\n",
      "Epoch 8/10\n",
      "92s - loss:  0.3641 - mse:  0.3639 - val_mse:  0.5374\n",
      "Epoch 9/10\n",
      "92s - loss:  0.3521 - mse:  0.3519 - val_mse:  0.5487\n",
      "Epoch 10/10\n",
      "94s - loss:  0.3424 - mse:  0.3422 - val_mse:  0.5593\n",
      "\n",
      "\n",
      " Training OPNN \n",
      "\n",
      "cuda:1\n",
      "Train on 570284 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "92s - loss:  0.7858 - mse:  0.7857 - val_mse:  0.4967\n",
      "Epoch 2/10\n",
      "93s - loss:  0.4788 - mse:  0.4788 - val_mse:  0.4846\n",
      "Epoch 3/10\n",
      "94s - loss:  0.4595 - mse:  0.4594 - val_mse:  0.4904\n",
      "Epoch 4/10\n",
      "93s - loss:  0.4459 - mse:  0.4458 - val_mse:  0.4809\n",
      "Epoch 5/10\n",
      "92s - loss:  0.4338 - mse:  0.4337 - val_mse:  0.4854\n",
      "Epoch 6/10\n",
      "92s - loss:  0.4196 - mse:  0.4195 - val_mse:  0.4919\n",
      "Epoch 7/10\n",
      "94s - loss:  0.4033 - mse:  0.4032 - val_mse:  0.5058\n",
      "Epoch 8/10\n",
      "94s - loss:  0.3871 - mse:  0.3870 - val_mse:  0.5121\n",
      "Epoch 9/10\n",
      "91s - loss:  0.3729 - mse:  0.3727 - val_mse:  0.5231\n",
      "Epoch 10/10\n",
      "89s - loss:  0.3609 - mse:  0.3607 - val_mse:  0.5344\n",
      "\n",
      "\n",
      " Training Wide&Deep \n",
      "\n",
      "cuda:1\n",
      "Train on 570284 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "147s - loss:  0.7347 - mse:  0.7346 - val_mse:  0.4955\n",
      "Epoch 2/10\n",
      "145s - loss:  0.4819 - mse:  0.4819 - val_mse:  0.4907\n",
      "Epoch 3/10\n",
      "145s - loss:  0.4729 - mse:  0.4728 - val_mse:  0.4889\n",
      "Epoch 4/10\n",
      "147s - loss:  0.4683 - mse:  0.4682 - val_mse:  0.4880\n",
      "Epoch 5/10\n",
      "146s - loss:  0.4651 - mse:  0.4650 - val_mse:  0.4901\n",
      "Epoch 6/10\n",
      "150s - loss:  0.4629 - mse:  0.4628 - val_mse:  0.4887\n",
      "Epoch 7/10\n",
      "154s - loss:  0.4609 - mse:  0.4607 - val_mse:  0.4880\n",
      "Epoch 8/10\n",
      "145s - loss:  0.4592 - mse:  0.4591 - val_mse:  0.4854\n",
      "Epoch 9/10\n",
      "146s - loss:  0.4557 - mse:  0.4555 - val_mse:  0.4842\n",
      "Epoch 10/10\n",
      "147s - loss:  0.4486 - mse:  0.4484 - val_mse:  0.4827\n",
      "\n",
      "\n",
      " Training DCN \n",
      "\n",
      "cuda:1\n",
      "Train on 570284 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "138s - loss:  0.7686 - mse:  0.7686 - val_mse:  0.4969\n",
      "Epoch 2/10\n",
      "130s - loss:  0.4815 - mse:  0.4815 - val_mse:  0.4921\n",
      "Epoch 3/10\n",
      "130s - loss:  0.4716 - mse:  0.4715 - val_mse:  0.4887\n",
      "Epoch 4/10\n",
      "131s - loss:  0.4647 - mse:  0.4646 - val_mse:  0.4884\n",
      "Epoch 5/10\n",
      "120s - loss:  0.4560 - mse:  0.4559 - val_mse:  0.4826\n",
      "Epoch 6/10\n",
      "129s - loss:  0.4483 - mse:  0.4482 - val_mse:  0.4835\n",
      "Epoch 7/10\n",
      "131s - loss:  0.4415 - mse:  0.4413 - val_mse:  0.4856\n",
      "Epoch 8/10\n",
      "130s - loss:  0.4353 - mse:  0.4351 - val_mse:  0.4839\n",
      "Epoch 9/10\n",
      "119s - loss:  0.4296 - mse:  0.4293 - val_mse:  0.4874\n",
      "Epoch 10/10\n",
      "130s - loss:  0.4236 - mse:  0.4234 - val_mse:  0.4905\n",
      "\n",
      "\n",
      " Training xDeepFM \n",
      "\n",
      "cuda:1\n",
      "Train on 570284 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "130s - loss:  0.6392 - mse:  0.6391 - val_mse:  0.4962\n",
      "Epoch 2/10\n",
      "132s - loss:  0.4791 - mse:  0.4791 - val_mse:  0.4855\n",
      "Epoch 3/10\n",
      "132s - loss:  0.4630 - mse:  0.4629 - val_mse:  0.4843\n",
      "Epoch 4/10\n",
      "132s - loss:  0.4522 - mse:  0.4521 - val_mse:  0.4847\n",
      "Epoch 5/10\n",
      "121s - loss:  0.4433 - mse:  0.4432 - val_mse:  0.4868\n",
      "Epoch 6/10\n",
      "131s - loss:  0.4308 - mse:  0.4306 - val_mse:  0.4886\n",
      "Epoch 7/10\n",
      "133s - loss:  0.4114 - mse:  0.4112 - val_mse:  0.4995\n",
      "Epoch 8/10\n",
      "132s - loss:  0.3883 - mse:  0.3881 - val_mse:  0.5107\n",
      "Epoch 9/10\n",
      "125s - loss:  0.3656 - mse:  0.3654 - val_mse:  0.5294\n",
      "Epoch 10/10\n",
      "127s - loss:  0.3477 - mse:  0.3474 - val_mse:  0.5363\n",
      "\n",
      "\n",
      " Training AFM \n",
      "\n",
      "cuda:1\n",
      "Train on 570284 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "117s - loss:  2.0492 - mse:  2.0487 - val_mse:  0.5817\n",
      "Epoch 2/10\n",
      "127s - loss:  0.5416 - mse:  0.5412 - val_mse:  0.5227\n",
      "Epoch 3/10\n",
      "128s - loss:  0.4964 - mse:  0.4960 - val_mse:  0.5024\n",
      "Epoch 4/10\n",
      "117s - loss:  0.4763 - mse:  0.4759 - val_mse:  0.4936\n",
      "Epoch 5/10\n",
      "128s - loss:  0.4656 - mse:  0.4651 - val_mse:  0.4905\n",
      "Epoch 6/10\n",
      "129s - loss:  0.4594 - mse:  0.4589 - val_mse:  0.4886\n",
      "Epoch 7/10\n",
      "117s - loss:  0.4555 - mse:  0.4549 - val_mse:  0.4883\n",
      "Epoch 8/10\n",
      "128s - loss:  0.4530 - mse:  0.4525 - val_mse:  0.4883\n",
      "Epoch 9/10\n",
      "128s - loss:  0.4512 - mse:  0.4507 - val_mse:  0.4884\n",
      "Epoch 10/10\n",
      "118s - loss:  0.4500 - mse:  0.4494 - val_mse:  0.4890\n",
      "========================== 3 Fold ==============================\n",
      "\n",
      "\n",
      "\n",
      " Training DeepFM \n",
      "\n",
      "cuda:1\n",
      "Train on 570285 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "127s - loss:  0.7377 - mse:  0.7376 - val_mse:  0.4986\n",
      "Epoch 2/10\n",
      "115s - loss:  0.4830 - mse:  0.4830 - val_mse:  0.4969\n",
      "Epoch 3/10\n",
      "127s - loss:  0.4728 - mse:  0.4727 - val_mse:  0.4892\n",
      "Epoch 4/10\n",
      "125s - loss:  0.4665 - mse:  0.4665 - val_mse:  0.4906\n",
      "Epoch 5/10\n",
      "119s - loss:  0.4608 - mse:  0.4607 - val_mse:  0.4955\n",
      "Epoch 6/10\n",
      "128s - loss:  0.4547 - mse:  0.4545 - val_mse:  0.4897\n",
      "Epoch 7/10\n",
      "127s - loss:  0.4474 - mse:  0.4472 - val_mse:  0.4875\n",
      "Epoch 8/10\n",
      "117s - loss:  0.4364 - mse:  0.4362 - val_mse:  0.4879\n",
      "Epoch 9/10\n",
      "128s - loss:  0.4239 - mse:  0.4236 - val_mse:  0.4919\n",
      "Epoch 10/10\n",
      "123s - loss:  0.4074 - mse:  0.4071 - val_mse:  0.5024\n",
      "\n",
      "\n",
      " Training CCPM \n",
      "\n",
      "cuda:1\n",
      "Train on 570285 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "129s - loss:  0.6656 - mse:  0.6656 - val_mse:  0.4981\n",
      "Epoch 2/10\n",
      "117s - loss:  0.4778 - mse:  0.4777 - val_mse:  0.4881\n",
      "Epoch 3/10\n",
      "129s - loss:  0.4661 - mse:  0.4660 - val_mse:  0.4852\n",
      "Epoch 4/10\n",
      "128s - loss:  0.4594 - mse:  0.4593 - val_mse:  0.4846\n",
      "Epoch 5/10\n",
      "120s - loss:  0.4527 - mse:  0.4526 - val_mse:  0.4971\n",
      "Epoch 6/10\n",
      "125s - loss:  0.4446 - mse:  0.4444 - val_mse:  0.4843\n",
      "Epoch 7/10\n",
      "112s - loss:  0.4332 - mse:  0.4330 - val_mse:  0.4877\n",
      "Epoch 8/10\n",
      "104s - loss:  0.4193 - mse:  0.4191 - val_mse:  0.5032\n",
      "Epoch 9/10\n",
      "100s - loss:  0.4040 - mse:  0.4037 - val_mse:  0.5019\n",
      "Epoch 10/10\n",
      "101s - loss:  0.3894 - mse:  0.3891 - val_mse:  0.5162\n",
      "\n",
      "\n",
      " Training IPMM \n",
      "\n",
      "cuda:1\n",
      "Train on 570285 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "62s - loss:  0.7733 - mse:  0.7733 - val_mse:  0.4926\n",
      "Epoch 2/10\n",
      "71s - loss:  0.4723 - mse:  0.4723 - val_mse:  0.4843\n",
      "Epoch 3/10\n",
      "62s - loss:  0.4520 - mse:  0.4520 - val_mse:  0.4862\n",
      "Epoch 4/10\n",
      "72s - loss:  0.4361 - mse:  0.4360 - val_mse:  0.4879\n",
      "Epoch 5/10\n",
      "61s - loss:  0.4195 - mse:  0.4194 - val_mse:  0.4989\n",
      "Epoch 6/10\n",
      "72s - loss:  0.4004 - mse:  0.4002 - val_mse:  0.5085\n",
      "Epoch 7/10\n",
      "62s - loss:  0.3813 - mse:  0.3812 - val_mse:  0.5270\n",
      "Epoch 8/10\n",
      "69s - loss:  0.3660 - mse:  0.3659 - val_mse:  0.5326\n",
      "Epoch 9/10\n",
      "64s - loss:  0.3532 - mse:  0.3530 - val_mse:  0.5398\n",
      "Epoch 10/10\n",
      "65s - loss:  0.3430 - mse:  0.3428 - val_mse:  0.5556\n",
      "\n",
      "\n",
      " Training OPNN \n",
      "\n",
      "cuda:1\n",
      "Train on 570285 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "62s - loss:  0.7866 - mse:  0.7866 - val_mse:  0.4964\n",
      "Epoch 2/10\n",
      "72s - loss:  0.4788 - mse:  0.4788 - val_mse:  0.4831\n",
      "Epoch 3/10\n",
      "63s - loss:  0.4596 - mse:  0.4596 - val_mse:  0.4806\n",
      "Epoch 4/10\n",
      "72s - loss:  0.4461 - mse:  0.4460 - val_mse:  0.4820\n",
      "Epoch 5/10\n",
      "63s - loss:  0.4320 - mse:  0.4319 - val_mse:  0.4865\n",
      "Epoch 6/10\n",
      "72s - loss:  0.4148 - mse:  0.4147 - val_mse:  0.4942\n",
      "Epoch 7/10\n",
      "63s - loss:  0.3982 - mse:  0.3981 - val_mse:  0.5046\n",
      "Epoch 8/10\n",
      "72s - loss:  0.3830 - mse:  0.3828 - val_mse:  0.5129\n",
      "Epoch 9/10\n",
      "62s - loss:  0.3691 - mse:  0.3689 - val_mse:  0.5313\n",
      "Epoch 10/10\n",
      "69s - loss:  0.3570 - mse:  0.3568 - val_mse:  0.5357\n",
      "\n",
      "\n",
      " Training Wide&Deep \n",
      "\n",
      "cuda:1\n",
      "Train on 570285 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "97s - loss:  0.7385 - mse:  0.7385 - val_mse:  0.4976\n",
      "Epoch 2/10\n",
      "97s - loss:  0.4819 - mse:  0.4819 - val_mse:  0.4958\n",
      "Epoch 3/10\n",
      "97s - loss:  0.4724 - mse:  0.4724 - val_mse:  0.4880\n",
      "Epoch 4/10\n",
      "105s - loss:  0.4679 - mse:  0.4679 - val_mse:  0.4901\n",
      "Epoch 5/10\n",
      "99s - loss:  0.4649 - mse:  0.4648 - val_mse:  0.4944\n",
      "Epoch 6/10\n",
      "98s - loss:  0.4623 - mse:  0.4622 - val_mse:  0.4905\n",
      "Epoch 7/10\n",
      "97s - loss:  0.4604 - mse:  0.4602 - val_mse:  0.4863\n",
      "Epoch 8/10\n",
      "96s - loss:  0.4584 - mse:  0.4583 - val_mse:  0.4859\n",
      "Epoch 9/10\n",
      "108s - loss:  0.4556 - mse:  0.4554 - val_mse:  0.4829\n",
      "Epoch 10/10\n",
      "98s - loss:  0.4491 - mse:  0.4489 - val_mse:  0.4807\n",
      "\n",
      "\n",
      " Training DCN \n",
      "\n",
      "cuda:1\n",
      "Train on 570285 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "103s - loss:  0.7686 - mse:  0.7685 - val_mse:  0.4974\n",
      "Epoch 2/10\n",
      "111s - loss:  0.4818 - mse:  0.4818 - val_mse:  0.4900\n",
      "Epoch 3/10\n",
      "101s - loss:  0.4713 - mse:  0.4712 - val_mse:  0.4905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "101s - loss:  0.4643 - mse:  0.4642 - val_mse:  0.4841\n",
      "Epoch 5/10\n",
      "112s - loss:  0.4559 - mse:  0.4558 - val_mse:  0.4820\n",
      "Epoch 6/10\n",
      "102s - loss:  0.4480 - mse:  0.4479 - val_mse:  0.4851\n",
      "Epoch 7/10\n",
      "102s - loss:  0.4411 - mse:  0.4409 - val_mse:  0.4864\n",
      "Epoch 8/10\n",
      "113s - loss:  0.4349 - mse:  0.4347 - val_mse:  0.4843\n",
      "Epoch 9/10\n",
      "102s - loss:  0.4291 - mse:  0.4289 - val_mse:  0.4852\n",
      "Epoch 10/10\n",
      "102s - loss:  0.4236 - mse:  0.4233 - val_mse:  0.4886\n",
      "\n",
      "\n",
      " Training xDeepFM \n",
      "\n",
      "cuda:1\n",
      "Train on 570285 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "105s - loss:  0.6382 - mse:  0.6382 - val_mse:  0.4952\n",
      "Epoch 2/10\n",
      "116s - loss:  0.4786 - mse:  0.4786 - val_mse:  0.4961\n",
      "Epoch 3/10\n",
      "105s - loss:  0.4627 - mse:  0.4626 - val_mse:  0.4845\n",
      "Epoch 4/10\n",
      "114s - loss:  0.4523 - mse:  0.4523 - val_mse:  0.4836\n",
      "Epoch 5/10\n",
      "108s - loss:  0.4441 - mse:  0.4440 - val_mse:  0.4829\n",
      "Epoch 6/10\n",
      "104s - loss:  0.4348 - mse:  0.4346 - val_mse:  0.4857\n",
      "Epoch 7/10\n",
      "115s - loss:  0.4197 - mse:  0.4195 - val_mse:  0.4928\n",
      "Epoch 8/10\n",
      "105s - loss:  0.3988 - mse:  0.3986 - val_mse:  0.5026\n",
      "Epoch 9/10\n",
      "110s - loss:  0.3774 - mse:  0.3771 - val_mse:  0.5216\n",
      "Epoch 10/10\n",
      "110s - loss:  0.3583 - mse:  0.3580 - val_mse:  0.5389\n",
      "\n",
      "\n",
      " Training AFM \n",
      "\n",
      "cuda:1\n",
      "Train on 570285 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "111s - loss:  2.0512 - mse:  2.0508 - val_mse:  0.5813\n",
      "Epoch 2/10\n",
      "100s - loss:  0.5410 - mse:  0.5406 - val_mse:  0.5224\n",
      "Epoch 3/10\n",
      "99s - loss:  0.4960 - mse:  0.4956 - val_mse:  0.5024\n",
      "Epoch 4/10\n",
      "101s - loss:  0.4759 - mse:  0.4754 - val_mse:  0.4939\n",
      "Epoch 5/10\n",
      "109s - loss:  0.4652 - mse:  0.4647 - val_mse:  0.4900\n",
      "Epoch 6/10\n",
      "99s - loss:  0.4590 - mse:  0.4585 - val_mse:  0.4884\n",
      "Epoch 7/10\n",
      "99s - loss:  0.4552 - mse:  0.4547 - val_mse:  0.4871\n",
      "Epoch 8/10\n",
      "100s - loss:  0.4527 - mse:  0.4521 - val_mse:  0.4873\n",
      "Epoch 9/10\n",
      "109s - loss:  0.4509 - mse:  0.4504 - val_mse:  0.4875\n",
      "Epoch 10/10\n",
      "100s - loss:  0.4497 - mse:  0.4491 - val_mse:  0.4880\n",
      "========================== 4 Fold ==============================\n",
      "\n",
      "\n",
      "\n",
      " Training DeepFM \n",
      "\n",
      "cuda:1\n",
      "Train on 570285 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "108s - loss:  0.7373 - mse:  0.7373 - val_mse:  0.5000\n",
      "Epoch 2/10\n",
      "99s - loss:  0.4823 - mse:  0.4823 - val_mse:  0.4927\n",
      "Epoch 3/10\n",
      "98s - loss:  0.4722 - mse:  0.4722 - val_mse:  0.4879\n",
      "Epoch 4/10\n",
      "99s - loss:  0.4651 - mse:  0.4650 - val_mse:  0.4938\n",
      "Epoch 5/10\n",
      "107s - loss:  0.4577 - mse:  0.4576 - val_mse:  0.4960\n",
      "Epoch 6/10\n",
      "101s - loss:  0.4497 - mse:  0.4495 - val_mse:  0.4914\n",
      "Epoch 7/10\n",
      "99s - loss:  0.4410 - mse:  0.4408 - val_mse:  0.4863\n",
      "Epoch 8/10\n",
      "99s - loss:  0.4305 - mse:  0.4302 - val_mse:  0.4922\n",
      "Epoch 9/10\n",
      "107s - loss:  0.4160 - mse:  0.4158 - val_mse:  0.4984\n",
      "Epoch 10/10\n",
      "101s - loss:  0.3995 - mse:  0.3992 - val_mse:  0.5080\n",
      "\n",
      "\n",
      " Training CCPM \n",
      "\n",
      "cuda:1\n",
      "Train on 570285 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "82s - loss:  0.6644 - mse:  0.6644 - val_mse:  0.4961\n",
      "Epoch 2/10\n",
      "61s - loss:  0.4770 - mse:  0.4770 - val_mse:  0.4897\n",
      "Epoch 3/10\n",
      "60s - loss:  0.4648 - mse:  0.4647 - val_mse:  0.4844\n",
      "Epoch 4/10\n",
      "64s - loss:  0.4572 - mse:  0.4571 - val_mse:  0.4855\n",
      "Epoch 5/10\n",
      "61s - loss:  0.4489 - mse:  0.4488 - val_mse:  0.5087\n",
      "Epoch 6/10\n",
      "61s - loss:  0.4382 - mse:  0.4380 - val_mse:  0.4901\n",
      "Epoch 7/10\n",
      "58s - loss:  0.4242 - mse:  0.4240 - val_mse:  0.4935\n",
      "Epoch 8/10\n",
      "62s - loss:  0.4083 - mse:  0.4080 - val_mse:  0.5141\n",
      "Epoch 9/10\n",
      "60s - loss:  0.3922 - mse:  0.3919 - val_mse:  0.5133\n",
      "Epoch 10/10\n",
      "60s - loss:  0.3785 - mse:  0.3782 - val_mse:  0.5214\n",
      "\n",
      "\n",
      " Training IPMM \n",
      "\n",
      "cuda:1\n",
      "Train on 570285 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "39s - loss:  0.7723 - mse:  0.7723 - val_mse:  0.4932\n",
      "Epoch 2/10\n",
      "38s - loss:  0.4714 - mse:  0.4714 - val_mse:  0.4844\n",
      "Epoch 3/10\n",
      "37s - loss:  0.4519 - mse:  0.4518 - val_mse:  0.4853\n",
      "Epoch 4/10\n",
      "38s - loss:  0.4340 - mse:  0.4339 - val_mse:  0.4899\n",
      "Epoch 5/10\n",
      "38s - loss:  0.4146 - mse:  0.4145 - val_mse:  0.4996\n",
      "Epoch 6/10\n",
      "39s - loss:  0.3942 - mse:  0.3941 - val_mse:  0.5144\n",
      "Epoch 7/10\n",
      "39s - loss:  0.3762 - mse:  0.3760 - val_mse:  0.5262\n",
      "Epoch 8/10\n",
      "37s - loss:  0.3623 - mse:  0.3621 - val_mse:  0.5380\n",
      "Epoch 9/10\n",
      "38s - loss:  0.3504 - mse:  0.3502 - val_mse:  0.5471\n",
      "Epoch 10/10\n",
      "37s - loss:  0.3407 - mse:  0.3405 - val_mse:  0.5584\n",
      "\n",
      "\n",
      " Training OPNN \n",
      "\n",
      "cuda:1\n",
      "Train on 570285 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "39s - loss:  0.7873 - mse:  0.7873 - val_mse:  0.4976\n",
      "Epoch 2/10\n",
      "42s - loss:  0.4786 - mse:  0.4786 - val_mse:  0.4851\n",
      "Epoch 3/10\n",
      "40s - loss:  0.4594 - mse:  0.4593 - val_mse:  0.4825\n",
      "Epoch 4/10\n",
      "40s - loss:  0.4466 - mse:  0.4466 - val_mse:  0.4814\n",
      "Epoch 5/10\n",
      "39s - loss:  0.4356 - mse:  0.4355 - val_mse:  0.4821\n",
      "Epoch 6/10\n",
      "40s - loss:  0.4219 - mse:  0.4218 - val_mse:  0.4914\n",
      "Epoch 7/10\n",
      "39s - loss:  0.4066 - mse:  0.4065 - val_mse:  0.4980\n",
      "Epoch 8/10\n",
      "39s - loss:  0.3901 - mse:  0.3899 - val_mse:  0.5106\n",
      "Epoch 9/10\n",
      "39s - loss:  0.3746 - mse:  0.3744 - val_mse:  0.5295\n",
      "Epoch 10/10\n",
      "41s - loss:  0.3613 - mse:  0.3611 - val_mse:  0.5359\n",
      "\n",
      "\n",
      " Training Wide&Deep \n",
      "\n",
      "cuda:1\n",
      "Train on 570285 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "59s - loss:  0.7378 - mse:  0.7378 - val_mse:  0.4992\n",
      "Epoch 2/10\n",
      "61s - loss:  0.4815 - mse:  0.4815 - val_mse:  0.4922\n",
      "Epoch 3/10\n",
      "59s - loss:  0.4724 - mse:  0.4723 - val_mse:  0.4875\n",
      "Epoch 4/10\n",
      "58s - loss:  0.4675 - mse:  0.4675 - val_mse:  0.4935\n",
      "Epoch 5/10\n",
      "59s - loss:  0.4645 - mse:  0.4644 - val_mse:  0.4967\n",
      "Epoch 6/10\n",
      "61s - loss:  0.4619 - mse:  0.4618 - val_mse:  0.4927\n",
      "Epoch 7/10\n",
      "55s - loss:  0.4600 - mse:  0.4599 - val_mse:  0.4858\n",
      "Epoch 8/10\n",
      "59s - loss:  0.4584 - mse:  0.4583 - val_mse:  0.4889\n",
      "Epoch 9/10\n",
      "58s - loss:  0.4556 - mse:  0.4554 - val_mse:  0.4833\n",
      "Epoch 10/10\n",
      "55s - loss:  0.4492 - mse:  0.4490 - val_mse:  0.4837\n",
      "\n",
      "\n",
      " Training DCN \n",
      "\n",
      "cuda:1\n",
      "Train on 570285 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "63s - loss:  0.7677 - mse:  0.7676 - val_mse:  0.4970\n",
      "Epoch 2/10\n",
      "63s - loss:  0.4814 - mse:  0.4814 - val_mse:  0.4905\n",
      "Epoch 3/10\n",
      "62s - loss:  0.4709 - mse:  0.4709 - val_mse:  0.4899\n",
      "Epoch 4/10\n",
      "63s - loss:  0.4635 - mse:  0.4634 - val_mse:  0.4839\n",
      "Epoch 5/10\n",
      "64s - loss:  0.4551 - mse:  0.4550 - val_mse:  0.4817\n",
      "Epoch 6/10\n",
      "64s - loss:  0.4470 - mse:  0.4468 - val_mse:  0.4828\n",
      "Epoch 7/10\n",
      "60s - loss:  0.4404 - mse:  0.4402 - val_mse:  0.4824\n",
      "Epoch 8/10\n",
      "61s - loss:  0.4347 - mse:  0.4345 - val_mse:  0.4844\n",
      "Epoch 9/10\n",
      "60s - loss:  0.4288 - mse:  0.4286 - val_mse:  0.4850\n",
      "Epoch 10/10\n",
      "61s - loss:  0.4234 - mse:  0.4232 - val_mse:  0.4885\n",
      "\n",
      "\n",
      " Training xDeepFM \n",
      "\n",
      "cuda:1\n",
      "Train on 570285 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "64s - loss:  0.6387 - mse:  0.6387 - val_mse:  0.4960\n",
      "Epoch 2/10\n",
      "65s - loss:  0.4775 - mse:  0.4775 - val_mse:  0.4924\n",
      "Epoch 3/10\n",
      "64s - loss:  0.4623 - mse:  0.4622 - val_mse:  0.4843\n",
      "Epoch 4/10\n",
      "62s - loss:  0.4518 - mse:  0.4517 - val_mse:  0.4830\n",
      "Epoch 5/10\n",
      "67s - loss:  0.4435 - mse:  0.4434 - val_mse:  0.4820\n",
      "Epoch 6/10\n",
      "65s - loss:  0.4329 - mse:  0.4327 - val_mse:  0.4853\n",
      "Epoch 7/10\n",
      "65s - loss:  0.4158 - mse:  0.4157 - val_mse:  0.4917\n",
      "Epoch 8/10\n",
      "65s - loss:  0.3943 - mse:  0.3941 - val_mse:  0.5019\n",
      "Epoch 9/10\n",
      "63s - loss:  0.3730 - mse:  0.3728 - val_mse:  0.5184\n",
      "Epoch 10/10\n",
      "64s - loss:  0.3545 - mse:  0.3542 - val_mse:  0.5316\n",
      "\n",
      "\n",
      " Training AFM \n",
      "\n",
      "cuda:1\n",
      "Train on 570285 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "62s - loss:  2.0509 - mse:  2.0505 - val_mse:  0.5812\n",
      "Epoch 2/10\n",
      "62s - loss:  0.5411 - mse:  0.5408 - val_mse:  0.5230\n",
      "Epoch 3/10\n",
      "62s - loss:  0.4960 - mse:  0.4956 - val_mse:  0.5025\n",
      "Epoch 4/10\n",
      "58s - loss:  0.4757 - mse:  0.4753 - val_mse:  0.4944\n",
      "Epoch 5/10\n",
      "60s - loss:  0.4650 - mse:  0.4645 - val_mse:  0.4902\n",
      "Epoch 6/10\n",
      "62s - loss:  0.4588 - mse:  0.4583 - val_mse:  0.4886\n",
      "Epoch 7/10\n",
      "61s - loss:  0.4548 - mse:  0.4543 - val_mse:  0.4874\n",
      "Epoch 8/10\n",
      "60s - loss:  0.4524 - mse:  0.4518 - val_mse:  0.4873\n",
      "Epoch 9/10\n",
      "57s - loss:  0.4505 - mse:  0.4500 - val_mse:  0.4880\n",
      "Epoch 10/10\n",
      "63s - loss:  0.4494 - mse:  0.4488 - val_mse:  0.4878\n",
      "========================== 5 Fold ==============================\n",
      "\n",
      "\n",
      "\n",
      " Training DeepFM \n",
      "\n",
      "cuda:1\n",
      "Train on 570285 samples, validate on 63365 samples, 2228 steps per epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "59s - loss:  0.7347 - mse:  0.7347 - val_mse:  0.5070\n",
      "Epoch 2/10\n",
      "61s - loss:  0.4820 - mse:  0.4820 - val_mse:  0.4981\n",
      "Epoch 3/10\n",
      "58s - loss:  0.4721 - mse:  0.4721 - val_mse:  0.4976\n",
      "Epoch 4/10\n",
      "58s - loss:  0.4657 - mse:  0.4656 - val_mse:  0.4993\n",
      "Epoch 5/10\n",
      "57s - loss:  0.4600 - mse:  0.4599 - val_mse:  0.5013\n",
      "Epoch 6/10\n",
      "60s - loss:  0.4543 - mse:  0.4542 - val_mse:  0.5007\n",
      "Epoch 7/10\n",
      "62s - loss:  0.4477 - mse:  0.4475 - val_mse:  0.4959\n",
      "Epoch 8/10\n",
      "58s - loss:  0.4372 - mse:  0.4370 - val_mse:  0.4983\n",
      "Epoch 9/10\n",
      "58s - loss:  0.4231 - mse:  0.4228 - val_mse:  0.5042\n",
      "Epoch 10/10\n",
      "60s - loss:  0.4060 - mse:  0.4056 - val_mse:  0.5152\n",
      "\n",
      "\n",
      " Training CCPM \n",
      "\n",
      "cuda:1\n",
      "Train on 570285 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "57s - loss:  0.6640 - mse:  0.6640 - val_mse:  0.5015\n",
      "Epoch 2/10\n",
      "58s - loss:  0.4765 - mse:  0.4765 - val_mse:  0.4978\n",
      "Epoch 3/10\n",
      "63s - loss:  0.4649 - mse:  0.4648 - val_mse:  0.4927\n",
      "Epoch 4/10\n",
      "61s - loss:  0.4574 - mse:  0.4573 - val_mse:  0.4935\n",
      "Epoch 5/10\n",
      "58s - loss:  0.4500 - mse:  0.4498 - val_mse:  0.5023\n",
      "Epoch 6/10\n",
      "58s - loss:  0.4411 - mse:  0.4410 - val_mse:  0.4986\n",
      "Epoch 7/10\n",
      "59s - loss:  0.4293 - mse:  0.4291 - val_mse:  0.5026\n",
      "Epoch 8/10\n",
      "60s - loss:  0.4152 - mse:  0.4149 - val_mse:  0.5166\n",
      "Epoch 9/10\n",
      "57s - loss:  0.3997 - mse:  0.3994 - val_mse:  0.5191\n",
      "Epoch 10/10\n",
      "61s - loss:  0.3864 - mse:  0.3861 - val_mse:  0.5309\n",
      "\n",
      "\n",
      " Training IPMM \n",
      "\n",
      "cuda:1\n",
      "Train on 570285 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "38s - loss:  0.7728 - mse:  0.7728 - val_mse:  0.5019\n",
      "Epoch 2/10\n",
      "37s - loss:  0.4717 - mse:  0.4717 - val_mse:  0.4902\n",
      "Epoch 3/10\n",
      "39s - loss:  0.4520 - mse:  0.4519 - val_mse:  0.4920\n",
      "Epoch 4/10\n",
      "38s - loss:  0.4338 - mse:  0.4337 - val_mse:  0.4982\n",
      "Epoch 5/10\n",
      "37s - loss:  0.4140 - mse:  0.4139 - val_mse:  0.5091\n",
      "Epoch 6/10\n",
      "37s - loss:  0.3939 - mse:  0.3938 - val_mse:  0.5218\n",
      "Epoch 7/10\n",
      "38s - loss:  0.3762 - mse:  0.3760 - val_mse:  0.5352\n",
      "Epoch 8/10\n",
      "39s - loss:  0.3620 - mse:  0.3618 - val_mse:  0.5476\n",
      "Epoch 9/10\n",
      "40s - loss:  0.3500 - mse:  0.3498 - val_mse:  0.5521\n",
      "Epoch 10/10\n",
      "39s - loss:  0.3399 - mse:  0.3397 - val_mse:  0.5671\n",
      "\n",
      "\n",
      " Training OPNN \n",
      "\n",
      "cuda:1\n",
      "Train on 570285 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "40s - loss:  0.7864 - mse:  0.7864 - val_mse:  0.5053\n",
      "Epoch 2/10\n",
      "37s - loss:  0.4777 - mse:  0.4777 - val_mse:  0.4914\n",
      "Epoch 3/10\n",
      "39s - loss:  0.4588 - mse:  0.4588 - val_mse:  0.4975\n",
      "Epoch 4/10\n",
      "37s - loss:  0.4453 - mse:  0.4453 - val_mse:  0.4898\n",
      "Epoch 5/10\n",
      "40s - loss:  0.4317 - mse:  0.4317 - val_mse:  0.4942\n",
      "Epoch 6/10\n",
      "37s - loss:  0.4160 - mse:  0.4159 - val_mse:  0.5028\n",
      "Epoch 7/10\n",
      "40s - loss:  0.4005 - mse:  0.4004 - val_mse:  0.5115\n",
      "Epoch 8/10\n",
      "40s - loss:  0.3853 - mse:  0.3851 - val_mse:  0.5249\n",
      "Epoch 9/10\n",
      "39s - loss:  0.3712 - mse:  0.3710 - val_mse:  0.5371\n",
      "Epoch 10/10\n",
      "37s - loss:  0.3588 - mse:  0.3586 - val_mse:  0.5465\n",
      "\n",
      "\n",
      " Training Wide&Deep \n",
      "\n",
      "cuda:1\n",
      "Train on 570285 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "53s - loss:  0.7358 - mse:  0.7358 - val_mse:  0.5060\n",
      "Epoch 2/10\n",
      "55s - loss:  0.4809 - mse:  0.4809 - val_mse:  0.4972\n",
      "Epoch 3/10\n",
      "56s - loss:  0.4718 - mse:  0.4717 - val_mse:  0.4970\n",
      "Epoch 4/10\n",
      "54s - loss:  0.4670 - mse:  0.4669 - val_mse:  0.4985\n",
      "Epoch 5/10\n",
      "57s - loss:  0.4639 - mse:  0.4638 - val_mse:  0.5016\n",
      "Epoch 6/10\n",
      "57s - loss:  0.4614 - mse:  0.4613 - val_mse:  0.5017\n",
      "Epoch 7/10\n",
      "55s - loss:  0.4595 - mse:  0.4594 - val_mse:  0.4943\n",
      "Epoch 8/10\n",
      "59s - loss:  0.4578 - mse:  0.4577 - val_mse:  0.4952\n",
      "Epoch 9/10\n",
      "58s - loss:  0.4543 - mse:  0.4541 - val_mse:  0.4922\n",
      "Epoch 10/10\n",
      "53s - loss:  0.4471 - mse:  0.4469 - val_mse:  0.4914\n",
      "\n",
      "\n",
      " Training DCN \n",
      "\n",
      "cuda:1\n",
      "Train on 570285 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "57s - loss:  0.7669 - mse:  0.7668 - val_mse:  0.5030\n",
      "Epoch 2/10\n",
      "59s - loss:  0.4808 - mse:  0.4808 - val_mse:  0.4963\n",
      "Epoch 3/10\n",
      "61s - loss:  0.4702 - mse:  0.4702 - val_mse:  0.5041\n",
      "Epoch 4/10\n",
      "60s - loss:  0.4628 - mse:  0.4628 - val_mse:  0.4927\n",
      "Epoch 5/10\n",
      "59s - loss:  0.4547 - mse:  0.4546 - val_mse:  0.4900\n",
      "Epoch 6/10\n",
      "58s - loss:  0.4467 - mse:  0.4465 - val_mse:  0.4904\n",
      "Epoch 7/10\n",
      "60s - loss:  0.4397 - mse:  0.4395 - val_mse:  0.4910\n",
      "Epoch 8/10\n",
      "61s - loss:  0.4340 - mse:  0.4338 - val_mse:  0.4918\n",
      "Epoch 9/10\n",
      "62s - loss:  0.4281 - mse:  0.4278 - val_mse:  0.4941\n",
      "Epoch 10/10\n",
      "61s - loss:  0.4224 - mse:  0.4221 - val_mse:  0.4981\n",
      "\n",
      "\n",
      " Training xDeepFM \n",
      "\n",
      "cuda:1\n",
      "Train on 570285 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "62s - loss:  0.6386 - mse:  0.6385 - val_mse:  0.5042\n",
      "Epoch 2/10\n",
      "59s - loss:  0.4773 - mse:  0.4772 - val_mse:  0.4982\n",
      "Epoch 3/10\n",
      "60s - loss:  0.4624 - mse:  0.4623 - val_mse:  0.4921\n",
      "Epoch 4/10\n",
      "62s - loss:  0.4511 - mse:  0.4510 - val_mse:  0.4923\n",
      "Epoch 5/10\n",
      "61s - loss:  0.4428 - mse:  0.4426 - val_mse:  0.4918\n",
      "Epoch 6/10\n",
      "62s - loss:  0.4321 - mse:  0.4320 - val_mse:  0.4949\n",
      "Epoch 7/10\n",
      "61s - loss:  0.4157 - mse:  0.4155 - val_mse:  0.5028\n",
      "Epoch 8/10\n",
      "59s - loss:  0.3945 - mse:  0.3943 - val_mse:  0.5116\n",
      "Epoch 9/10\n",
      "60s - loss:  0.3736 - mse:  0.3733 - val_mse:  0.5280\n",
      "Epoch 10/10\n",
      "64s - loss:  0.3551 - mse:  0.3548 - val_mse:  0.5440\n",
      "\n",
      "\n",
      " Training AFM \n",
      "\n",
      "cuda:1\n",
      "Train on 570285 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "56s - loss:  2.0498 - mse:  2.0493 - val_mse:  0.5876\n",
      "Epoch 2/10\n",
      "53s - loss:  0.5403 - mse:  0.5399 - val_mse:  0.5292\n",
      "Epoch 3/10\n",
      "56s - loss:  0.4952 - mse:  0.4948 - val_mse:  0.5096\n",
      "Epoch 4/10\n",
      "58s - loss:  0.4750 - mse:  0.4746 - val_mse:  0.5024\n",
      "Epoch 5/10\n",
      "57s - loss:  0.4643 - mse:  0.4638 - val_mse:  0.4981\n",
      "Epoch 6/10\n",
      "58s - loss:  0.4582 - mse:  0.4577 - val_mse:  0.4971\n",
      "Epoch 7/10\n",
      "59s - loss:  0.4542 - mse:  0.4537 - val_mse:  0.4968\n",
      "Epoch 8/10\n",
      "58s - loss:  0.4518 - mse:  0.4512 - val_mse:  0.4970\n",
      "Epoch 9/10\n",
      "58s - loss:  0.4500 - mse:  0.4494 - val_mse:  0.4972\n",
      "Epoch 10/10\n",
      "59s - loss:  0.4488 - mse:  0.4482 - val_mse:  0.4972\n"
     ]
    }
   ],
   "source": [
    "fold_cnt = 0\n",
    "\n",
    "for train_index, test_index in kf.split(rel):\n",
    "    \n",
    "    fold_cnt += 1\n",
    "    print(\"========================== {} Fold ==============================\\n\".format(fold_cnt))\n",
    "    \n",
    "    ### train\n",
    "    train_input = {name: rel[name][train_index] for name in sparse_features}\n",
    "    train_input[\"group\"] = _group[train_index]\n",
    "    train_input[\"location\"] = _location[train_index]\n",
    "    train_input[\"user\"] = _user[train_index]\n",
    "    train_input[\"year\"] = _year[train_index]\n",
    "    train_input[\"publisher\"] = _publisher[train_index]\n",
    "    train_input[\"author\"] = _author[train_index]\n",
    "    train_target = np.array(rel[rating][train_index])\n",
    "    \n",
    "    ### test\n",
    "    test_input = {name: rel[name][test_index] for name in sparse_features}\n",
    "    test_input[\"group\"] = _group[test_index]\n",
    "    test_input[\"location\"] = _location[test_index]\n",
    "    test_input[\"user\"] = _user[test_index]\n",
    "    test_input[\"year\"] = _year[test_index]\n",
    "    test_input[\"publisher\"] = _publisher[test_index]\n",
    "    test_input[\"author\"] = _author[test_index]\n",
    "    test_target = np.array(rel[rating][test_index])\n",
    "    binary_target = np.where(test_target > 3, 1, 0).reshape(1, -1)\n",
    "    \n",
    "    print(\"\\n\\n Training DeepFM \\n\")\n",
    "    ### DeepFM\n",
    "    deepfm = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    deepfm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    deepfm_hist = deepfm.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = deepfm.predict(test_input, batch_size=256)\n",
    "    deepfm_mse += mean_squared_error(test_target, pred_ans)\n",
    "    \n",
    "    pred_ans = np.where(pred_ans > 3, 1, 0).reshape((1, -1))\n",
    "    deepfm_recall += recall_score(binary_target.reshape(-1, 1), pred_ans.reshape(-1, 1))\n",
    "    deepfm_ndcg += ndcg_score(binary_target, pred_ans)\n",
    "#     print(\"DeepFM MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    print(\"\\n\\n Training CCPM \\n\")\n",
    "    ### CCPM\n",
    "    ccpm = CCPM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    ccpm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    ccpm_hist = ccpm.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = ccpm.predict(test_input, batch_size=256)\n",
    "    ccpm_mse += mean_squared_error(test_target, pred_ans)\n",
    "    \n",
    "    pred_ans = np.where(pred_ans > 3, 1, 0).reshape((1, -1))\n",
    "    ccpm_recall += recall_score(binary_target.reshape(-1, 1), pred_ans.reshape(-1, 1))\n",
    "    ccpm_ndcg += ndcg_score(binary_target, pred_ans)\n",
    "#     print(\"CCPM MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    print(\"\\n\\n Training IPMM \\n\")\n",
    "    ### IPNN\n",
    "    ipnn = PNN(dnn_feature_columns, task='regression', device=device, use_inner=True, use_outter=False)\n",
    "    ipnn.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    ipnn_hist = ipnn.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = ipnn.predict(test_input, batch_size=256)\n",
    "    ipnn_mse += mean_squared_error(test_target, pred_ans)\n",
    "    \n",
    "    pred_ans = np.where(pred_ans > 3, 1, 0).reshape((1, -1))\n",
    "    ipnn_recall += recall_score(binary_target.reshape(-1, 1), pred_ans.reshape(-1, 1))\n",
    "    ipnn_ndcg += ndcg_score(binary_target, pred_ans)\n",
    "#     print(\"IPNN MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    print(\"\\n\\n Training OPNN \\n\")\n",
    "    ### OPNN\n",
    "    opnn = PNN(dnn_feature_columns, task='regression', device=device, use_inner=False, use_outter=True)\n",
    "    opnn.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    opnn_hist = opnn.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = opnn.predict(test_input, batch_size=256)\n",
    "    opnn_mse += mean_squared_error(test_target, pred_ans)\n",
    "    \n",
    "    pred_ans = np.where(pred_ans > 3, 1, 0).reshape((1, -1))\n",
    "    opnn_recall += recall_score(binary_target.reshape(-1, 1), pred_ans.reshape(-1, 1))\n",
    "    opnn_ndcg += ndcg_score(binary_target, pred_ans)\n",
    "#     print(\"OPNN MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    print(\"\\n\\n Training Wide&Deep \\n\")\n",
    "    ### Wide & Deep\n",
    "    wdl = WDL(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    wdl.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    wdl_hist = wdl.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = wdl.predict(test_input, batch_size=256)\n",
    "    wdl_mse += mean_squared_error(test_target, pred_ans)\n",
    "    \n",
    "    pred_ans = np.where(pred_ans > 3, 1, 0).reshape((1, -1))\n",
    "    wdl_recall += recall_score(binary_target.reshape(-1, 1), pred_ans.reshape(-1, 1))\n",
    "    wdl_ndcg += ndcg_score(binary_target, pred_ans)\n",
    "#     print(\"WDL MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    print(\"\\n\\n Training DCN \\n\")\n",
    "    ### DCN\n",
    "    dcn = DCN(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    dcn.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    dcn_hist = dcn.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = dcn.predict(test_input, batch_size=256)\n",
    "    dcn_mse += mean_squared_error(test_target, pred_ans)\n",
    "    \n",
    "    pred_ans = np.where(pred_ans > 3, 1, 0).reshape((1, -1))\n",
    "    dcn_recall += recall_score(binary_target.reshape(-1, 1), pred_ans.reshape(-1, 1))\n",
    "    dcn_ndcg += ndcg_score(binary_target, pred_ans)\n",
    "#     print(\"DCN MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\n Training xDeepFM \\n\")\n",
    "    ### xDeepFM\n",
    "    xdeepfm = xDeepFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    xdeepfm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    xdeepfm_hist = xdeepfm.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = xdeepfm.predict(test_input, batch_size=256)\n",
    "    xdeepfm_mse += mean_squared_error(test_target, pred_ans)\n",
    "    \n",
    "    pred_ans = np.where(pred_ans > 3, 1, 0).reshape((1, -1))\n",
    "    xdeepfm_recall += recall_score(binary_target.reshape(-1, 1), pred_ans.reshape(-1, 1))\n",
    "    xdeepfm_ndcg += ndcg_score(binary_target, pred_ans)\n",
    "#     print(\"xDeepFM MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\n Training AFM \\n\")\n",
    "    ### AFM\n",
    "    afm = AFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    afm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    afm_hist = afm.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = afm.predict(test_input, batch_size=256)\n",
    "    afm_mse += mean_squared_error(test_target, pred_ans)\n",
    "\n",
    "    pred_ans = np.where(pred_ans > 3, 1, 0).reshape((1, -1))\n",
    "    afm_recall += recall_score(binary_target.reshape(-1, 1), pred_ans.reshape(-1, 1))\n",
    "    afm_ndcg += ndcg_score(binary_target, pred_ans)\n",
    "#     print(\"AFM MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"\\n Training DIN \\n\")\n",
    "    ### DIN\n",
    "    din = DIN(dnn_feature_columns, [], task='regression', device=device)\n",
    "    din.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    din_hist = din.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = din.predict(test_input, batch_size=256)\n",
    "    din_mse += mean_squared_error(test_target, pred_ans)\n",
    "    print(\"DIN MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-browse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "better-panic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5103606755492056"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepfm_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "excited-macro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5219495062444357"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccpm_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "radio-accident",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5620374499083931"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipnn_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "hidden-america",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5383967453805119"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opnn_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "reliable-office",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4858329905815232"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdl_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "moving-miracle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49363165212456117"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcn_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "current-danish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.537465826313654"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdeepfm_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "positive-douglas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49192400220032606"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afm_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-purchase",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "restricted-giving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9905938536780777"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepfm_recall /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "breeding-allah",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9882263266304131"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccpm_recall /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "controlling-locking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9843651928566974"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipnn_recall /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "resident-framework",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9858546700254811"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opnn_recall /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "quick-installation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9942133078354309"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdl_recall /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "interior-comparison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9929549714162722"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcn_recall /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "amended-report",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9856652552575926"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdeepfm_recall /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "thrown-winner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9946642684054929"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afm_recall /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-westminster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "objective-paragraph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9755637019966767"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepfm_ndcg /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "higher-burning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975783872271591"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccpm_ndcg /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "parallel-bulgarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9756824247519752"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipnn_ndcg /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "crucial-physics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9757084911839575"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opnn_ndcg /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "stretch-report",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9752225721673415"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdl_ndcg /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "increasing-cowboy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9752853282679352"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcn_ndcg /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "contemporary-embassy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9757399736574657"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdeepfm_ndcg /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "imported-audit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9750043066949938"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afm_ndcg /5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-combining",
   "metadata": {},
   "source": [
    "# Test single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "south-consumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p = os.path.join(root, \"train.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "athletic-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "group, group_i, group_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"user_group.dat\"), user_cnt=13024)\n",
    "location, location_i, location_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"user_location.dat\"), user_cnt=13024)\n",
    "user, user_i, user_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"user_user.dat\"), user_cnt=13024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "competent-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "year, year_i, year_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"book_year.dat\"), user_cnt=22347)\n",
    "publisher, publisher_i, publisher_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"book_publisher.dat\"), user_cnt=22347)\n",
    "author, author_i, author_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"book_author.dat\"), user_cnt=22347)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "center-brown",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = [\"cols_0\", \"cols_1\"] # user_id, movie_id\n",
    "rating = \"cols_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dense-cincinnati",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cols_0</th>\n",
       "      <th>cols_1</th>\n",
       "      <th>cols_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9608</td>\n",
       "      <td>791</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11607</td>\n",
       "      <td>2664</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3630</td>\n",
       "      <td>712</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12070</td>\n",
       "      <td>5046</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3967</td>\n",
       "      <td>202</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cols_0  cols_1  cols_2\n",
       "0    9608     791       3\n",
       "1   11607    2664       4\n",
       "2    3630     712       4\n",
       "3   12070    5046       5\n",
       "4    3967     202       5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = utils.read_file(train_p)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "interracial-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "_group = group[rel.cols_0 -1]\n",
    "_location = location[rel.cols_0 -1]\n",
    "_user = user[rel.cols_0 -1]\n",
    "\n",
    "_year = year[rel.cols_1 -1]\n",
    "_publisher = publisher[rel.cols_1 -1]\n",
    "_author = author[rel.cols_1 -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "separated-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Label Encoding for sparse features,and process sequence features\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    train[feat] = lbe.fit_transform(train[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "precious-wheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, train[feat].nunique(), embedding_dim=4) for feat in sparse_features]\n",
    "\n",
    "varlen_feature_columns = [\n",
    "    VarLenSparseFeat(SparseFeat('group', vocabulary_size=group_i + 1, embedding_dim=4), maxlen=group_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('location', vocabulary_size=location_i + 1, embedding_dim=4), maxlen=location_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('user', vocabulary_size=13024 + 1, embedding_dim=4), maxlen=user_m, combiner='mean'),\n",
    "    \n",
    "    VarLenSparseFeat(SparseFeat('year', vocabulary_size=year_i + 1, embedding_dim=4), maxlen=year_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('publisher', vocabulary_size=publisher_i + 1, embedding_dim=4), maxlen=publisher_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('author', vocabulary_size=author_i + 1, embedding_dim=4), maxlen=author_m, combiner='mean')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "configured-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dress-pioneer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.generate input data for model\n",
    "model_input = {name: train[name] for name in sparse_features}  #\n",
    "model_input[\"group\"] = _group\n",
    "model_input[\"location\"] = _location\n",
    "model_input[\"user\"] = _user\n",
    "model_input[\"year\"] = _year\n",
    "model_input[\"publisher\"] = _publisher\n",
    "model_input[\"author\"] = _author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-repair",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-victoria",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-chess",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-toddler",
   "metadata": {},
   "source": [
    "### DeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "compound-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import DeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "civic-reduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "228s - loss:  0.7947 - mse:  0.7945 - val_mse:  0.5051\n",
      "Epoch 2/10\n",
      "230s - loss:  0.4835 - mse:  0.4835 - val_mse:  0.5019\n",
      "Epoch 3/10\n",
      "228s - loss:  0.4719 - mse:  0.4718 - val_mse:  0.4993\n",
      "Epoch 4/10\n",
      "226s - loss:  0.4649 - mse:  0.4649 - val_mse:  0.5034\n",
      "Epoch 5/10\n",
      "232s - loss:  0.4600 - mse:  0.4599 - val_mse:  0.4983\n",
      "Epoch 6/10\n",
      "226s - loss:  0.4546 - mse:  0.4545 - val_mse:  0.5073\n",
      "Epoch 7/10\n",
      "228s - loss:  0.4494 - mse:  0.4492 - val_mse:  0.5018\n",
      "Epoch 8/10\n",
      "229s - loss:  0.4428 - mse:  0.4426 - val_mse:  0.5088\n",
      "Epoch 9/10\n",
      "228s - loss:  0.4335 - mse:  0.4333 - val_mse:  0.4998\n",
      "Epoch 10/10\n",
      "229s - loss:  0.4216 - mse:  0.4213 - val_mse:  0.5087\n"
     ]
    }
   ],
   "source": [
    "deepfm = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "\n",
    "deepfm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = deepfm.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-danger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "received-nursing",
   "metadata": {},
   "source": [
    "### CCPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "biblical-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import CCPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dependent-sierra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "228s - loss:  0.7249 - mse:  0.7248 - val_mse:  0.5026\n",
      "Epoch 2/10\n",
      "229s - loss:  0.4766 - mse:  0.4765 - val_mse:  0.4946\n",
      "Epoch 3/10\n",
      "224s - loss:  0.4588 - mse:  0.4588 - val_mse:  0.4915\n",
      "Epoch 4/10\n",
      "231s - loss:  0.4455 - mse:  0.4456 - val_mse:  0.4947\n",
      "Epoch 5/10\n",
      "237s - loss:  0.4302 - mse:  0.4300 - val_mse:  0.4993\n",
      "Epoch 6/10\n",
      "232s - loss:  0.4124 - mse:  0.4122 - val_mse:  0.5155\n",
      "Epoch 7/10\n",
      "207s - loss:  0.3938 - mse:  0.3936 - val_mse:  0.5194\n",
      "Epoch 8/10\n",
      "210s - loss:  0.3771 - mse:  0.3770 - val_mse:  0.5336\n",
      "Epoch 9/10\n",
      "214s - loss:  0.3616 - mse:  0.3613 - val_mse:  0.5405\n",
      "Epoch 10/10\n",
      "213s - loss:  0.3485 - mse:  0.3483 - val_mse:  0.5592\n"
     ]
    }
   ],
   "source": [
    "ccpm = CCPM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "\n",
    "ccpm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = ccpm.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-queue",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "accessory-journal",
   "metadata": {},
   "source": [
    "### PNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "competent-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import PNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-handbook",
   "metadata": {},
   "source": [
    "#### IPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "stone-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipnn = PNN(dnn_feature_columns, task='regression', device=device, use_inner=True, use_outter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "hispanic-arabic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "125s - loss:  0.9133 - mse:  0.9131 - val_mse:  0.5042\n",
      "Epoch 2/10\n",
      "125s - loss:  0.4784 - mse:  0.4784 - val_mse:  0.4927\n",
      "Epoch 3/10\n",
      "123s - loss:  0.4554 - mse:  0.4554 - val_mse:  0.4902\n",
      "Epoch 4/10\n",
      "124s - loss:  0.4353 - mse:  0.4353 - val_mse:  0.4972\n",
      "Epoch 5/10\n",
      "128s - loss:  0.4149 - mse:  0.4150 - val_mse:  0.5067\n",
      "Epoch 6/10\n",
      "128s - loss:  0.3920 - mse:  0.3918 - val_mse:  0.5238\n",
      "Epoch 7/10\n",
      "128s - loss:  0.3712 - mse:  0.3711 - val_mse:  0.5402\n",
      "Epoch 8/10\n",
      "136s - loss:  0.3534 - mse:  0.3532 - val_mse:  0.5562\n",
      "Epoch 9/10\n",
      "141s - loss:  0.3391 - mse:  0.3390 - val_mse:  0.5750\n",
      "Epoch 10/10\n",
      "136s - loss:  0.3282 - mse:  0.3280 - val_mse:  0.5825\n"
     ]
    }
   ],
   "source": [
    "ipnn.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = ipnn.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-person",
   "metadata": {},
   "source": [
    "#### OPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "secret-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "opnn = PNN(dnn_feature_columns, task='regression', device=device, use_inner=False, use_outter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "objective-deployment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "142s - loss:  0.8448 - mse:  0.8446 - val_mse:  0.5039\n",
      "Epoch 2/10\n",
      "143s - loss:  0.4802 - mse:  0.4802 - val_mse:  0.4969\n",
      "Epoch 3/10\n",
      "141s - loss:  0.4659 - mse:  0.4658 - val_mse:  0.4955\n",
      "Epoch 4/10\n",
      "149s - loss:  0.4523 - mse:  0.4523 - val_mse:  0.4966\n",
      "Epoch 5/10\n",
      "145s - loss:  0.4381 - mse:  0.4381 - val_mse:  0.4894\n",
      "Epoch 6/10\n",
      "148s - loss:  0.4243 - mse:  0.4242 - val_mse:  0.4984\n",
      "Epoch 7/10\n",
      "149s - loss:  0.4031 - mse:  0.4031 - val_mse:  0.5068\n",
      "Epoch 8/10\n",
      "148s - loss:  0.3811 - mse:  0.3809 - val_mse:  0.5243\n",
      "Epoch 9/10\n",
      "149s - loss:  0.3619 - mse:  0.3618 - val_mse:  0.5375\n",
      "Epoch 10/10\n",
      "150s - loss:  0.3465 - mse:  0.3463 - val_mse:  0.5589\n"
     ]
    }
   ],
   "source": [
    "opnn.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = opnn.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-audience",
   "metadata": {},
   "source": [
    "#### PIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-concept",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-football",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "educational-desert",
   "metadata": {},
   "source": [
    "### Wide & Deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "quantitative-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import WDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "modified-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdl = WDL(linear_feature_columns, dnn_feature_columns, task='regression', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "oriental-colors",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "246s - loss:  0.7961 - mse:  0.7960 - val_mse:  0.5040\n",
      "Epoch 2/10\n",
      "240s - loss:  0.4823 - mse:  0.4823 - val_mse:  0.5012\n",
      "Epoch 3/10\n",
      "246s - loss:  0.4711 - mse:  0.4710 - val_mse:  0.4985\n",
      "Epoch 4/10\n",
      "250s - loss:  0.4652 - mse:  0.4651 - val_mse:  0.5034\n",
      "Epoch 5/10\n",
      "244s - loss:  0.4620 - mse:  0.4618 - val_mse:  0.4979\n",
      "Epoch 6/10\n",
      "246s - loss:  0.4590 - mse:  0.4589 - val_mse:  0.5057\n",
      "Epoch 7/10\n",
      "227s - loss:  0.4565 - mse:  0.4564 - val_mse:  0.5003\n",
      "Epoch 8/10\n",
      "216s - loss:  0.4539 - mse:  0.4538 - val_mse:  0.5046\n",
      "Epoch 9/10\n",
      "224s - loss:  0.4500 - mse:  0.4499 - val_mse:  0.4941\n",
      "Epoch 10/10\n",
      "246s - loss:  0.4450 - mse:  0.4449 - val_mse:  0.4990\n"
     ]
    }
   ],
   "source": [
    "wdl.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = wdl.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-offer",
   "metadata": {},
   "source": [
    "### Deep Cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "white-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import DCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "atlantic-ticket",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcn = DCN(linear_feature_columns, dnn_feature_columns, task='regression', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "based-correction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "258s - loss:  0.8089 - mse:  0.8087 - val_mse:  0.5125\n",
      "Epoch 2/10\n",
      "261s - loss:  0.4816 - mse:  0.4817 - val_mse:  0.4968\n",
      "Epoch 3/10\n",
      "261s - loss:  0.4698 - mse:  0.4698 - val_mse:  0.4977\n",
      "Epoch 4/10\n",
      "257s - loss:  0.4629 - mse:  0.4628 - val_mse:  0.4945\n",
      "Epoch 5/10\n",
      "255s - loss:  0.4569 - mse:  0.4567 - val_mse:  0.4912\n",
      "Epoch 6/10\n",
      "258s - loss:  0.4486 - mse:  0.4486 - val_mse:  0.4922\n",
      "Epoch 7/10\n",
      "252s - loss:  0.4416 - mse:  0.4415 - val_mse:  0.4916\n",
      "Epoch 8/10\n",
      "251s - loss:  0.4345 - mse:  0.4343 - val_mse:  0.4934\n",
      "Epoch 9/10\n",
      "256s - loss:  0.4284 - mse:  0.4283 - val_mse:  0.4968\n",
      "Epoch 10/10\n",
      "263s - loss:  0.4220 - mse:  0.4217 - val_mse:  0.5029\n"
     ]
    }
   ],
   "source": [
    "dcn.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = dcn.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-tours",
   "metadata": {},
   "source": [
    "### xDeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "wicked-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import xDeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "equipped-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdeepfm = xDeepFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "equal-austin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "267s - loss:  0.6677 - mse:  0.6676 - val_mse:  0.5041\n",
      "Epoch 2/10\n",
      "262s - loss:  0.4801 - mse:  0.4800 - val_mse:  0.5075\n",
      "Epoch 3/10\n",
      "260s - loss:  0.4634 - mse:  0.4634 - val_mse:  0.4897\n",
      "Epoch 4/10\n",
      "259s - loss:  0.4514 - mse:  0.4513 - val_mse:  0.4937\n",
      "Epoch 5/10\n",
      "266s - loss:  0.4428 - mse:  0.4428 - val_mse:  0.4951\n",
      "Epoch 6/10\n",
      "261s - loss:  0.4348 - mse:  0.4347 - val_mse:  0.4953\n",
      "Epoch 7/10\n",
      "262s - loss:  0.4266 - mse:  0.4264 - val_mse:  0.4972\n",
      "Epoch 8/10\n",
      "253s - loss:  0.4124 - mse:  0.4123 - val_mse:  0.5075\n",
      "Epoch 9/10\n",
      "265s - loss:  0.3919 - mse:  0.3917 - val_mse:  0.5153\n",
      "Epoch 10/10\n",
      "268s - loss:  0.3690 - mse:  0.3688 - val_mse:  0.5356\n"
     ]
    }
   ],
   "source": [
    "xdeepfm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = xdeepfm.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-bennett",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "configured-sailing",
   "metadata": {},
   "source": [
    "### Attentional Factorization Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dynamic-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import AFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "altered-morris",
   "metadata": {},
   "outputs": [],
   "source": [
    "afm = AFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "separate-restriction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "255s - loss:  2.5075 - mse:  2.5064 - val_mse:  0.6100\n",
      "Epoch 2/10\n",
      "245s - loss:  0.5585 - mse:  0.5580 - val_mse:  0.5407\n",
      "Epoch 3/10\n",
      "250s - loss:  0.5036 - mse:  0.5033 - val_mse:  0.5176\n",
      "Epoch 4/10\n",
      "248s - loss:  0.4790 - mse:  0.4785 - val_mse:  0.5092\n",
      "Epoch 5/10\n",
      "255s - loss:  0.4663 - mse:  0.4658 - val_mse:  0.5048\n",
      "Epoch 6/10\n",
      "251s - loss:  0.4587 - mse:  0.4581 - val_mse:  0.5022\n",
      "Epoch 7/10\n",
      "253s - loss:  0.4536 - mse:  0.4529 - val_mse:  0.5014\n",
      "Epoch 8/10\n",
      "251s - loss:  0.4497 - mse:  0.4490 - val_mse:  0.5012\n",
      "Epoch 9/10\n",
      "256s - loss:  0.4468 - mse:  0.4461 - val_mse:  0.5005\n",
      "Epoch 10/10\n",
      "254s - loss:  0.4443 - mse:  0.4436 - val_mse:  0.5011\n"
     ]
    }
   ],
   "source": [
    "afm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = afm.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-american",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "focal-perception",
   "metadata": {},
   "source": [
    "### Neural Factorization Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "remarkable-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import NFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adaptive-survivor",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfm = NFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "recorded-composite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "247s - loss:  0.7533 - mse:  0.7532 - val_mse:  0.5090\n",
      "Epoch 2/10\n",
      "234s - loss:  0.4786 - mse:  0.4785 - val_mse:  0.4960\n",
      "Epoch 3/10\n",
      "246s - loss:  0.4566 - mse:  0.4565 - val_mse:  0.4959\n",
      "Epoch 4/10\n",
      "246s - loss:  0.4432 - mse:  0.4432 - val_mse:  0.4988\n",
      "Epoch 5/10\n",
      "242s - loss:  0.4338 - mse:  0.4337 - val_mse:  0.5024\n",
      "Epoch 6/10\n",
      "248s - loss:  0.4259 - mse:  0.4258 - val_mse:  0.5026\n",
      "Epoch 7/10\n",
      "238s - loss:  0.4191 - mse:  0.4189 - val_mse:  0.5034\n",
      "Epoch 8/10\n",
      "248s - loss:  0.4125 - mse:  0.4123 - val_mse:  0.5059\n",
      "Epoch 9/10\n",
      "236s - loss:  0.4040 - mse:  0.4037 - val_mse:  0.5117\n",
      "Epoch 10/10\n",
      "230s - loss:  0.3946 - mse:  0.3943 - val_mse:  0.5179\n"
     ]
    }
   ],
   "source": [
    "nfm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = nfm.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-longer",
   "metadata": {},
   "source": [
    "### Deep Interest Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "further-liquid",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import DIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "coral-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_feature_list = np.array([\"cols_0\", \"cols_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "subjective-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "din = DIN(dnn_feature_columns, behavior_feature_list, task='regression', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "progressive-trance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'VarLenSparseFeat' object has no attribute 'use_hash'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-c5fe815ca6cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrating\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/deepctr_torch/models/basemodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, initial_epoch, validation_split, validation_data, shuffle, callbacks)\u001b[0m\n\u001b[1;32m    239\u001b[0m                         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/deepctr_torch/models/din.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         sequence_embed_dict = varlen_embedding_lookup(X, self.embedding_dict, self.feature_index,\n\u001b[0;32m---> 95\u001b[0;31m                                                       self.sparse_varlen_feature_columns)\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         sequence_embed_list = get_varlen_pooling_list(sequence_embed_dict, X, self.feature_index,\n",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/deepctr_torch/inputs.py\u001b[0m in \u001b[0;36mvarlen_embedding_lookup\u001b[0;34m(X, embedding_dict, sequence_input_dict, varlen_sparse_feature_columns)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mfeature_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0membedding_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_hash\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m             \u001b[0;31m# lookup_idx = Hash(fc.vocabulary_size, mask_zero=True)(sequence_input_dict[feature_name])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;31m# TODO: add hash function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VarLenSparseFeat' object has no attribute 'use_hash'"
     ]
    }
   ],
   "source": [
    "din.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = din.fit(model_input, train[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-prisoner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
