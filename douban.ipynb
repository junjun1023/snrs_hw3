{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "academic-trademark",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, ndcg_score, recall_score\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "floral-green",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "\n",
    "from deepctr_torch.inputs import SparseFeat, VarLenSparseFeat, get_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "meaning-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import DIN\n",
    "from deepctr_torch.models import AFM\n",
    "from deepctr_torch.models import WDL\n",
    "from deepctr_torch.models import xDeepFM\n",
    "from deepctr_torch.models import DeepFM\n",
    "from deepctr_torch.models import PNN\n",
    "from deepctr_torch.models import DCN\n",
    "from deepctr_torch.models import CCPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "collectible-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "greek-gossip",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda ready...\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "use_cuda = True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    print('cuda ready...')\n",
    "    device = 'cuda:0'\n",
    "\n",
    "root = os.path.join(os.getcwd(), \"DoubanBook\")\n",
    "rel_p = os.path.join(root, \"user_book.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-massachusetts",
   "metadata": {},
   "source": [
    "### User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ranging-recommendation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "group, group_i, group_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"user_group.dat\"), user_cnt=13024)\n",
    "location, location_i, location_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"user_location.dat\"), user_cnt=13024)\n",
    "user, user_i, user_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"user_user.dat\"), user_cnt=13024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-compensation",
   "metadata": {},
   "source": [
    "### Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "improving-conversion",
   "metadata": {},
   "outputs": [],
   "source": [
    "year, year_i, year_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"book_year.dat\"), user_cnt=22347)\n",
    "publisher, publisher_i, publisher_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"book_publisher.dat\"), user_cnt=22347)\n",
    "author, author_i, author_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"book_author.dat\"), user_cnt=22347)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-metallic",
   "metadata": {},
   "source": [
    "### Interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bearing-concert",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = [\"cols_0\", \"cols_1\"] # user_id, movie_id\n",
    "rating = \"cols_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "personalized-millennium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cols_0</th>\n",
       "      <th>cols_1</th>\n",
       "      <th>cols_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10855</td>\n",
       "      <td>938</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10027</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>741</td>\n",
       "      <td>2426</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>453</td>\n",
       "      <td>1263</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11665</td>\n",
       "      <td>7717</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cols_0  cols_1  cols_2\n",
       "0   10855     938       4\n",
       "1   10027       3       3\n",
       "2     741    2426       5\n",
       "3     453    1263       4\n",
       "4   11665    7717       5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel = utils.read_file(rel_p)\n",
    "rel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "manual-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "_group = group[rel.cols_0 -1]\n",
    "_location = location[rel.cols_0 -1]\n",
    "_user = user[rel.cols_0 -1]\n",
    "\n",
    "_year = year[rel.cols_1 -1]\n",
    "_publisher = publisher[rel.cols_1 -1]\n",
    "_author = author[rel.cols_1 -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "informational-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Label Encoding for sparse features,and process sequence features\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    rel[feat] = lbe.fit_transform(rel[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "furnished-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, rel[feat].nunique(), embedding_dim=4) for feat in sparse_features]\n",
    "\n",
    "varlen_feature_columns = [\n",
    "    VarLenSparseFeat(SparseFeat('group', vocabulary_size=group_i + 1, embedding_dim=4), maxlen=group_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('location', vocabulary_size=location_i + 1, embedding_dim=4), maxlen=location_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('user', vocabulary_size=13024 + 1, embedding_dim=4), maxlen=user_m, combiner='mean'),\n",
    "    \n",
    "    VarLenSparseFeat(SparseFeat('year', vocabulary_size=year_i + 1, embedding_dim=4), maxlen=year_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('publisher', vocabulary_size=publisher_i + 1, embedding_dim=4), maxlen=publisher_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('author', vocabulary_size=author_i + 1, embedding_dim=4), maxlen=author_m, combiner='mean')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "existing-vegetable",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-district",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "spectacular-treasury",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "domestic-shift",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepfm_mse = 0\n",
    "ccpm_mse = 0\n",
    "ipnn_mse = 0\n",
    "opnn_mse = 0\n",
    "wdl_mse = 0\n",
    "dcn_mse = 0\n",
    "xdeepfm_mse = 0\n",
    "afm_mse = 0\n",
    "din_mse = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-richards",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================== 1 Fold ==============================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Training DeepFM \n",
      "\n",
      "cuda:0\n",
      "Train on 570284 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "299s - loss:  0.7355 - mse:  0.7354 - val_mse:  0.4965\n",
      "Epoch 2/10\n",
      "306s - loss:  0.4834 - mse:  0.4834 - val_mse:  0.4935\n",
      "Epoch 3/10\n",
      "306s - loss:  0.4734 - mse:  0.4733 - val_mse:  0.4899\n",
      "Epoch 4/10\n",
      "294s - loss:  0.4672 - mse:  0.4672 - val_mse:  0.4881\n",
      "Epoch 5/10\n",
      "334s - loss:  0.4614 - mse:  0.4613 - val_mse:  0.4903\n",
      "Epoch 6/10\n",
      "350s - loss:  0.4553 - mse:  0.4552 - val_mse:  0.4886\n",
      "Epoch 7/10\n",
      "350s - loss:  0.4470 - mse:  0.4469 - val_mse:  0.4873\n",
      "Epoch 8/10\n",
      "347s - loss:  0.4363 - mse:  0.4361 - val_mse:  0.4893\n",
      "Epoch 9/10\n",
      "354s - loss:  0.4219 - mse:  0.4216 - val_mse:  0.4982\n",
      "Epoch 10/10\n",
      "352s - loss:  0.4049 - mse:  0.4045 - val_mse:  0.5070\n",
      "DeepFM MSE 0.5089\n",
      "\n",
      "\n",
      " Training CCPM \n",
      "\n",
      "cuda:0\n",
      "Train on 570284 samples, validate on 63365 samples, 2228 steps per epoch\n",
      "Epoch 1/10\n",
      "376s - loss:  0.6663 - mse:  0.6663 - val_mse:  0.4957\n",
      "Epoch 2/10\n",
      "400s - loss:  0.4787 - mse:  0.4787 - val_mse:  0.4878\n",
      "Epoch 3/10\n",
      "399s - loss:  0.4668 - mse:  0.4667 - val_mse:  0.4868\n"
     ]
    }
   ],
   "source": [
    "fold_cnt = 0\n",
    "\n",
    "for train_index, test_index in kf.split(rel):\n",
    "    \n",
    "    fold_cnt += 1\n",
    "    print(\"========================== {} Fold ==============================\\n\\n\".format(fold_cnt))\n",
    "    \n",
    "    ### train\n",
    "    train_input = {name: rel[name][train_index] for name in sparse_features}\n",
    "    train_input[\"group\"] = _group[train_index]\n",
    "    train_input[\"location\"] = _location[train_index]\n",
    "    train_input[\"user\"] = _user[train_index]\n",
    "    train_input[\"year\"] = _year[train_index]\n",
    "    train_input[\"publisher\"] = _publisher[train_index]\n",
    "    train_input[\"author\"] = _author[train_index]\n",
    "    train_target = np.array(rel[rating][train_index])\n",
    "    \n",
    "    ### test\n",
    "    test_input = {name: rel[name][test_index] for name in sparse_features}\n",
    "    test_input[\"group\"] = _group[test_index]\n",
    "    test_input[\"location\"] = _location[test_index]\n",
    "    test_input[\"user\"] = _user[test_index]\n",
    "    test_input[\"year\"] = _year[test_index]\n",
    "    test_input[\"publisher\"] = _publisher[test_index]\n",
    "    test_input[\"author\"] = _author[test_index]\n",
    "    test_target = np.array(rel[rating][test_index])\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\n Training DeepFM \\n\")\n",
    "    ### DeepFM\n",
    "    deepfm = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    deepfm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    deepfm_hist = deepfm.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = deepfm.predict(test_input, batch_size=256)\n",
    "    deepfm_mse += mean_squared_error(test_target, pred_ans)\n",
    "    print(\"DeepFM MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    print(\"\\n\\n Training CCPM \\n\")\n",
    "    ### CCPM\n",
    "    ccpm = CCPM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    ccpm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    ccpm_hist = ccpm.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = ccpm.predict(test_input, batch_size=256)\n",
    "    ccpm_mse += mean_squared_error(test_target, pred_ans)\n",
    "    print(\"CCPM MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    print(\"\\n\\n Training IPMM \\n\")\n",
    "    ### IPNN\n",
    "    ipnn = PNN(dnn_feature_columns, task='regression', device=device, use_inner=True, use_outter=False)\n",
    "    ipnn.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    ipnn_hist = ipnn.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = ipnn.predict(test_input, batch_size=256)\n",
    "    ipnn_mse += mean_squared_error(test_target, pred_ans)\n",
    "    print(\"IPNN MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    print(\"\\n\\n Training OPNN \\n\")\n",
    "    ### OPNN\n",
    "    opnn = PNN(dnn_feature_columns, task='regression', device=device, use_inner=False, use_outter=True)\n",
    "    opnn.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    opnn_hist = opnn.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = opnn.predict(test_input, batch_size=256)\n",
    "    opnn_mse += mean_squared_error(test_target, pred_ans)\n",
    "    print(\"OPNN MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    print(\"\\n\\n Training Wide&Deep \\n\")\n",
    "    ### Wide & Deep\n",
    "    wdl = WDL(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    wdl.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    wdl_hist = wdl.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = wdl.predict(test_input, batch_size=256)\n",
    "    wdl_mse += mean_squared_error(test_target, pred_ans)\n",
    "    print(\"WDL MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    print(\"\\n\\n Training DCN \\n\")\n",
    "    ### DCN\n",
    "    dcn = DCN(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    dcn.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    dcn_hist = dcn.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = dcn.predict(test_input, batch_size=256)\n",
    "    dcn_mse += mean_squared_error(test_target, pred_ans)\n",
    "    print(\"DCN MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\n Training xDeepFM \\n\")\n",
    "    ### xDeepFM\n",
    "    xdeepfm = xDeepFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    xdeepfm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    xdeepfm_hist = xdeepfm.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = xdeepfm.predict(test_input, batch_size=256)\n",
    "    xdeepfm_mse += mean_squared_error(test_target, pred_ans)\n",
    "    print(\"xDeepFM MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\n Training AFM \\n\")\n",
    "    ### AFM\n",
    "    afm = AFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    afm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    afm_hist = afm.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = afm.predict(test_input, batch_size=256)\n",
    "    afm_mse += mean_squared_error(test_target, pred_ans)\n",
    "    print(\"AFM MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"\\n Training DIN \\n\")\n",
    "    ### DIN\n",
    "    din = DIN(dnn_feature_columns, [], task='regression', device=device)\n",
    "    din.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    din_hist = din.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = din.predict(test_input, batch_size=256)\n",
    "    din_mse += mean_squared_error(test_target, pred_ans)\n",
    "    print(\"DIN MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-atlanta",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-murray",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepfm_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccpm_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipnn_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-breach",
   "metadata": {},
   "outputs": [],
   "source": [
    "opnn_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdl_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcn_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-gothic",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdeepfm_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "afm_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "din_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-mixer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sporting-acrylic",
   "metadata": {},
   "source": [
    "# Test single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "typical-police",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p = os.path.join(root, \"train.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dressed-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "group, group_i, group_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"user_group.dat\"), user_cnt=13024)\n",
    "location, location_i, location_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"user_location.dat\"), user_cnt=13024)\n",
    "user, user_i, user_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"user_user.dat\"), user_cnt=13024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "beginning-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "year, year_i, year_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"book_year.dat\"), user_cnt=22347)\n",
    "publisher, publisher_i, publisher_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"book_publisher.dat\"), user_cnt=22347)\n",
    "author, author_i, author_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"book_author.dat\"), user_cnt=22347)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "proper-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = [\"cols_0\", \"cols_1\"] # user_id, movie_id\n",
    "rating = \"cols_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "received-leisure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cols_0</th>\n",
       "      <th>cols_1</th>\n",
       "      <th>cols_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9608</td>\n",
       "      <td>791</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11607</td>\n",
       "      <td>2664</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3630</td>\n",
       "      <td>712</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12070</td>\n",
       "      <td>5046</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3967</td>\n",
       "      <td>202</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cols_0  cols_1  cols_2\n",
       "0    9608     791       3\n",
       "1   11607    2664       4\n",
       "2    3630     712       4\n",
       "3   12070    5046       5\n",
       "4    3967     202       5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = utils.read_file(train_p)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "persistent-groove",
   "metadata": {},
   "outputs": [],
   "source": [
    "_group = group[rel.cols_0 -1]\n",
    "_location = location[rel.cols_0 -1]\n",
    "_user = user[rel.cols_0 -1]\n",
    "\n",
    "_year = year[rel.cols_1 -1]\n",
    "_publisher = publisher[rel.cols_1 -1]\n",
    "_author = author[rel.cols_1 -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "quantitative-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Label Encoding for sparse features,and process sequence features\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    train[feat] = lbe.fit_transform(train[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "normal-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, train[feat].nunique(), embedding_dim=4) for feat in sparse_features]\n",
    "\n",
    "varlen_feature_columns = [\n",
    "    VarLenSparseFeat(SparseFeat('group', vocabulary_size=group_i + 1, embedding_dim=4), maxlen=group_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('location', vocabulary_size=location_i + 1, embedding_dim=4), maxlen=location_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('user', vocabulary_size=13024 + 1, embedding_dim=4), maxlen=user_m, combiner='mean'),\n",
    "    \n",
    "    VarLenSparseFeat(SparseFeat('year', vocabulary_size=year_i + 1, embedding_dim=4), maxlen=year_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('publisher', vocabulary_size=publisher_i + 1, embedding_dim=4), maxlen=publisher_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('author', vocabulary_size=author_i + 1, embedding_dim=4), maxlen=author_m, combiner='mean')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "mature-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "august-desert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.generate input data for model\n",
    "model_input = {name: train[name] for name in sparse_features}  #\n",
    "model_input[\"group\"] = _group\n",
    "model_input[\"location\"] = _location\n",
    "model_input[\"user\"] = _user\n",
    "model_input[\"year\"] = _year\n",
    "model_input[\"publisher\"] = _publisher\n",
    "model_input[\"author\"] = _author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-burns",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-protest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-conviction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "binding-costa",
   "metadata": {},
   "source": [
    "### DeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "shared-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import DeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "atmospheric-question",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "228s - loss:  0.7947 - mse:  0.7945 - val_mse:  0.5051\n",
      "Epoch 2/10\n",
      "230s - loss:  0.4835 - mse:  0.4835 - val_mse:  0.5019\n",
      "Epoch 3/10\n",
      "228s - loss:  0.4719 - mse:  0.4718 - val_mse:  0.4993\n",
      "Epoch 4/10\n",
      "226s - loss:  0.4649 - mse:  0.4649 - val_mse:  0.5034\n",
      "Epoch 5/10\n",
      "232s - loss:  0.4600 - mse:  0.4599 - val_mse:  0.4983\n",
      "Epoch 6/10\n",
      "226s - loss:  0.4546 - mse:  0.4545 - val_mse:  0.5073\n",
      "Epoch 7/10\n",
      "228s - loss:  0.4494 - mse:  0.4492 - val_mse:  0.5018\n",
      "Epoch 8/10\n",
      "229s - loss:  0.4428 - mse:  0.4426 - val_mse:  0.5088\n",
      "Epoch 9/10\n",
      "228s - loss:  0.4335 - mse:  0.4333 - val_mse:  0.4998\n",
      "Epoch 10/10\n",
      "229s - loss:  0.4216 - mse:  0.4213 - val_mse:  0.5087\n"
     ]
    }
   ],
   "source": [
    "deepfm = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "\n",
    "deepfm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = deepfm.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-significance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "integral-drunk",
   "metadata": {},
   "source": [
    "### CCPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "intended-administrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import CCPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "opposite-silver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "228s - loss:  0.7249 - mse:  0.7248 - val_mse:  0.5026\n",
      "Epoch 2/10\n",
      "229s - loss:  0.4766 - mse:  0.4765 - val_mse:  0.4946\n",
      "Epoch 3/10\n",
      "224s - loss:  0.4588 - mse:  0.4588 - val_mse:  0.4915\n",
      "Epoch 4/10\n",
      "231s - loss:  0.4455 - mse:  0.4456 - val_mse:  0.4947\n",
      "Epoch 5/10\n",
      "237s - loss:  0.4302 - mse:  0.4300 - val_mse:  0.4993\n",
      "Epoch 6/10\n",
      "232s - loss:  0.4124 - mse:  0.4122 - val_mse:  0.5155\n",
      "Epoch 7/10\n",
      "207s - loss:  0.3938 - mse:  0.3936 - val_mse:  0.5194\n",
      "Epoch 8/10\n",
      "210s - loss:  0.3771 - mse:  0.3770 - val_mse:  0.5336\n",
      "Epoch 9/10\n",
      "214s - loss:  0.3616 - mse:  0.3613 - val_mse:  0.5405\n",
      "Epoch 10/10\n",
      "213s - loss:  0.3485 - mse:  0.3483 - val_mse:  0.5592\n"
     ]
    }
   ],
   "source": [
    "ccpm = CCPM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "\n",
    "ccpm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = ccpm.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-fiber",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "received-chess",
   "metadata": {},
   "source": [
    "### PNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "necessary-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import PNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-patent",
   "metadata": {},
   "source": [
    "#### IPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "continued-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipnn = PNN(dnn_feature_columns, task='regression', device=device, use_inner=True, use_outter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "swedish-principle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "125s - loss:  0.9133 - mse:  0.9131 - val_mse:  0.5042\n",
      "Epoch 2/10\n",
      "125s - loss:  0.4784 - mse:  0.4784 - val_mse:  0.4927\n",
      "Epoch 3/10\n",
      "123s - loss:  0.4554 - mse:  0.4554 - val_mse:  0.4902\n",
      "Epoch 4/10\n",
      "124s - loss:  0.4353 - mse:  0.4353 - val_mse:  0.4972\n",
      "Epoch 5/10\n",
      "128s - loss:  0.4149 - mse:  0.4150 - val_mse:  0.5067\n",
      "Epoch 6/10\n",
      "128s - loss:  0.3920 - mse:  0.3918 - val_mse:  0.5238\n",
      "Epoch 7/10\n",
      "128s - loss:  0.3712 - mse:  0.3711 - val_mse:  0.5402\n",
      "Epoch 8/10\n",
      "136s - loss:  0.3534 - mse:  0.3532 - val_mse:  0.5562\n",
      "Epoch 9/10\n",
      "141s - loss:  0.3391 - mse:  0.3390 - val_mse:  0.5750\n",
      "Epoch 10/10\n",
      "136s - loss:  0.3282 - mse:  0.3280 - val_mse:  0.5825\n"
     ]
    }
   ],
   "source": [
    "ipnn.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = ipnn.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-electron",
   "metadata": {},
   "source": [
    "#### OPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "optimum-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "opnn = PNN(dnn_feature_columns, task='regression', device=device, use_inner=False, use_outter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "solved-recording",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "142s - loss:  0.8448 - mse:  0.8446 - val_mse:  0.5039\n",
      "Epoch 2/10\n",
      "143s - loss:  0.4802 - mse:  0.4802 - val_mse:  0.4969\n",
      "Epoch 3/10\n",
      "141s - loss:  0.4659 - mse:  0.4658 - val_mse:  0.4955\n",
      "Epoch 4/10\n",
      "149s - loss:  0.4523 - mse:  0.4523 - val_mse:  0.4966\n",
      "Epoch 5/10\n",
      "145s - loss:  0.4381 - mse:  0.4381 - val_mse:  0.4894\n",
      "Epoch 6/10\n",
      "148s - loss:  0.4243 - mse:  0.4242 - val_mse:  0.4984\n",
      "Epoch 7/10\n",
      "149s - loss:  0.4031 - mse:  0.4031 - val_mse:  0.5068\n",
      "Epoch 8/10\n",
      "148s - loss:  0.3811 - mse:  0.3809 - val_mse:  0.5243\n",
      "Epoch 9/10\n",
      "149s - loss:  0.3619 - mse:  0.3618 - val_mse:  0.5375\n",
      "Epoch 10/10\n",
      "150s - loss:  0.3465 - mse:  0.3463 - val_mse:  0.5589\n"
     ]
    }
   ],
   "source": [
    "opnn.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = opnn.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-dating",
   "metadata": {},
   "source": [
    "#### PIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-above",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-founder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "numerical-dubai",
   "metadata": {},
   "source": [
    "### Wide & Deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "skilled-paraguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import WDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "alleged-letters",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdl = WDL(linear_feature_columns, dnn_feature_columns, task='regression', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "rising-skirt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "246s - loss:  0.7961 - mse:  0.7960 - val_mse:  0.5040\n",
      "Epoch 2/10\n",
      "240s - loss:  0.4823 - mse:  0.4823 - val_mse:  0.5012\n",
      "Epoch 3/10\n",
      "246s - loss:  0.4711 - mse:  0.4710 - val_mse:  0.4985\n",
      "Epoch 4/10\n",
      "250s - loss:  0.4652 - mse:  0.4651 - val_mse:  0.5034\n",
      "Epoch 5/10\n",
      "244s - loss:  0.4620 - mse:  0.4618 - val_mse:  0.4979\n",
      "Epoch 6/10\n",
      "246s - loss:  0.4590 - mse:  0.4589 - val_mse:  0.5057\n",
      "Epoch 7/10\n",
      "227s - loss:  0.4565 - mse:  0.4564 - val_mse:  0.5003\n",
      "Epoch 8/10\n",
      "216s - loss:  0.4539 - mse:  0.4538 - val_mse:  0.5046\n",
      "Epoch 9/10\n",
      "224s - loss:  0.4500 - mse:  0.4499 - val_mse:  0.4941\n",
      "Epoch 10/10\n",
      "246s - loss:  0.4450 - mse:  0.4449 - val_mse:  0.4990\n"
     ]
    }
   ],
   "source": [
    "wdl.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = wdl.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-syndication",
   "metadata": {},
   "source": [
    "### Deep Cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "textile-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import DCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "suited-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcn = DCN(linear_feature_columns, dnn_feature_columns, task='regression', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "spanish-trailer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "258s - loss:  0.8089 - mse:  0.8087 - val_mse:  0.5125\n",
      "Epoch 2/10\n",
      "261s - loss:  0.4816 - mse:  0.4817 - val_mse:  0.4968\n",
      "Epoch 3/10\n",
      "261s - loss:  0.4698 - mse:  0.4698 - val_mse:  0.4977\n",
      "Epoch 4/10\n",
      "257s - loss:  0.4629 - mse:  0.4628 - val_mse:  0.4945\n",
      "Epoch 5/10\n",
      "255s - loss:  0.4569 - mse:  0.4567 - val_mse:  0.4912\n",
      "Epoch 6/10\n",
      "258s - loss:  0.4486 - mse:  0.4486 - val_mse:  0.4922\n",
      "Epoch 7/10\n",
      "252s - loss:  0.4416 - mse:  0.4415 - val_mse:  0.4916\n",
      "Epoch 8/10\n",
      "251s - loss:  0.4345 - mse:  0.4343 - val_mse:  0.4934\n",
      "Epoch 9/10\n",
      "256s - loss:  0.4284 - mse:  0.4283 - val_mse:  0.4968\n",
      "Epoch 10/10\n",
      "263s - loss:  0.4220 - mse:  0.4217 - val_mse:  0.5029\n"
     ]
    }
   ],
   "source": [
    "dcn.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = dcn.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-marriage",
   "metadata": {},
   "source": [
    "### xDeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ignored-telling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import xDeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "classical-chambers",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdeepfm = xDeepFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "regular-casting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "267s - loss:  0.6677 - mse:  0.6676 - val_mse:  0.5041\n",
      "Epoch 2/10\n",
      "262s - loss:  0.4801 - mse:  0.4800 - val_mse:  0.5075\n",
      "Epoch 3/10\n",
      "260s - loss:  0.4634 - mse:  0.4634 - val_mse:  0.4897\n",
      "Epoch 4/10\n",
      "259s - loss:  0.4514 - mse:  0.4513 - val_mse:  0.4937\n",
      "Epoch 5/10\n",
      "266s - loss:  0.4428 - mse:  0.4428 - val_mse:  0.4951\n",
      "Epoch 6/10\n",
      "261s - loss:  0.4348 - mse:  0.4347 - val_mse:  0.4953\n",
      "Epoch 7/10\n",
      "262s - loss:  0.4266 - mse:  0.4264 - val_mse:  0.4972\n",
      "Epoch 8/10\n",
      "253s - loss:  0.4124 - mse:  0.4123 - val_mse:  0.5075\n",
      "Epoch 9/10\n",
      "265s - loss:  0.3919 - mse:  0.3917 - val_mse:  0.5153\n",
      "Epoch 10/10\n",
      "268s - loss:  0.3690 - mse:  0.3688 - val_mse:  0.5356\n"
     ]
    }
   ],
   "source": [
    "xdeepfm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = xdeepfm.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-drilling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "normal-turkish",
   "metadata": {},
   "source": [
    "### Attentional Factorization Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "published-style",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import AFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "continuing-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "afm = AFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "boring-affiliation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "255s - loss:  2.5075 - mse:  2.5064 - val_mse:  0.6100\n",
      "Epoch 2/10\n",
      "245s - loss:  0.5585 - mse:  0.5580 - val_mse:  0.5407\n",
      "Epoch 3/10\n",
      "250s - loss:  0.5036 - mse:  0.5033 - val_mse:  0.5176\n",
      "Epoch 4/10\n",
      "248s - loss:  0.4790 - mse:  0.4785 - val_mse:  0.5092\n",
      "Epoch 5/10\n",
      "255s - loss:  0.4663 - mse:  0.4658 - val_mse:  0.5048\n",
      "Epoch 6/10\n",
      "251s - loss:  0.4587 - mse:  0.4581 - val_mse:  0.5022\n",
      "Epoch 7/10\n",
      "253s - loss:  0.4536 - mse:  0.4529 - val_mse:  0.5014\n",
      "Epoch 8/10\n",
      "251s - loss:  0.4497 - mse:  0.4490 - val_mse:  0.5012\n",
      "Epoch 9/10\n",
      "256s - loss:  0.4468 - mse:  0.4461 - val_mse:  0.5005\n",
      "Epoch 10/10\n",
      "254s - loss:  0.4443 - mse:  0.4436 - val_mse:  0.5011\n"
     ]
    }
   ],
   "source": [
    "afm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = afm.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-lucas",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "resident-figure",
   "metadata": {},
   "source": [
    "### Neural Factorization Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "adapted-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import NFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "returning-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfm = NFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "engaging-basket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "247s - loss:  0.7533 - mse:  0.7532 - val_mse:  0.5090\n",
      "Epoch 2/10\n",
      "234s - loss:  0.4786 - mse:  0.4785 - val_mse:  0.4960\n",
      "Epoch 3/10\n",
      "246s - loss:  0.4566 - mse:  0.4565 - val_mse:  0.4959\n",
      "Epoch 4/10\n",
      "246s - loss:  0.4432 - mse:  0.4432 - val_mse:  0.4988\n",
      "Epoch 5/10\n",
      "242s - loss:  0.4338 - mse:  0.4337 - val_mse:  0.5024\n",
      "Epoch 6/10\n",
      "248s - loss:  0.4259 - mse:  0.4258 - val_mse:  0.5026\n",
      "Epoch 7/10\n",
      "238s - loss:  0.4191 - mse:  0.4189 - val_mse:  0.5034\n",
      "Epoch 8/10\n",
      "248s - loss:  0.4125 - mse:  0.4123 - val_mse:  0.5059\n",
      "Epoch 9/10\n",
      "236s - loss:  0.4040 - mse:  0.4037 - val_mse:  0.5117\n",
      "Epoch 10/10\n",
      "230s - loss:  0.3946 - mse:  0.3943 - val_mse:  0.5179\n"
     ]
    }
   ],
   "source": [
    "nfm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = nfm.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-option",
   "metadata": {},
   "source": [
    "### Deep Interest Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "decimal-personality",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import DIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "thirty-island",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_feature_list = np.array([\"cols_0\", \"cols_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "severe-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "din = DIN(dnn_feature_columns, behavior_feature_list, task='regression', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "extensive-speaker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'VarLenSparseFeat' object has no attribute 'use_hash'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-c5fe815ca6cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrating\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/deepctr_torch/models/basemodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, initial_epoch, validation_split, validation_data, shuffle, callbacks)\u001b[0m\n\u001b[1;32m    239\u001b[0m                         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/deepctr_torch/models/din.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         sequence_embed_dict = varlen_embedding_lookup(X, self.embedding_dict, self.feature_index,\n\u001b[0;32m---> 95\u001b[0;31m                                                       self.sparse_varlen_feature_columns)\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         sequence_embed_list = get_varlen_pooling_list(sequence_embed_dict, X, self.feature_index,\n",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/deepctr_torch/inputs.py\u001b[0m in \u001b[0;36mvarlen_embedding_lookup\u001b[0;34m(X, embedding_dict, sequence_input_dict, varlen_sparse_feature_columns)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mfeature_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0membedding_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_hash\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m             \u001b[0;31m# lookup_idx = Hash(fc.vocabulary_size, mask_zero=True)(sequence_input_dict[feature_name])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;31m# TODO: add hash function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VarLenSparseFeat' object has no attribute 'use_hash'"
     ]
    }
   ],
   "source": [
    "din.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = din.fit(model_input, train[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-handy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
