{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "published-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, ndcg_score, recall_score\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "seven-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "\n",
    "from deepctr_torch.inputs import SparseFeat, VarLenSparseFeat, get_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "specific-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import DIN\n",
    "from deepctr_torch.models import AFM\n",
    "from deepctr_torch.models import WDL\n",
    "from deepctr_torch.models import xDeepFM\n",
    "from deepctr_torch.models import DeepFM\n",
    "from deepctr_torch.models import PNN\n",
    "from deepctr_torch.models import DCN\n",
    "from deepctr_torch.models import CCPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "turkish-thickness",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "laden-certificate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda ready...\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "use_cuda = True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    print('cuda ready...')\n",
    "    device = 'cuda:0'\n",
    "\n",
    "root = os.path.join(os.getcwd(), \"Yelp\")\n",
    "rel_p = os.path.join(root, \"user_business.dat\")\n",
    "\n",
    "user_cnt = 16239"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-diesel",
   "metadata": {},
   "source": [
    "### User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "numeric-victory",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compliment, compliment_i, compliment_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"Yelp\", \"user_compliment.dat\"), user_cnt=user_cnt)\n",
    "user, user_i, user_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"Yelp\", \"user_user.dat\"), user_cnt=user_cnt)\n",
    "# user, user_i, user_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"Movielens\", \"user_user.dat\"), user_cnt=user_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-tomato",
   "metadata": {},
   "source": [
    "### Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "secure-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "city, city_i, city_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"Yelp\", \"business_city.dat\"), user_cnt=14284)\n",
    "category, category_i, category_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"Yelp\", \"business_category.dat\"), user_cnt=14284)\n",
    "# author, author_i, author_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"Movielens\", \"book_author.dat\"), user_cnt=user_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-karma",
   "metadata": {},
   "source": [
    "### Interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "atlantic-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = [\"cols_0\", \"cols_1\"] # user_id, movie_id\n",
    "rating = \"cols_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "color-peninsula",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cols_0</th>\n",
       "      <th>cols_1</th>\n",
       "      <th>cols_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8391</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8971</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>186</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>205</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>209</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cols_0  cols_1  cols_2\n",
       "0       1    8391       5\n",
       "1       1    8971       5\n",
       "2       2     186       5\n",
       "3       2     205       5\n",
       "4       2     209       4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel = utils.read_file(rel_p)\n",
    "rel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "moved-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "_compliment = compliment[rel.cols_0 -1]\n",
    "_user = user[rel.cols_0 -1]\n",
    "# _user = user[rel.cols_0 -1]\n",
    "\n",
    "_category = category[rel.cols_1 -1]\n",
    "_city = city[rel.cols_1 -1]\n",
    "# _author = author[rel.cols_1 -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "transsexual-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Label Encoding for sparse features,and process sequence features\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    rel[feat] = lbe.fit_transform(rel[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "disciplinary-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, rel[feat].nunique(), embedding_dim=4) for feat in sparse_features]\n",
    "\n",
    "varlen_feature_columns = [\n",
    "    VarLenSparseFeat(SparseFeat('compliment', vocabulary_size=compliment_i + 1, embedding_dim=4), maxlen=compliment_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('user', vocabulary_size=user_cnt + 1, embedding_dim=4), maxlen=user_m, combiner='mean'),\n",
    "#     VarLenSparseFeat(SparseFeat('user', vocabulary_size=13024 + 1, embedding_dim=4), maxlen=user_m, combiner='mean'),\n",
    "    \n",
    "    VarLenSparseFeat(SparseFeat('category', vocabulary_size=category_i + 1, embedding_dim=4), maxlen=category_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('city', vocabulary_size=city_i + 1, embedding_dim=4), maxlen=city_m, combiner='mean'),\n",
    "#     VarLenSparseFeat(SparseFeat('author', vocabulary_size=author_i + 1, embedding_dim=4), maxlen=author_m, combiner='mean')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "clean-tuition",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-representation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "proud-registrar",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "consecutive-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepfm_mse = 0\n",
    "ccpm_mse = 0\n",
    "ipnn_mse = 0\n",
    "opnn_mse = 0\n",
    "wdl_mse = 0\n",
    "dcn_mse = 0\n",
    "xdeepfm_mse = 0\n",
    "afm_mse = 0\n",
    "din_mse = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cross-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepfm_recall = 0\n",
    "ccpm_recall = 0\n",
    "ipnn_recall = 0\n",
    "opnn_recall = 0\n",
    "wdl_recall = 0\n",
    "dcn_recall = 0\n",
    "xdeepfm_recall = 0\n",
    "afm_recall = 0\n",
    "din_recall = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hidden-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepfm_ndcg = 0\n",
    "ccpm_ndcg = 0\n",
    "ipnn_ndcg = 0\n",
    "opnn_ndcg = 0\n",
    "wdl_ndcg = 0\n",
    "dcn_ndcg = 0\n",
    "xdeepfm_ndcg = 0\n",
    "afm_ndcg = 0\n",
    "din_ndcg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "optical-strengthening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================== 1 Fold ==============================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Training DeepFM \n",
      "\n",
      "cuda:0\n",
      "Train on 142845 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "64s - loss:  1.7934 - mse:  1.7934 - val_mse:  1.1672\n",
      "Epoch 2/10\n",
      "61s - loss:  0.9725 - mse:  0.9725 - val_mse:  1.1570\n",
      "Epoch 3/10\n",
      "63s - loss:  0.9110 - mse:  0.9110 - val_mse:  1.1602\n",
      "Epoch 4/10\n",
      "60s - loss:  0.8823 - mse:  0.8823 - val_mse:  1.1760\n",
      "Epoch 5/10\n",
      "63s - loss:  0.8664 - mse:  0.8664 - val_mse:  1.1774\n",
      "Epoch 6/10\n",
      "60s - loss:  0.8544 - mse:  0.8544 - val_mse:  1.1423\n",
      "Epoch 7/10\n",
      "62s - loss:  0.8465 - mse:  0.8465 - val_mse:  1.1677\n",
      "Epoch 8/10\n",
      "63s - loss:  0.8414 - mse:  0.8413 - val_mse:  1.1381\n",
      "Epoch 9/10\n",
      "60s - loss:  0.8347 - mse:  0.8347 - val_mse:  1.1819\n",
      "Epoch 10/10\n",
      "63s - loss:  0.8315 - mse:  0.8315 - val_mse:  1.1845\n",
      "\n",
      "\n",
      " Training CCPM \n",
      "\n",
      "cuda:0\n",
      "Train on 142845 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "63s - loss:  1.7181 - mse:  1.7181 - val_mse:  1.1124\n",
      "Epoch 2/10\n",
      "63s - loss:  0.9876 - mse:  0.9876 - val_mse:  1.1001\n",
      "Epoch 3/10\n",
      "57s - loss:  0.9119 - mse:  0.9119 - val_mse:  1.1280\n",
      "Epoch 4/10\n",
      "63s - loss:  0.8764 - mse:  0.8764 - val_mse:  1.1356\n",
      "Epoch 5/10\n",
      "61s - loss:  0.8551 - mse:  0.8550 - val_mse:  1.1456\n",
      "Epoch 6/10\n",
      "64s - loss:  0.8386 - mse:  0.8385 - val_mse:  1.1435\n",
      "Epoch 7/10\n",
      "61s - loss:  0.8253 - mse:  0.8253 - val_mse:  1.1779\n",
      "Epoch 8/10\n",
      "64s - loss:  0.8093 - mse:  0.8092 - val_mse:  1.1667\n",
      "Epoch 9/10\n",
      "54s - loss:  0.7942 - mse:  0.7942 - val_mse:  1.2226\n",
      "Epoch 10/10\n",
      "62s - loss:  0.7768 - mse:  0.7767 - val_mse:  1.2025\n",
      "\n",
      "\n",
      " Training IPMM \n",
      "\n",
      "cuda:0\n",
      "Train on 142845 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "33s - loss:  2.0160 - mse:  2.0160 - val_mse:  1.2293\n",
      "Epoch 2/10\n",
      "36s - loss:  0.9744 - mse:  0.9744 - val_mse:  1.2209\n",
      "Epoch 3/10\n",
      "36s - loss:  0.9090 - mse:  0.9090 - val_mse:  1.2065\n",
      "Epoch 4/10\n",
      "36s - loss:  0.8769 - mse:  0.8769 - val_mse:  1.1523\n",
      "Epoch 5/10\n",
      "33s - loss:  0.8580 - mse:  0.8580 - val_mse:  1.1847\n",
      "Epoch 6/10\n",
      "35s - loss:  0.8449 - mse:  0.8449 - val_mse:  1.1920\n",
      "Epoch 7/10\n",
      "36s - loss:  0.8324 - mse:  0.8324 - val_mse:  1.1923\n",
      "Epoch 8/10\n",
      "32s - loss:  0.8225 - mse:  0.8225 - val_mse:  1.1980\n",
      "Epoch 9/10\n",
      "35s - loss:  0.8077 - mse:  0.8077 - val_mse:  1.1645\n",
      "Epoch 10/10\n",
      "36s - loss:  0.7888 - mse:  0.7887 - val_mse:  1.1832\n",
      "\n",
      "\n",
      " Training OPNN \n",
      "\n",
      "cuda:0\n",
      "Train on 142845 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "36s - loss:  1.9161 - mse:  1.9161 - val_mse:  1.2586\n",
      "Epoch 2/10\n",
      "33s - loss:  0.9734 - mse:  0.9733 - val_mse:  1.1784\n",
      "Epoch 3/10\n",
      "37s - loss:  0.9093 - mse:  0.9093 - val_mse:  1.1781\n",
      "Epoch 4/10\n",
      "37s - loss:  0.8772 - mse:  0.8772 - val_mse:  1.1736\n",
      "Epoch 5/10\n",
      "32s - loss:  0.8578 - mse:  0.8578 - val_mse:  1.1608\n",
      "Epoch 6/10\n",
      "36s - loss:  0.8447 - mse:  0.8446 - val_mse:  1.1483\n",
      "Epoch 7/10\n",
      "36s - loss:  0.8303 - mse:  0.8302 - val_mse:  1.1890\n",
      "Epoch 8/10\n",
      "37s - loss:  0.8100 - mse:  0.8100 - val_mse:  1.1624\n",
      "Epoch 9/10\n",
      "34s - loss:  0.7844 - mse:  0.7844 - val_mse:  1.1455\n",
      "Epoch 10/10\n",
      "37s - loss:  0.7628 - mse:  0.7627 - val_mse:  1.1570\n",
      "\n",
      "\n",
      " Training Wide&Deep \n",
      "\n",
      "cuda:0\n",
      "Train on 142845 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "61s - loss:  1.7973 - mse:  1.7973 - val_mse:  1.1573\n",
      "Epoch 2/10\n",
      "59s - loss:  0.9719 - mse:  0.9719 - val_mse:  1.1504\n",
      "Epoch 3/10\n",
      "63s - loss:  0.9100 - mse:  0.9100 - val_mse:  1.1555\n",
      "Epoch 4/10\n",
      "60s - loss:  0.8812 - mse:  0.8812 - val_mse:  1.1704\n",
      "Epoch 5/10\n",
      "63s - loss:  0.8652 - mse:  0.8652 - val_mse:  1.1747\n",
      "Epoch 6/10\n",
      "59s - loss:  0.8531 - mse:  0.8531 - val_mse:  1.1429\n",
      "Epoch 7/10\n",
      "63s - loss:  0.8453 - mse:  0.8453 - val_mse:  1.1660\n",
      "Epoch 8/10\n",
      "54s - loss:  0.8403 - mse:  0.8402 - val_mse:  1.1394\n",
      "Epoch 9/10\n",
      "62s - loss:  0.8337 - mse:  0.8337 - val_mse:  1.1828\n",
      "Epoch 10/10\n",
      "60s - loss:  0.8308 - mse:  0.8307 - val_mse:  1.1849\n",
      "\n",
      "\n",
      " Training DCN \n",
      "\n",
      "cuda:0\n",
      "Train on 142845 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "62s - loss:  1.8897 - mse:  1.8897 - val_mse:  1.2256\n",
      "Epoch 2/10\n",
      "58s - loss:  0.9731 - mse:  0.9731 - val_mse:  1.2090\n",
      "Epoch 3/10\n",
      "65s - loss:  0.9114 - mse:  0.9114 - val_mse:  1.2230\n",
      "Epoch 4/10\n",
      "61s - loss:  0.8807 - mse:  0.8807 - val_mse:  1.1740\n",
      "Epoch 5/10\n",
      "62s - loss:  0.8635 - mse:  0.8635 - val_mse:  1.1611\n",
      "Epoch 6/10\n",
      "59s - loss:  0.8521 - mse:  0.8520 - val_mse:  1.1621\n",
      "Epoch 7/10\n",
      "65s - loss:  0.8430 - mse:  0.8430 - val_mse:  1.1472\n",
      "Epoch 8/10\n",
      "61s - loss:  0.8372 - mse:  0.8372 - val_mse:  1.1805\n",
      "Epoch 9/10\n",
      "64s - loss:  0.8298 - mse:  0.8298 - val_mse:  1.1616\n",
      "Epoch 10/10\n",
      "58s - loss:  0.8246 - mse:  0.8246 - val_mse:  1.1663\n",
      "\n",
      "\n",
      " Training xDeepFM \n",
      "\n",
      "cuda:0\n",
      "Train on 142845 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "64s - loss:  1.4291 - mse:  1.4290 - val_mse:  1.1159\n",
      "Epoch 2/10\n",
      "63s - loss:  0.9659 - mse:  0.9659 - val_mse:  1.0926\n",
      "Epoch 3/10\n",
      "66s - loss:  0.9049 - mse:  0.9049 - val_mse:  1.1016\n",
      "Epoch 4/10\n",
      "61s - loss:  0.8743 - mse:  0.8743 - val_mse:  1.1178\n",
      "Epoch 5/10\n",
      "66s - loss:  0.8536 - mse:  0.8536 - val_mse:  1.1366\n",
      "Epoch 6/10\n",
      "63s - loss:  0.8360 - mse:  0.8359 - val_mse:  1.1534\n",
      "Epoch 7/10\n",
      "66s - loss:  0.8201 - mse:  0.8201 - val_mse:  1.1624\n",
      "Epoch 8/10\n",
      "59s - loss:  0.8073 - mse:  0.8072 - val_mse:  1.1595\n",
      "Epoch 9/10\n",
      "67s - loss:  0.7966 - mse:  0.7966 - val_mse:  1.1515\n",
      "Epoch 10/10\n",
      "62s - loss:  0.7852 - mse:  0.7851 - val_mse:  1.1682\n",
      "\n",
      "\n",
      " Training AFM \n",
      "\n",
      "cuda:0\n",
      "Train on 142845 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "63s - loss:  6.6383 - mse:  6.6382 - val_mse:  8.8579\n",
      "Epoch 2/10\n",
      "60s - loss:  1.3828 - mse:  1.3828 - val_mse:  8.2118\n",
      "Epoch 3/10\n",
      "63s - loss:  1.2290 - mse:  1.2289 - val_mse:  7.6428\n",
      "Epoch 4/10\n",
      "59s - loss:  1.1292 - mse:  1.1291 - val_mse:  7.2282\n",
      "Epoch 5/10\n",
      "61s - loss:  1.0570 - mse:  1.0569 - val_mse:  6.9337\n",
      "Epoch 6/10\n",
      "62s - loss:  1.0026 - mse:  1.0025 - val_mse:  6.7743\n",
      "Epoch 7/10\n",
      "61s - loss:  0.9602 - mse:  0.9601 - val_mse:  6.6987\n",
      "Epoch 8/10\n",
      "63s - loss:  0.9294 - mse:  0.9292 - val_mse:  6.6548\n",
      "Epoch 9/10\n",
      "59s - loss:  0.9064 - mse:  0.9062 - val_mse:  6.6826\n",
      "Epoch 10/10\n",
      "60s - loss:  0.8884 - mse:  0.8882 - val_mse:  6.6666\n",
      "========================== 2 Fold ==============================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Training DeepFM \n",
      "\n",
      "cuda:0\n",
      "Train on 142845 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "59s - loss:  1.7874 - mse:  1.7874 - val_mse:  1.1603\n",
      "Epoch 2/10\n",
      "63s - loss:  0.9668 - mse:  0.9668 - val_mse:  1.1749\n",
      "Epoch 3/10\n",
      "58s - loss:  0.9049 - mse:  0.9049 - val_mse:  1.1641\n",
      "Epoch 4/10\n",
      "63s - loss:  0.8762 - mse:  0.8762 - val_mse:  1.1744\n",
      "Epoch 5/10\n",
      "60s - loss:  0.8602 - mse:  0.8602 - val_mse:  1.1778\n",
      "Epoch 6/10\n",
      "64s - loss:  0.8486 - mse:  0.8486 - val_mse:  1.1658\n",
      "Epoch 7/10\n",
      "59s - loss:  0.8403 - mse:  0.8403 - val_mse:  1.1349\n",
      "Epoch 8/10\n",
      "64s - loss:  0.8353 - mse:  0.8353 - val_mse:  1.1213\n",
      "Epoch 9/10\n",
      "54s - loss:  0.8292 - mse:  0.8291 - val_mse:  1.1663\n",
      "Epoch 10/10\n",
      "61s - loss:  0.8250 - mse:  0.8249 - val_mse:  1.1648\n",
      "\n",
      "\n",
      " Training CCPM \n",
      "\n",
      "cuda:0\n",
      "Train on 142845 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "60s - loss:  1.7139 - mse:  1.7139 - val_mse:  1.1168\n",
      "Epoch 2/10\n",
      "64s - loss:  0.9815 - mse:  0.9815 - val_mse:  1.1160\n",
      "Epoch 3/10\n",
      "60s - loss:  0.9060 - mse:  0.9060 - val_mse:  1.1161\n",
      "Epoch 4/10\n",
      "62s - loss:  0.8709 - mse:  0.8709 - val_mse:  1.1329\n",
      "Epoch 5/10\n",
      "61s - loss:  0.8489 - mse:  0.8489 - val_mse:  1.1567\n",
      "Epoch 6/10\n",
      "65s - loss:  0.8345 - mse:  0.8345 - val_mse:  1.1275\n",
      "Epoch 7/10\n",
      "61s - loss:  0.8208 - mse:  0.8207 - val_mse:  1.1759\n",
      "Epoch 8/10\n",
      "64s - loss:  0.8071 - mse:  0.8071 - val_mse:  1.1929\n",
      "Epoch 9/10\n",
      "59s - loss:  0.7944 - mse:  0.7944 - val_mse:  1.2009\n",
      "Epoch 10/10\n",
      "65s - loss:  0.7784 - mse:  0.7783 - val_mse:  1.2071\n",
      "\n",
      "\n",
      " Training IPMM \n",
      "\n",
      "cuda:0\n",
      "Train on 142845 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "37s - loss:  2.0103 - mse:  2.0103 - val_mse:  1.2359\n",
      "Epoch 2/10\n",
      "34s - loss:  0.9680 - mse:  0.9680 - val_mse:  1.2024\n",
      "Epoch 3/10\n",
      "36s - loss:  0.9023 - mse:  0.9023 - val_mse:  1.1865\n",
      "Epoch 4/10\n",
      "36s - loss:  0.8707 - mse:  0.8707 - val_mse:  1.1539\n",
      "Epoch 5/10\n",
      "33s - loss:  0.8510 - mse:  0.8510 - val_mse:  1.1863\n",
      "Epoch 6/10\n",
      "36s - loss:  0.8360 - mse:  0.8359 - val_mse:  1.1865\n",
      "Epoch 7/10\n",
      "34s - loss:  0.8208 - mse:  0.8208 - val_mse:  1.2123\n",
      "Epoch 8/10\n",
      "36s - loss:  0.8040 - mse:  0.8040 - val_mse:  1.1808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "33s - loss:  0.7849 - mse:  0.7849 - val_mse:  1.1844\n",
      "Epoch 10/10\n",
      "36s - loss:  0.7644 - mse:  0.7644 - val_mse:  1.1795\n",
      "\n",
      "\n",
      " Training OPNN \n",
      "\n",
      "cuda:0\n",
      "Train on 142845 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "37s - loss:  1.9124 - mse:  1.9124 - val_mse:  1.2431\n",
      "Epoch 2/10\n",
      "33s - loss:  0.9678 - mse:  0.9678 - val_mse:  1.1678\n",
      "Epoch 3/10\n",
      "36s - loss:  0.9036 - mse:  0.9036 - val_mse:  1.1616\n",
      "Epoch 4/10\n",
      "35s - loss:  0.8717 - mse:  0.8717 - val_mse:  1.1857\n",
      "Epoch 5/10\n",
      "36s - loss:  0.8527 - mse:  0.8526 - val_mse:  1.1666\n",
      "Epoch 6/10\n",
      "29s - loss:  0.8386 - mse:  0.8386 - val_mse:  1.1422\n",
      "Epoch 7/10\n",
      "36s - loss:  0.8238 - mse:  0.8238 - val_mse:  1.1638\n",
      "Epoch 8/10\n",
      "37s - loss:  0.8061 - mse:  0.8061 - val_mse:  1.1535\n",
      "Epoch 9/10\n",
      "37s - loss:  0.7823 - mse:  0.7823 - val_mse:  1.1513\n",
      "Epoch 10/10\n",
      "34s - loss:  0.7617 - mse:  0.7617 - val_mse:  1.1478\n",
      "\n",
      "\n",
      " Training Wide&Deep \n",
      "\n",
      "cuda:0\n",
      "Train on 142845 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "62s - loss:  1.7917 - mse:  1.7917 - val_mse:  1.1504\n",
      "Epoch 2/10\n",
      "58s - loss:  0.9663 - mse:  0.9663 - val_mse:  1.1664\n",
      "Epoch 3/10\n",
      "62s - loss:  0.9041 - mse:  0.9041 - val_mse:  1.1582\n",
      "Epoch 4/10\n",
      "59s - loss:  0.8751 - mse:  0.8751 - val_mse:  1.1690\n",
      "Epoch 5/10\n",
      "63s - loss:  0.8591 - mse:  0.8591 - val_mse:  1.1744\n",
      "Epoch 6/10\n",
      "59s - loss:  0.8475 - mse:  0.8474 - val_mse:  1.1658\n",
      "Epoch 7/10\n",
      "63s - loss:  0.8392 - mse:  0.8392 - val_mse:  1.1355\n",
      "Epoch 8/10\n",
      "59s - loss:  0.8343 - mse:  0.8343 - val_mse:  1.1233\n",
      "Epoch 9/10\n",
      "62s - loss:  0.8283 - mse:  0.8283 - val_mse:  1.1667\n",
      "Epoch 10/10\n",
      "60s - loss:  0.8243 - mse:  0.8243 - val_mse:  1.1647\n",
      "\n",
      "\n",
      " Training DCN \n",
      "\n",
      "cuda:0\n",
      "Train on 142845 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "64s - loss:  1.8857 - mse:  1.8857 - val_mse:  1.2470\n",
      "Epoch 2/10\n",
      "63s - loss:  0.9669 - mse:  0.9668 - val_mse:  1.1834\n",
      "Epoch 3/10\n",
      "64s - loss:  0.9051 - mse:  0.9051 - val_mse:  1.2178\n",
      "Epoch 4/10\n",
      "62s - loss:  0.8751 - mse:  0.8751 - val_mse:  1.1852\n",
      "Epoch 5/10\n",
      "62s - loss:  0.8573 - mse:  0.8573 - val_mse:  1.1610\n",
      "Epoch 6/10\n",
      "65s - loss:  0.8462 - mse:  0.8461 - val_mse:  1.1439\n",
      "Epoch 7/10\n",
      "61s - loss:  0.8371 - mse:  0.8371 - val_mse:  1.1467\n",
      "Epoch 8/10\n",
      "65s - loss:  0.8314 - mse:  0.8314 - val_mse:  1.1560\n",
      "Epoch 9/10\n",
      "53s - loss:  0.8245 - mse:  0.8244 - val_mse:  1.2010\n",
      "Epoch 10/10\n",
      "65s - loss:  0.8200 - mse:  0.8199 - val_mse:  1.2075\n",
      "\n",
      "\n",
      " Training xDeepFM \n",
      "\n",
      "cuda:0\n",
      "Train on 142845 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "62s - loss:  1.4190 - mse:  1.4190 - val_mse:  1.1113\n",
      "Epoch 2/10\n",
      "63s - loss:  0.9592 - mse:  0.9592 - val_mse:  1.0971\n",
      "Epoch 3/10\n",
      "64s - loss:  0.8987 - mse:  0.8987 - val_mse:  1.1250\n",
      "Epoch 4/10\n",
      "67s - loss:  0.8697 - mse:  0.8696 - val_mse:  1.1156\n",
      "Epoch 5/10\n",
      "63s - loss:  0.8503 - mse:  0.8503 - val_mse:  1.1344\n",
      "Epoch 6/10\n",
      "66s - loss:  0.8357 - mse:  0.8356 - val_mse:  1.1521\n",
      "Epoch 7/10\n",
      "63s - loss:  0.8210 - mse:  0.8210 - val_mse:  1.1675\n",
      "Epoch 8/10\n",
      "64s - loss:  0.8067 - mse:  0.8066 - val_mse:  1.1422\n",
      "Epoch 9/10\n",
      "61s - loss:  0.7946 - mse:  0.7946 - val_mse:  1.1436\n",
      "Epoch 10/10\n",
      "67s - loss:  0.7842 - mse:  0.7842 - val_mse:  1.1809\n",
      "\n",
      "\n",
      " Training AFM \n",
      "\n",
      "cuda:0\n",
      "Train on 142845 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "60s - loss:  6.7216 - mse:  6.7215 - val_mse:  8.7330\n",
      "Epoch 2/10\n",
      "62s - loss:  1.3880 - mse:  1.3879 - val_mse:  8.0772\n",
      "Epoch 3/10\n",
      "61s - loss:  1.2299 - mse:  1.2299 - val_mse:  7.4943\n",
      "Epoch 4/10\n",
      "65s - loss:  1.1253 - mse:  1.1252 - val_mse:  7.0433\n",
      "Epoch 5/10\n",
      "60s - loss:  1.0481 - mse:  1.0479 - val_mse:  6.7399\n",
      "Epoch 6/10\n",
      "61s - loss:  0.9907 - mse:  0.9906 - val_mse:  6.5808\n",
      "Epoch 7/10\n",
      "57s - loss:  0.9479 - mse:  0.9478 - val_mse:  6.4893\n",
      "Epoch 8/10\n",
      "62s - loss:  0.9165 - mse:  0.9164 - val_mse:  6.4473\n",
      "Epoch 9/10\n",
      "55s - loss:  0.8943 - mse:  0.8941 - val_mse:  6.4573\n",
      "Epoch 10/10\n",
      "64s - loss:  0.8772 - mse:  0.8770 - val_mse:  6.4674\n",
      "========================== 3 Fold ==============================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Training DeepFM \n",
      "\n",
      "cuda:0\n",
      "Train on 142846 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "60s - loss:  1.7668 - mse:  1.7667 - val_mse:  1.1919\n",
      "Epoch 2/10\n",
      "64s - loss:  0.9591 - mse:  0.9591 - val_mse:  1.1347\n",
      "Epoch 3/10\n",
      "59s - loss:  0.9002 - mse:  0.9002 - val_mse:  1.1628\n",
      "Epoch 4/10\n",
      "64s - loss:  0.8716 - mse:  0.8716 - val_mse:  1.1304\n",
      "Epoch 5/10\n",
      "59s - loss:  0.8557 - mse:  0.8556 - val_mse:  1.1513\n",
      "Epoch 6/10\n",
      "64s - loss:  0.8442 - mse:  0.8442 - val_mse:  1.2022\n",
      "Epoch 7/10\n",
      "60s - loss:  0.8369 - mse:  0.8368 - val_mse:  1.1769\n",
      "Epoch 8/10\n",
      "63s - loss:  0.8307 - mse:  0.8307 - val_mse:  1.2149\n",
      "Epoch 9/10\n",
      "59s - loss:  0.8254 - mse:  0.8253 - val_mse:  1.1517\n",
      "Epoch 10/10\n",
      "63s - loss:  0.8211 - mse:  0.8211 - val_mse:  1.1416\n",
      "\n",
      "\n",
      " Training CCPM \n",
      "\n",
      "cuda:0\n",
      "Train on 142846 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "57s - loss:  1.7065 - mse:  1.7065 - val_mse:  1.1310\n",
      "Epoch 2/10\n",
      "60s - loss:  0.9756 - mse:  0.9756 - val_mse:  1.1387\n",
      "Epoch 3/10\n",
      "58s - loss:  0.9014 - mse:  0.9014 - val_mse:  1.1284\n",
      "Epoch 4/10\n",
      "62s - loss:  0.8661 - mse:  0.8661 - val_mse:  1.1658\n",
      "Epoch 5/10\n",
      "62s - loss:  0.8458 - mse:  0.8458 - val_mse:  1.1713\n",
      "Epoch 6/10\n",
      "62s - loss:  0.8295 - mse:  0.8295 - val_mse:  1.1614\n",
      "Epoch 7/10\n",
      "64s - loss:  0.8157 - mse:  0.8156 - val_mse:  1.2351\n",
      "Epoch 8/10\n",
      "61s - loss:  0.8030 - mse:  0.8029 - val_mse:  1.1741\n",
      "Epoch 9/10\n",
      "64s - loss:  0.7880 - mse:  0.7879 - val_mse:  1.1769\n",
      "Epoch 10/10\n",
      "57s - loss:  0.7716 - mse:  0.7715 - val_mse:  1.2346\n",
      "\n",
      "\n",
      " Training IPMM \n",
      "\n",
      "cuda:0\n",
      "Train on 142846 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "37s - loss:  1.9987 - mse:  1.9987 - val_mse:  1.2155\n",
      "Epoch 2/10\n",
      "34s - loss:  0.9622 - mse:  0.9622 - val_mse:  1.2319\n",
      "Epoch 3/10\n",
      "37s - loss:  0.8980 - mse:  0.8980 - val_mse:  1.1526\n",
      "Epoch 4/10\n",
      "36s - loss:  0.8673 - mse:  0.8673 - val_mse:  1.1907\n",
      "Epoch 5/10\n",
      "37s - loss:  0.8475 - mse:  0.8475 - val_mse:  1.1697\n",
      "Epoch 6/10\n",
      "31s - loss:  0.8355 - mse:  0.8354 - val_mse:  1.1711\n",
      "Epoch 7/10\n",
      "35s - loss:  0.8258 - mse:  0.8258 - val_mse:  1.1953\n",
      "Epoch 8/10\n",
      "36s - loss:  0.8153 - mse:  0.8152 - val_mse:  1.1771\n",
      "Epoch 9/10\n",
      "36s - loss:  0.8038 - mse:  0.8037 - val_mse:  1.1630\n",
      "Epoch 10/10\n",
      "33s - loss:  0.7905 - mse:  0.7904 - val_mse:  1.1745\n",
      "\n",
      "\n",
      " Training OPNN \n",
      "\n",
      "cuda:0\n",
      "Train on 142846 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "37s - loss:  1.9190 - mse:  1.9190 - val_mse:  1.2152\n",
      "Epoch 2/10\n",
      "37s - loss:  0.9609 - mse:  0.9609 - val_mse:  1.1858\n",
      "Epoch 3/10\n",
      "33s - loss:  0.8978 - mse:  0.8978 - val_mse:  1.1767\n",
      "Epoch 4/10\n",
      "36s - loss:  0.8672 - mse:  0.8671 - val_mse:  1.1598\n",
      "Epoch 5/10\n",
      "37s - loss:  0.8478 - mse:  0.8477 - val_mse:  1.2018\n",
      "Epoch 6/10\n",
      "37s - loss:  0.8348 - mse:  0.8348 - val_mse:  1.1779\n",
      "Epoch 7/10\n",
      "34s - loss:  0.8201 - mse:  0.8201 - val_mse:  1.2070\n",
      "Epoch 8/10\n",
      "37s - loss:  0.7995 - mse:  0.7995 - val_mse:  1.1782\n",
      "Epoch 9/10\n",
      "37s - loss:  0.7761 - mse:  0.7761 - val_mse:  1.1595\n",
      "Epoch 10/10\n",
      "33s - loss:  0.7534 - mse:  0.7534 - val_mse:  1.1706\n",
      "\n",
      "\n",
      " Training Wide&Deep \n",
      "\n",
      "cuda:0\n",
      "Train on 142846 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "61s - loss:  1.7698 - mse:  1.7697 - val_mse:  1.1874\n",
      "Epoch 2/10\n",
      "57s - loss:  0.9589 - mse:  0.9589 - val_mse:  1.1342\n",
      "Epoch 3/10\n",
      "62s - loss:  0.8994 - mse:  0.8994 - val_mse:  1.1630\n",
      "Epoch 4/10\n",
      "60s - loss:  0.8706 - mse:  0.8706 - val_mse:  1.1315\n",
      "Epoch 5/10\n",
      "62s - loss:  0.8546 - mse:  0.8546 - val_mse:  1.1527\n",
      "Epoch 6/10\n",
      "63s - loss:  0.8431 - mse:  0.8431 - val_mse:  1.2049\n",
      "Epoch 7/10\n",
      "59s - loss:  0.8358 - mse:  0.8358 - val_mse:  1.1799\n",
      "Epoch 8/10\n",
      "63s - loss:  0.8298 - mse:  0.8298 - val_mse:  1.2168\n",
      "Epoch 9/10\n",
      "51s - loss:  0.8246 - mse:  0.8245 - val_mse:  1.1530\n",
      "Epoch 10/10\n",
      "63s - loss:  0.8206 - mse:  0.8206 - val_mse:  1.1446\n",
      "\n",
      "\n",
      " Training DCN \n",
      "\n",
      "cuda:0\n",
      "Train on 142846 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "61s - loss:  1.8729 - mse:  1.8729 - val_mse:  1.2306\n",
      "Epoch 2/10\n",
      "64s - loss:  0.9611 - mse:  0.9610 - val_mse:  1.2000\n",
      "Epoch 3/10\n",
      "57s - loss:  0.8995 - mse:  0.8994 - val_mse:  1.2018\n",
      "Epoch 4/10\n",
      "64s - loss:  0.8708 - mse:  0.8708 - val_mse:  1.2115\n",
      "Epoch 5/10\n",
      "60s - loss:  0.8535 - mse:  0.8535 - val_mse:  1.1774\n",
      "Epoch 6/10\n",
      "64s - loss:  0.8422 - mse:  0.8422 - val_mse:  1.1745\n",
      "Epoch 7/10\n",
      "63s - loss:  0.8336 - mse:  0.8335 - val_mse:  1.1627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "66s - loss:  0.8268 - mse:  0.8267 - val_mse:  1.1531\n",
      "Epoch 9/10\n",
      "62s - loss:  0.8210 - mse:  0.8210 - val_mse:  1.1805\n",
      "Epoch 10/10\n",
      "66s - loss:  0.8152 - mse:  0.8151 - val_mse:  1.1489\n",
      "\n",
      "\n",
      " Training xDeepFM \n",
      "\n",
      "cuda:0\n",
      "Train on 142846 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "63s - loss:  1.4119 - mse:  1.4119 - val_mse:  1.1601\n",
      "Epoch 2/10\n",
      "67s - loss:  0.9533 - mse:  0.9533 - val_mse:  1.1137\n",
      "Epoch 3/10\n",
      "63s - loss:  0.8936 - mse:  0.8936 - val_mse:  1.1084\n",
      "Epoch 4/10\n",
      "67s - loss:  0.8638 - mse:  0.8638 - val_mse:  1.1356\n",
      "Epoch 5/10\n",
      "63s - loss:  0.8423 - mse:  0.8423 - val_mse:  1.1167\n",
      "Epoch 6/10\n",
      "67s - loss:  0.8248 - mse:  0.8248 - val_mse:  1.1398\n",
      "Epoch 7/10\n",
      "64s - loss:  0.8097 - mse:  0.8097 - val_mse:  1.1364\n",
      "Epoch 8/10\n",
      "66s - loss:  0.7968 - mse:  0.7968 - val_mse:  1.1314\n",
      "Epoch 9/10\n",
      "60s - loss:  0.7849 - mse:  0.7848 - val_mse:  1.1685\n",
      "Epoch 10/10\n",
      "66s - loss:  0.7740 - mse:  0.7740 - val_mse:  1.1414\n",
      "\n",
      "\n",
      " Training AFM \n",
      "\n",
      "cuda:0\n",
      "Train on 142846 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "62s - loss:  6.6213 - mse:  6.6212 - val_mse:  8.8358\n",
      "Epoch 2/10\n",
      "64s - loss:  1.3710 - mse:  1.3710 - val_mse:  8.1928\n",
      "Epoch 3/10\n",
      "60s - loss:  1.2173 - mse:  1.2172 - val_mse:  7.6115\n",
      "Epoch 4/10\n",
      "64s - loss:  1.1181 - mse:  1.1181 - val_mse:  7.1957\n",
      "Epoch 5/10\n",
      "60s - loss:  1.0463 - mse:  1.0462 - val_mse:  6.9050\n",
      "Epoch 6/10\n",
      "64s - loss:  0.9922 - mse:  0.9921 - val_mse:  6.7256\n",
      "Epoch 7/10\n",
      "60s - loss:  0.9482 - mse:  0.9480 - val_mse:  6.6207\n",
      "Epoch 8/10\n",
      "62s - loss:  0.9153 - mse:  0.9152 - val_mse:  6.5550\n",
      "Epoch 9/10\n",
      "58s - loss:  0.8919 - mse:  0.8917 - val_mse:  6.5255\n",
      "Epoch 10/10\n",
      "63s - loss:  0.8735 - mse:  0.8733 - val_mse:  6.5366\n",
      "========================== 4 Fold ==============================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Training DeepFM \n",
      "\n",
      "cuda:0\n",
      "Train on 142846 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "58s - loss:  1.7788 - mse:  1.7788 - val_mse:  1.1920\n",
      "Epoch 2/10\n",
      "59s - loss:  0.9734 - mse:  0.9734 - val_mse:  1.1620\n",
      "Epoch 3/10\n",
      "58s - loss:  0.9115 - mse:  0.9115 - val_mse:  1.1398\n",
      "Epoch 4/10\n",
      "64s - loss:  0.8823 - mse:  0.8823 - val_mse:  1.1369\n",
      "Epoch 5/10\n",
      "61s - loss:  0.8654 - mse:  0.8654 - val_mse:  1.1654\n",
      "Epoch 6/10\n",
      "64s - loss:  0.8543 - mse:  0.8542 - val_mse:  1.1703\n",
      "Epoch 7/10\n",
      "61s - loss:  0.8471 - mse:  0.8471 - val_mse:  1.1952\n",
      "Epoch 8/10\n",
      "63s - loss:  0.8395 - mse:  0.8394 - val_mse:  1.2071\n",
      "Epoch 9/10\n",
      "55s - loss:  0.8360 - mse:  0.8359 - val_mse:  1.1674\n",
      "Epoch 10/10\n",
      "63s - loss:  0.8297 - mse:  0.8297 - val_mse:  1.1708\n",
      "\n",
      "\n",
      " Training CCPM \n",
      "\n",
      "cuda:0\n",
      "Train on 142846 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "61s - loss:  1.7169 - mse:  1.7168 - val_mse:  1.1410\n",
      "Epoch 2/10\n",
      "65s - loss:  0.9886 - mse:  0.9886 - val_mse:  1.1295\n",
      "Epoch 3/10\n",
      "61s - loss:  0.9124 - mse:  0.9124 - val_mse:  1.1271\n",
      "Epoch 4/10\n",
      "65s - loss:  0.8769 - mse:  0.8769 - val_mse:  1.1622\n",
      "Epoch 5/10\n",
      "61s - loss:  0.8551 - mse:  0.8551 - val_mse:  1.1765\n",
      "Epoch 6/10\n",
      "64s - loss:  0.8382 - mse:  0.8381 - val_mse:  1.1669\n",
      "Epoch 7/10\n",
      "61s - loss:  0.8228 - mse:  0.8228 - val_mse:  1.2183\n",
      "Epoch 8/10\n",
      "65s - loss:  0.8080 - mse:  0.8079 - val_mse:  1.2321\n",
      "Epoch 9/10\n",
      "61s - loss:  0.7895 - mse:  0.7894 - val_mse:  1.2059\n",
      "Epoch 10/10\n",
      "61s - loss:  0.7693 - mse:  0.7693 - val_mse:  1.2346\n",
      "\n",
      "\n",
      " Training IPMM \n",
      "\n",
      "cuda:0\n",
      "Train on 142846 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "36s - loss:  2.0156 - mse:  2.0156 - val_mse:  1.2448\n",
      "Epoch 2/10\n",
      "34s - loss:  0.9754 - mse:  0.9754 - val_mse:  1.2422\n",
      "Epoch 3/10\n",
      "34s - loss:  0.9094 - mse:  0.9094 - val_mse:  1.1680\n",
      "Epoch 4/10\n",
      "35s - loss:  0.8773 - mse:  0.8773 - val_mse:  1.2197\n",
      "Epoch 5/10\n",
      "35s - loss:  0.8576 - mse:  0.8576 - val_mse:  1.1739\n",
      "Epoch 6/10\n",
      "32s - loss:  0.8449 - mse:  0.8449 - val_mse:  1.1583\n",
      "Epoch 7/10\n",
      "34s - loss:  0.8337 - mse:  0.8337 - val_mse:  1.2359\n",
      "Epoch 8/10\n",
      "35s - loss:  0.8217 - mse:  0.8217 - val_mse:  1.1808\n",
      "Epoch 9/10\n",
      "36s - loss:  0.8072 - mse:  0.8071 - val_mse:  1.1690\n",
      "Epoch 10/10\n",
      "32s - loss:  0.7912 - mse:  0.7911 - val_mse:  1.1830\n",
      "\n",
      "\n",
      " Training OPNN \n",
      "\n",
      "cuda:0\n",
      "Train on 142846 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "36s - loss:  1.9273 - mse:  1.9272 - val_mse:  1.1992\n",
      "Epoch 2/10\n",
      "35s - loss:  0.9738 - mse:  0.9738 - val_mse:  1.2201\n",
      "Epoch 3/10\n",
      "33s - loss:  0.9091 - mse:  0.9091 - val_mse:  1.2047\n",
      "Epoch 4/10\n",
      "37s - loss:  0.8779 - mse:  0.8779 - val_mse:  1.1521\n",
      "Epoch 5/10\n",
      "35s - loss:  0.8582 - mse:  0.8582 - val_mse:  1.1841\n",
      "Epoch 6/10\n",
      "36s - loss:  0.8441 - mse:  0.8441 - val_mse:  1.1852\n",
      "Epoch 7/10\n",
      "30s - loss:  0.8278 - mse:  0.8278 - val_mse:  1.1872\n",
      "Epoch 8/10\n",
      "37s - loss:  0.8072 - mse:  0.8071 - val_mse:  1.1729\n",
      "Epoch 9/10\n",
      "37s - loss:  0.7845 - mse:  0.7845 - val_mse:  1.1844\n",
      "Epoch 10/10\n",
      "36s - loss:  0.7633 - mse:  0.7633 - val_mse:  1.1714\n",
      "\n",
      "\n",
      " Training Wide&Deep \n",
      "\n",
      "cuda:0\n",
      "Train on 142846 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "64s - loss:  1.7820 - mse:  1.7820 - val_mse:  1.1820\n",
      "Epoch 2/10\n",
      "62s - loss:  0.9729 - mse:  0.9729 - val_mse:  1.1567\n",
      "Epoch 3/10\n",
      "60s - loss:  0.9107 - mse:  0.9107 - val_mse:  1.1369\n",
      "Epoch 4/10\n",
      "63s - loss:  0.8812 - mse:  0.8812 - val_mse:  1.1359\n",
      "Epoch 5/10\n",
      "57s - loss:  0.8642 - mse:  0.8642 - val_mse:  1.1639\n",
      "Epoch 6/10\n",
      "63s - loss:  0.8530 - mse:  0.8530 - val_mse:  1.1674\n",
      "Epoch 7/10\n",
      "59s - loss:  0.8460 - mse:  0.8460 - val_mse:  1.1949\n",
      "Epoch 8/10\n",
      "62s - loss:  0.8385 - mse:  0.8385 - val_mse:  1.2056\n",
      "Epoch 9/10\n",
      "56s - loss:  0.8353 - mse:  0.8352 - val_mse:  1.1671\n",
      "Epoch 10/10\n",
      "62s - loss:  0.8292 - mse:  0.8292 - val_mse:  1.1733\n",
      "\n",
      "\n",
      " Training DCN \n",
      "\n",
      "cuda:0\n",
      "Train on 142846 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "58s - loss:  1.8845 - mse:  1.8845 - val_mse:  1.2351\n",
      "Epoch 2/10\n",
      "66s - loss:  0.9743 - mse:  0.9743 - val_mse:  1.2128\n",
      "Epoch 3/10\n",
      "59s - loss:  0.9111 - mse:  0.9111 - val_mse:  1.2198\n",
      "Epoch 4/10\n",
      "66s - loss:  0.8815 - mse:  0.8815 - val_mse:  1.1975\n",
      "Epoch 5/10\n",
      "61s - loss:  0.8636 - mse:  0.8636 - val_mse:  1.1775\n",
      "Epoch 6/10\n",
      "65s - loss:  0.8515 - mse:  0.8515 - val_mse:  1.1758\n",
      "Epoch 7/10\n",
      "62s - loss:  0.8431 - mse:  0.8430 - val_mse:  1.1732\n",
      "Epoch 8/10\n",
      "65s - loss:  0.8368 - mse:  0.8368 - val_mse:  1.1594\n",
      "Epoch 9/10\n",
      "57s - loss:  0.8300 - mse:  0.8300 - val_mse:  1.1945\n",
      "Epoch 10/10\n",
      "65s - loss:  0.8245 - mse:  0.8245 - val_mse:  1.1557\n",
      "\n",
      "\n",
      " Training xDeepFM \n",
      "\n",
      "cuda:0\n",
      "Train on 142846 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "62s - loss:  1.4252 - mse:  1.4252 - val_mse:  1.1386\n",
      "Epoch 2/10\n",
      "67s - loss:  0.9664 - mse:  0.9664 - val_mse:  1.1199\n",
      "Epoch 3/10\n",
      "63s - loss:  0.9048 - mse:  0.9048 - val_mse:  1.1189\n",
      "Epoch 4/10\n",
      "67s - loss:  0.8762 - mse:  0.8761 - val_mse:  1.1460\n",
      "Epoch 5/10\n",
      "63s - loss:  0.8561 - mse:  0.8561 - val_mse:  1.1260\n",
      "Epoch 6/10\n",
      "67s - loss:  0.8387 - mse:  0.8386 - val_mse:  1.1637\n",
      "Epoch 7/10\n",
      "63s - loss:  0.8214 - mse:  0.8214 - val_mse:  1.1339\n",
      "Epoch 8/10\n",
      "67s - loss:  0.8055 - mse:  0.8055 - val_mse:  1.1421\n",
      "Epoch 9/10\n",
      "63s - loss:  0.7925 - mse:  0.7924 - val_mse:  1.1625\n",
      "Epoch 10/10\n",
      "67s - loss:  0.7808 - mse:  0.7808 - val_mse:  1.1442\n",
      "\n",
      "\n",
      " Training AFM \n",
      "\n",
      "cuda:0\n",
      "Train on 142846 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "60s - loss:  6.6025 - mse:  6.6024 - val_mse:  8.6945\n",
      "Epoch 2/10\n",
      "64s - loss:  1.3844 - mse:  1.3844 - val_mse:  8.0348\n",
      "Epoch 3/10\n",
      "60s - loss:  1.2346 - mse:  1.2346 - val_mse:  7.4677\n",
      "Epoch 4/10\n",
      "63s - loss:  1.1246 - mse:  1.1245 - val_mse:  7.0471\n",
      "Epoch 5/10\n",
      "59s - loss:  1.0394 - mse:  1.0393 - val_mse:  6.7589\n",
      "Epoch 6/10\n",
      "63s - loss:  0.9804 - mse:  0.9803 - val_mse:  6.5886\n",
      "Epoch 7/10\n",
      "60s - loss:  0.9386 - mse:  0.9385 - val_mse:  6.5199\n",
      "Epoch 8/10\n",
      "64s - loss:  0.9083 - mse:  0.9082 - val_mse:  6.4941\n",
      "Epoch 9/10\n",
      "56s - loss:  0.8869 - mse:  0.8867 - val_mse:  6.5200\n",
      "Epoch 10/10\n",
      "63s - loss:  0.8708 - mse:  0.8706 - val_mse:  6.5458\n",
      "========================== 5 Fold ==============================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Training DeepFM \n",
      "\n",
      "cuda:0\n",
      "Train on 142846 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "59s - loss:  1.7836 - mse:  1.7836 - val_mse:  1.1092\n",
      "Epoch 2/10\n",
      "62s - loss:  0.9758 - mse:  0.9758 - val_mse:  1.1127\n",
      "Epoch 3/10\n",
      "59s - loss:  0.9141 - mse:  0.9141 - val_mse:  1.1169\n",
      "Epoch 4/10\n",
      "61s - loss:  0.8847 - mse:  0.8847 - val_mse:  1.1213\n",
      "Epoch 5/10\n",
      "60s - loss:  0.8677 - mse:  0.8677 - val_mse:  1.1385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "59s - loss:  0.8569 - mse:  0.8569 - val_mse:  1.1578\n",
      "Epoch 7/10\n",
      "62s - loss:  0.8498 - mse:  0.8498 - val_mse:  1.1788\n",
      "Epoch 8/10\n",
      "62s - loss:  0.8430 - mse:  0.8430 - val_mse:  1.1816\n",
      "Epoch 9/10\n",
      "63s - loss:  0.8383 - mse:  0.8382 - val_mse:  1.1772\n",
      "Epoch 10/10\n",
      "60s - loss:  0.8330 - mse:  0.8330 - val_mse:  1.1680\n",
      "\n",
      "\n",
      " Training CCPM \n",
      "\n",
      "cuda:0\n",
      "Train on 142846 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "61s - loss:  1.7178 - mse:  1.7178 - val_mse:  1.1136\n",
      "Epoch 2/10\n",
      "61s - loss:  0.9915 - mse:  0.9915 - val_mse:  1.1192\n",
      "Epoch 3/10\n",
      "64s - loss:  0.9151 - mse:  0.9151 - val_mse:  1.1198\n",
      "Epoch 4/10\n",
      "58s - loss:  0.8799 - mse:  0.8799 - val_mse:  1.1442\n",
      "Epoch 5/10\n",
      "61s - loss:  0.8568 - mse:  0.8567 - val_mse:  1.1592\n",
      "Epoch 6/10\n",
      "61s - loss:  0.8405 - mse:  0.8405 - val_mse:  1.1587\n",
      "Epoch 7/10\n",
      "65s - loss:  0.8238 - mse:  0.8237 - val_mse:  1.1886\n",
      "Epoch 8/10\n",
      "61s - loss:  0.8077 - mse:  0.8076 - val_mse:  1.2292\n",
      "Epoch 9/10\n",
      "65s - loss:  0.7892 - mse:  0.7891 - val_mse:  1.2233\n",
      "Epoch 10/10\n",
      "56s - loss:  0.7663 - mse:  0.7663 - val_mse:  1.2568\n",
      "\n",
      "\n",
      " Training IPMM \n",
      "\n",
      "cuda:0\n",
      "Train on 142846 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "36s - loss:  2.0111 - mse:  2.0111 - val_mse:  1.1443\n",
      "Epoch 2/10\n",
      "37s - loss:  0.9777 - mse:  0.9777 - val_mse:  1.1562\n",
      "Epoch 3/10\n",
      "31s - loss:  0.9113 - mse:  0.9113 - val_mse:  1.1248\n",
      "Epoch 4/10\n",
      "36s - loss:  0.8788 - mse:  0.8787 - val_mse:  1.1977\n",
      "Epoch 5/10\n",
      "37s - loss:  0.8580 - mse:  0.8580 - val_mse:  1.1660\n",
      "Epoch 6/10\n",
      "34s - loss:  0.8426 - mse:  0.8426 - val_mse:  1.1387\n",
      "Epoch 7/10\n",
      "35s - loss:  0.8264 - mse:  0.8264 - val_mse:  1.2077\n",
      "Epoch 8/10\n",
      "37s - loss:  0.8082 - mse:  0.8082 - val_mse:  1.1892\n",
      "Epoch 9/10\n",
      "36s - loss:  0.7867 - mse:  0.7866 - val_mse:  1.1668\n",
      "Epoch 10/10\n",
      "34s - loss:  0.7621 - mse:  0.7621 - val_mse:  1.2028\n",
      "\n",
      "\n",
      " Training OPNN \n",
      "\n",
      "cuda:0\n",
      "Train on 142846 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "37s - loss:  1.9257 - mse:  1.9257 - val_mse:  1.1297\n",
      "Epoch 2/10\n",
      "36s - loss:  0.9759 - mse:  0.9759 - val_mse:  1.1467\n",
      "Epoch 3/10\n",
      "35s - loss:  0.9115 - mse:  0.9115 - val_mse:  1.1372\n",
      "Epoch 4/10\n",
      "36s - loss:  0.8805 - mse:  0.8805 - val_mse:  1.1358\n",
      "Epoch 5/10\n",
      "37s - loss:  0.8602 - mse:  0.8602 - val_mse:  1.1450\n",
      "Epoch 6/10\n",
      "37s - loss:  0.8455 - mse:  0.8455 - val_mse:  1.1942\n",
      "Epoch 7/10\n",
      "33s - loss:  0.8283 - mse:  0.8283 - val_mse:  1.2211\n",
      "Epoch 8/10\n",
      "37s - loss:  0.8077 - mse:  0.8077 - val_mse:  1.1730\n",
      "Epoch 9/10\n",
      "36s - loss:  0.7845 - mse:  0.7845 - val_mse:  1.1789\n",
      "Epoch 10/10\n",
      "36s - loss:  0.7638 - mse:  0.7637 - val_mse:  1.1684\n",
      "\n",
      "\n",
      " Training Wide&Deep \n",
      "\n",
      "cuda:0\n",
      "Train on 142846 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "62s - loss:  1.7877 - mse:  1.7876 - val_mse:  1.1077\n",
      "Epoch 2/10\n",
      "63s - loss:  0.9752 - mse:  0.9752 - val_mse:  1.1118\n",
      "Epoch 3/10\n",
      "60s - loss:  0.9132 - mse:  0.9132 - val_mse:  1.1171\n",
      "Epoch 4/10\n",
      "63s - loss:  0.8835 - mse:  0.8835 - val_mse:  1.1223\n",
      "Epoch 5/10\n",
      "59s - loss:  0.8664 - mse:  0.8664 - val_mse:  1.1391\n",
      "Epoch 6/10\n",
      "63s - loss:  0.8556 - mse:  0.8556 - val_mse:  1.1575\n",
      "Epoch 7/10\n",
      "60s - loss:  0.8485 - mse:  0.8485 - val_mse:  1.1808\n",
      "Epoch 8/10\n",
      "63s - loss:  0.8419 - mse:  0.8419 - val_mse:  1.1826\n",
      "Epoch 9/10\n",
      "54s - loss:  0.8373 - mse:  0.8373 - val_mse:  1.1771\n",
      "Epoch 10/10\n",
      "63s - loss:  0.8323 - mse:  0.8323 - val_mse:  1.1713\n",
      "\n",
      "\n",
      " Training DCN \n",
      "\n",
      "cuda:0\n",
      "Train on 142846 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "60s - loss:  1.8903 - mse:  1.8903 - val_mse:  1.1431\n",
      "Epoch 2/10\n",
      "65s - loss:  0.9764 - mse:  0.9764 - val_mse:  1.1211\n",
      "Epoch 3/10\n",
      "62s - loss:  0.9132 - mse:  0.9132 - val_mse:  1.1739\n",
      "Epoch 4/10\n",
      "64s - loss:  0.8839 - mse:  0.8839 - val_mse:  1.1622\n",
      "Epoch 5/10\n",
      "62s - loss:  0.8665 - mse:  0.8664 - val_mse:  1.1347\n",
      "Epoch 6/10\n",
      "65s - loss:  0.8546 - mse:  0.8546 - val_mse:  1.1447\n",
      "Epoch 7/10\n",
      "60s - loss:  0.8453 - mse:  0.8452 - val_mse:  1.1634\n",
      "Epoch 8/10\n",
      "63s - loss:  0.8395 - mse:  0.8395 - val_mse:  1.1528\n",
      "Epoch 9/10\n",
      "60s - loss:  0.8331 - mse:  0.8331 - val_mse:  1.1497\n",
      "Epoch 10/10\n",
      "66s - loss:  0.8275 - mse:  0.8275 - val_mse:  1.1551\n",
      "\n",
      "\n",
      " Training xDeepFM \n",
      "\n",
      "cuda:0\n",
      "Train on 142846 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "62s - loss:  1.4289 - mse:  1.4289 - val_mse:  1.1168\n",
      "Epoch 2/10\n",
      "67s - loss:  0.9685 - mse:  0.9685 - val_mse:  1.1089\n",
      "Epoch 3/10\n",
      "64s - loss:  0.9073 - mse:  0.9073 - val_mse:  1.1314\n",
      "Epoch 4/10\n",
      "62s - loss:  0.8782 - mse:  0.8782 - val_mse:  1.1532\n",
      "Epoch 5/10\n",
      "59s - loss:  0.8581 - mse:  0.8580 - val_mse:  1.1382\n",
      "Epoch 6/10\n",
      "62s - loss:  0.8413 - mse:  0.8413 - val_mse:  1.1696\n",
      "Epoch 7/10\n",
      "59s - loss:  0.8251 - mse:  0.8250 - val_mse:  1.1655\n",
      "Epoch 8/10\n",
      "65s - loss:  0.8101 - mse:  0.8101 - val_mse:  1.1646\n",
      "Epoch 9/10\n",
      "56s - loss:  0.7998 - mse:  0.7998 - val_mse:  1.2027\n",
      "Epoch 10/10\n",
      "63s - loss:  0.7880 - mse:  0.7879 - val_mse:  1.1591\n",
      "\n",
      "\n",
      " Training AFM \n",
      "\n",
      "cuda:0\n",
      "Train on 142846 samples, validate on 15872 samples, 558 steps per epoch\n",
      "Epoch 1/10\n",
      "59s - loss:  6.4045 - mse:  6.4045 - val_mse:  1.2650\n",
      "Epoch 2/10\n",
      "64s - loss:  1.2308 - mse:  1.2308 - val_mse:  1.2035\n",
      "Epoch 3/10\n",
      "58s - loss:  1.1502 - mse:  1.1502 - val_mse:  1.1517\n",
      "Epoch 4/10\n",
      "65s - loss:  1.0806 - mse:  1.0805 - val_mse:  1.1218\n",
      "Epoch 5/10\n",
      "60s - loss:  1.0198 - mse:  1.0197 - val_mse:  1.1008\n",
      "Epoch 6/10\n",
      "64s - loss:  0.9635 - mse:  0.9634 - val_mse:  1.1065\n",
      "Epoch 7/10\n",
      "59s - loss:  0.9213 - mse:  0.9211 - val_mse:  1.1112\n",
      "Epoch 8/10\n",
      "60s - loss:  0.8919 - mse:  0.8917 - val_mse:  1.1225\n",
      "Epoch 9/10\n",
      "61s - loss:  0.8703 - mse:  0.8701 - val_mse:  1.1294\n",
      "Epoch 10/10\n",
      "60s - loss:  0.8542 - mse:  0.8540 - val_mse:  1.1428\n"
     ]
    }
   ],
   "source": [
    "fold_cnt = 0\n",
    "\n",
    "for train_index, test_index in kf.split(rel):\n",
    "    \n",
    "    fold_cnt += 1\n",
    "    print(\"========================== {} Fold ==============================\\n\\n\".format(fold_cnt))\n",
    "    \n",
    "    ### train\n",
    "    train_input = {name: rel[name][train_index] for name in sparse_features}\n",
    "    train_input[\"compliment\"] = _compliment[train_index]\n",
    "    train_input[\"user\"] = _user[train_index]\n",
    "    train_input[\"city\"] = _city[train_index]\n",
    "    train_input[\"category\"] = _category[train_index]\n",
    "    train_target = np.array(rel[rating][train_index])\n",
    "    \n",
    "    ### test\n",
    "    test_input = {name: rel[name][test_index] for name in sparse_features}\n",
    "    test_input[\"compliment\"] = _compliment[test_index]\n",
    "    test_input[\"user\"] = _user[test_index]\n",
    "    test_input[\"city\"] = _city[test_index]\n",
    "    test_input[\"category\"] = _category[test_index]\n",
    "    test_target = np.array(rel[rating][test_index])\n",
    "    binary_target = np.where(test_target > 3, 1, 0).reshape(1, -1)\n",
    "    \n",
    "    print(\"\\n\\n Training DeepFM \\n\")\n",
    "    ### DeepFM\n",
    "    deepfm = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    deepfm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    deepfm_hist = deepfm.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = deepfm.predict(test_input, batch_size=256)\n",
    "    deepfm_mse += mean_squared_error(test_target, pred_ans)\n",
    "    \n",
    "    pred_ans = np.where(pred_ans > 3, 1, 0).reshape((1, -1))\n",
    "    deepfm_recall += recall_score(binary_target.reshape(-1, 1), pred_ans.reshape(-1, 1))\n",
    "    deepfm_ndcg += ndcg_score(binary_target, pred_ans)\n",
    "#     print(\"DeepFM MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    print(\"\\n\\n Training CCPM \\n\")\n",
    "    ### CCPM\n",
    "    ccpm = CCPM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    ccpm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    ccpm_hist = ccpm.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = ccpm.predict(test_input, batch_size=256)\n",
    "    ccpm_mse += mean_squared_error(test_target, pred_ans)\n",
    "    \n",
    "    pred_ans = np.where(pred_ans > 3, 1, 0).reshape((1, -1))\n",
    "    ccpm_recall += recall_score(binary_target.reshape(-1, 1), pred_ans.reshape(-1, 1))\n",
    "    ccpm_ndcg += ndcg_score(binary_target, pred_ans)\n",
    "#     print(\"CCPM MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    print(\"\\n\\n Training IPMM \\n\")\n",
    "    ### IPNN\n",
    "    ipnn = PNN(dnn_feature_columns, task='regression', device=device, use_inner=True, use_outter=False)\n",
    "    ipnn.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    ipnn_hist = ipnn.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = ipnn.predict(test_input, batch_size=256)\n",
    "    ipnn_mse += mean_squared_error(test_target, pred_ans)\n",
    "    \n",
    "    pred_ans = np.where(pred_ans > 3, 1, 0).reshape((1, -1))\n",
    "    ipnn_recall += recall_score(binary_target.reshape(-1, 1), pred_ans.reshape(-1, 1))\n",
    "    ipnn_ndcg += ndcg_score(binary_target, pred_ans)\n",
    "#     print(\"IPNN MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    print(\"\\n\\n Training OPNN \\n\")\n",
    "    ### OPNN\n",
    "    opnn = PNN(dnn_feature_columns, task='regression', device=device, use_inner=False, use_outter=True)\n",
    "    opnn.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    opnn_hist = opnn.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = opnn.predict(test_input, batch_size=256)\n",
    "    opnn_mse += mean_squared_error(test_target, pred_ans)\n",
    "    \n",
    "    pred_ans = np.where(pred_ans > 3, 1, 0).reshape((1, -1))\n",
    "    opnn_recall += recall_score(binary_target.reshape(-1, 1), pred_ans.reshape(-1, 1))\n",
    "    opnn_ndcg += ndcg_score(binary_target, pred_ans)\n",
    "#     print(\"OPNN MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    print(\"\\n\\n Training Wide&Deep \\n\")\n",
    "    ### Wide & Deep\n",
    "    wdl = WDL(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    wdl.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    wdl_hist = wdl.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = wdl.predict(test_input, batch_size=256)\n",
    "    wdl_mse += mean_squared_error(test_target, pred_ans)\n",
    "    \n",
    "    pred_ans = np.where(pred_ans > 3, 1, 0).reshape((1, -1))\n",
    "    wdl_recall += recall_score(binary_target.reshape(-1, 1), pred_ans.reshape(-1, 1))\n",
    "    wdl_ndcg += ndcg_score(binary_target, pred_ans)\n",
    "#     print(\"WDL MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    print(\"\\n\\n Training DCN \\n\")\n",
    "    ### DCN\n",
    "    dcn = DCN(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    dcn.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    dcn_hist = dcn.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = dcn.predict(test_input, batch_size=256)\n",
    "    dcn_mse += mean_squared_error(test_target, pred_ans)\n",
    "    \n",
    "    pred_ans = np.where(pred_ans > 3, 1, 0).reshape((1, -1))\n",
    "    dcn_recall += recall_score(binary_target.reshape(-1, 1), pred_ans.reshape(-1, 1))\n",
    "    dcn_ndcg += ndcg_score(binary_target, pred_ans)\n",
    "#     print(\"DCN MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\n Training xDeepFM \\n\")\n",
    "    ### xDeepFM\n",
    "    xdeepfm = xDeepFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    xdeepfm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    xdeepfm_hist = xdeepfm.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = xdeepfm.predict(test_input, batch_size=256)\n",
    "    xdeepfm_mse += mean_squared_error(test_target, pred_ans)\n",
    "    \n",
    "    pred_ans = np.where(pred_ans > 3, 1, 0).reshape((1, -1))\n",
    "    xdeepfm_recall += recall_score(binary_target.reshape(-1, 1), pred_ans.reshape(-1, 1))\n",
    "    xdeepfm_ndcg += ndcg_score(binary_target, pred_ans)\n",
    "#     print(\"xDeepFM MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\n Training AFM \\n\")\n",
    "    ### AFM\n",
    "    afm = AFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    afm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    afm_hist = afm.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = afm.predict(test_input, batch_size=256)\n",
    "    afm_mse += mean_squared_error(test_target, pred_ans)\n",
    "    \n",
    "    pred_ans = np.where(pred_ans > 3, 1, 0).reshape((1, -1))\n",
    "    afm_recall += recall_score(binary_target.reshape(-1, 1), pred_ans.reshape(-1, 1))\n",
    "    afm_ndcg += ndcg_score(binary_target, pred_ans)\n",
    "#     print(\"AFM MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"\\n Training DIN \\n\")\n",
    "    ### DIN\n",
    "    din = DIN(dnn_feature_columns, [], task='regression', device=device)\n",
    "    din.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    din_hist = din.fit(train_input, train_target, batch_size=256, epochs=10, verbose=2, validation_split=0.1)\n",
    "    pred_ans = din.predict(test_input, batch_size=256)\n",
    "    din_mse += mean_squared_error(test_target, pred_ans)\n",
    "    print(\"DIN MSE\", round(mean_squared_error(test_target, pred_ans), 4))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-disaster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "moral-layer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.181351914169992"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepfm_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "british-genius",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.247156750644464"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccpm_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "christian-mediterranean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2237504230197114"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipnn_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "parliamentary-glass",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2032459417340755"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opnn_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "welcome-progressive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1819719420137116"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdl_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "stopped-actress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1787456364447428"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcn_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "advanced-currency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2258726829876367"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdeepfm_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "alleged-switzerland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0971227548817133"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afm_mse /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-lightweight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "comparable-migration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9383477244528511"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepfm_recall /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "forward-athletics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8832626772570575"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccpm_recall /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "independent-japan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9187351093512783"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipnn_recall /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "vanilla-madonna",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9257387712511094"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opnn_recall /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "opposite-preliminary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9372927532789355"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdl_recall /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "complimentary-correlation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9400705396558118"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcn_recall /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "sufficient-chambers",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9404136288678112"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdeepfm_recall /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "animated-exclusive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8554051007429688"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afm_recall /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-satellite",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "rough-piece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.962206180439169"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepfm_ndcg / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "vital-occasions",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9638919699693549"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccpm_ndcg /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "objective-signal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9628357715520451"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipnn_ndcg /5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "focal-howard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9625913045520829"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opnn_ndcg / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cubic-senate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9622612026110966"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdl_ndcg / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "rising-prophet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9620958874825464"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcn_ndcg / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eastern-plenty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9617192195249606"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdeepfm_ndcg / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "super-estonia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9602507389334376"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afm_ndcg / 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-revelation",
   "metadata": {},
   "source": [
    "# Test single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "stable-selling",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p = os.path.join(root, \"train.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "laughing-result",
   "metadata": {},
   "outputs": [],
   "source": [
    "group, group_i, group_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"user_group.dat\"), user_cnt=13024)\n",
    "location, location_i, location_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"user_location.dat\"), user_cnt=13024)\n",
    "user, user_i, user_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"user_user.dat\"), user_cnt=13024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "likely-venture",
   "metadata": {},
   "outputs": [],
   "source": [
    "year, year_i, year_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"book_year.dat\"), user_cnt=22347)\n",
    "publisher, publisher_i, publisher_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"book_publisher.dat\"), user_cnt=22347)\n",
    "author, author_i, author_m = utils.m2m_to_list(os.path.join(os.getcwd(), \"DoubanBook\", \"book_author.dat\"), user_cnt=22347)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "statistical-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = [\"cols_0\", \"cols_1\"] # user_id, movie_id\n",
    "rating = \"cols_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "disabled-virgin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cols_0</th>\n",
       "      <th>cols_1</th>\n",
       "      <th>cols_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9608</td>\n",
       "      <td>791</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11607</td>\n",
       "      <td>2664</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3630</td>\n",
       "      <td>712</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12070</td>\n",
       "      <td>5046</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3967</td>\n",
       "      <td>202</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cols_0  cols_1  cols_2\n",
       "0    9608     791       3\n",
       "1   11607    2664       4\n",
       "2    3630     712       4\n",
       "3   12070    5046       5\n",
       "4    3967     202       5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = utils.read_file(train_p)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "consecutive-latin",
   "metadata": {},
   "outputs": [],
   "source": [
    "_group = group[rel.cols_0 -1]\n",
    "_location = location[rel.cols_0 -1]\n",
    "_user = user[rel.cols_0 -1]\n",
    "\n",
    "_year = year[rel.cols_1 -1]\n",
    "_publisher = publisher[rel.cols_1 -1]\n",
    "_author = author[rel.cols_1 -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "scheduled-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Label Encoding for sparse features,and process sequence features\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    train[feat] = lbe.fit_transform(train[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "detailed-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, train[feat].nunique(), embedding_dim=4) for feat in sparse_features]\n",
    "\n",
    "varlen_feature_columns = [\n",
    "    VarLenSparseFeat(SparseFeat('group', vocabulary_size=group_i + 1, embedding_dim=4), maxlen=group_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('location', vocabulary_size=location_i + 1, embedding_dim=4), maxlen=location_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('user', vocabulary_size=13024 + 1, embedding_dim=4), maxlen=user_m, combiner='mean'),\n",
    "    \n",
    "    VarLenSparseFeat(SparseFeat('year', vocabulary_size=year_i + 1, embedding_dim=4), maxlen=year_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('publisher', vocabulary_size=publisher_i + 1, embedding_dim=4), maxlen=publisher_m, combiner='mean'),\n",
    "    VarLenSparseFeat(SparseFeat('author', vocabulary_size=author_i + 1, embedding_dim=4), maxlen=author_m, combiner='mean')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "after-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "logical-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.generate input data for model\n",
    "model_input = {name: train[name] for name in sparse_features}  #\n",
    "model_input[\"group\"] = _group\n",
    "model_input[\"location\"] = _location\n",
    "model_input[\"user\"] = _user\n",
    "model_input[\"year\"] = _year\n",
    "model_input[\"publisher\"] = _publisher\n",
    "model_input[\"author\"] = _author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-exception",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-drill",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-public",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "female-maple",
   "metadata": {},
   "source": [
    "### DeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "wireless-boring",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import DeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "unexpected-stack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "228s - loss:  0.7947 - mse:  0.7945 - val_mse:  0.5051\n",
      "Epoch 2/10\n",
      "230s - loss:  0.4835 - mse:  0.4835 - val_mse:  0.5019\n",
      "Epoch 3/10\n",
      "228s - loss:  0.4719 - mse:  0.4718 - val_mse:  0.4993\n",
      "Epoch 4/10\n",
      "226s - loss:  0.4649 - mse:  0.4649 - val_mse:  0.5034\n",
      "Epoch 5/10\n",
      "232s - loss:  0.4600 - mse:  0.4599 - val_mse:  0.4983\n",
      "Epoch 6/10\n",
      "226s - loss:  0.4546 - mse:  0.4545 - val_mse:  0.5073\n",
      "Epoch 7/10\n",
      "228s - loss:  0.4494 - mse:  0.4492 - val_mse:  0.5018\n",
      "Epoch 8/10\n",
      "229s - loss:  0.4428 - mse:  0.4426 - val_mse:  0.5088\n",
      "Epoch 9/10\n",
      "228s - loss:  0.4335 - mse:  0.4333 - val_mse:  0.4998\n",
      "Epoch 10/10\n",
      "229s - loss:  0.4216 - mse:  0.4213 - val_mse:  0.5087\n"
     ]
    }
   ],
   "source": [
    "deepfm = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "\n",
    "deepfm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = deepfm.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-relation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "superb-greeting",
   "metadata": {},
   "source": [
    "### CCPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "grave-companion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import CCPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "static-martin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "228s - loss:  0.7249 - mse:  0.7248 - val_mse:  0.5026\n",
      "Epoch 2/10\n",
      "229s - loss:  0.4766 - mse:  0.4765 - val_mse:  0.4946\n",
      "Epoch 3/10\n",
      "224s - loss:  0.4588 - mse:  0.4588 - val_mse:  0.4915\n",
      "Epoch 4/10\n",
      "231s - loss:  0.4455 - mse:  0.4456 - val_mse:  0.4947\n",
      "Epoch 5/10\n",
      "237s - loss:  0.4302 - mse:  0.4300 - val_mse:  0.4993\n",
      "Epoch 6/10\n",
      "232s - loss:  0.4124 - mse:  0.4122 - val_mse:  0.5155\n",
      "Epoch 7/10\n",
      "207s - loss:  0.3938 - mse:  0.3936 - val_mse:  0.5194\n",
      "Epoch 8/10\n",
      "210s - loss:  0.3771 - mse:  0.3770 - val_mse:  0.5336\n",
      "Epoch 9/10\n",
      "214s - loss:  0.3616 - mse:  0.3613 - val_mse:  0.5405\n",
      "Epoch 10/10\n",
      "213s - loss:  0.3485 - mse:  0.3483 - val_mse:  0.5592\n"
     ]
    }
   ],
   "source": [
    "ccpm = CCPM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "\n",
    "ccpm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = ccpm.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-masters",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "renewable-forwarding",
   "metadata": {},
   "source": [
    "### PNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dated-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import PNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-accused",
   "metadata": {},
   "source": [
    "#### IPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "little-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipnn = PNN(dnn_feature_columns, task='regression', device=device, use_inner=True, use_outter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "celtic-qualification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "125s - loss:  0.9133 - mse:  0.9131 - val_mse:  0.5042\n",
      "Epoch 2/10\n",
      "125s - loss:  0.4784 - mse:  0.4784 - val_mse:  0.4927\n",
      "Epoch 3/10\n",
      "123s - loss:  0.4554 - mse:  0.4554 - val_mse:  0.4902\n",
      "Epoch 4/10\n",
      "124s - loss:  0.4353 - mse:  0.4353 - val_mse:  0.4972\n",
      "Epoch 5/10\n",
      "128s - loss:  0.4149 - mse:  0.4150 - val_mse:  0.5067\n",
      "Epoch 6/10\n",
      "128s - loss:  0.3920 - mse:  0.3918 - val_mse:  0.5238\n",
      "Epoch 7/10\n",
      "128s - loss:  0.3712 - mse:  0.3711 - val_mse:  0.5402\n",
      "Epoch 8/10\n",
      "136s - loss:  0.3534 - mse:  0.3532 - val_mse:  0.5562\n",
      "Epoch 9/10\n",
      "141s - loss:  0.3391 - mse:  0.3390 - val_mse:  0.5750\n",
      "Epoch 10/10\n",
      "136s - loss:  0.3282 - mse:  0.3280 - val_mse:  0.5825\n"
     ]
    }
   ],
   "source": [
    "ipnn.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = ipnn.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-swing",
   "metadata": {},
   "source": [
    "#### OPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abstract-makeup",
   "metadata": {},
   "outputs": [],
   "source": [
    "opnn = PNN(dnn_feature_columns, task='regression', device=device, use_inner=False, use_outter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "collaborative-medicine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "142s - loss:  0.8448 - mse:  0.8446 - val_mse:  0.5039\n",
      "Epoch 2/10\n",
      "143s - loss:  0.4802 - mse:  0.4802 - val_mse:  0.4969\n",
      "Epoch 3/10\n",
      "141s - loss:  0.4659 - mse:  0.4658 - val_mse:  0.4955\n",
      "Epoch 4/10\n",
      "149s - loss:  0.4523 - mse:  0.4523 - val_mse:  0.4966\n",
      "Epoch 5/10\n",
      "145s - loss:  0.4381 - mse:  0.4381 - val_mse:  0.4894\n",
      "Epoch 6/10\n",
      "148s - loss:  0.4243 - mse:  0.4242 - val_mse:  0.4984\n",
      "Epoch 7/10\n",
      "149s - loss:  0.4031 - mse:  0.4031 - val_mse:  0.5068\n",
      "Epoch 8/10\n",
      "148s - loss:  0.3811 - mse:  0.3809 - val_mse:  0.5243\n",
      "Epoch 9/10\n",
      "149s - loss:  0.3619 - mse:  0.3618 - val_mse:  0.5375\n",
      "Epoch 10/10\n",
      "150s - loss:  0.3465 - mse:  0.3463 - val_mse:  0.5589\n"
     ]
    }
   ],
   "source": [
    "opnn.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = opnn.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-airplane",
   "metadata": {},
   "source": [
    "#### PIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-bridal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-ecuador",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "relative-sustainability",
   "metadata": {},
   "source": [
    "### Wide & Deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "consistent-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import WDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "protected-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdl = WDL(linear_feature_columns, dnn_feature_columns, task='regression', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "female-tokyo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "246s - loss:  0.7961 - mse:  0.7960 - val_mse:  0.5040\n",
      "Epoch 2/10\n",
      "240s - loss:  0.4823 - mse:  0.4823 - val_mse:  0.5012\n",
      "Epoch 3/10\n",
      "246s - loss:  0.4711 - mse:  0.4710 - val_mse:  0.4985\n",
      "Epoch 4/10\n",
      "250s - loss:  0.4652 - mse:  0.4651 - val_mse:  0.5034\n",
      "Epoch 5/10\n",
      "244s - loss:  0.4620 - mse:  0.4618 - val_mse:  0.4979\n",
      "Epoch 6/10\n",
      "246s - loss:  0.4590 - mse:  0.4589 - val_mse:  0.5057\n",
      "Epoch 7/10\n",
      "227s - loss:  0.4565 - mse:  0.4564 - val_mse:  0.5003\n",
      "Epoch 8/10\n",
      "216s - loss:  0.4539 - mse:  0.4538 - val_mse:  0.5046\n",
      "Epoch 9/10\n",
      "224s - loss:  0.4500 - mse:  0.4499 - val_mse:  0.4941\n",
      "Epoch 10/10\n",
      "246s - loss:  0.4450 - mse:  0.4449 - val_mse:  0.4990\n"
     ]
    }
   ],
   "source": [
    "wdl.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = wdl.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-lounge",
   "metadata": {},
   "source": [
    "### Deep Cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "parallel-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import DCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "thorough-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcn = DCN(linear_feature_columns, dnn_feature_columns, task='regression', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "crucial-establishment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "258s - loss:  0.8089 - mse:  0.8087 - val_mse:  0.5125\n",
      "Epoch 2/10\n",
      "261s - loss:  0.4816 - mse:  0.4817 - val_mse:  0.4968\n",
      "Epoch 3/10\n",
      "261s - loss:  0.4698 - mse:  0.4698 - val_mse:  0.4977\n",
      "Epoch 4/10\n",
      "257s - loss:  0.4629 - mse:  0.4628 - val_mse:  0.4945\n",
      "Epoch 5/10\n",
      "255s - loss:  0.4569 - mse:  0.4567 - val_mse:  0.4912\n",
      "Epoch 6/10\n",
      "258s - loss:  0.4486 - mse:  0.4486 - val_mse:  0.4922\n",
      "Epoch 7/10\n",
      "252s - loss:  0.4416 - mse:  0.4415 - val_mse:  0.4916\n",
      "Epoch 8/10\n",
      "251s - loss:  0.4345 - mse:  0.4343 - val_mse:  0.4934\n",
      "Epoch 9/10\n",
      "256s - loss:  0.4284 - mse:  0.4283 - val_mse:  0.4968\n",
      "Epoch 10/10\n",
      "263s - loss:  0.4220 - mse:  0.4217 - val_mse:  0.5029\n"
     ]
    }
   ],
   "source": [
    "dcn.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = dcn.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-atlantic",
   "metadata": {},
   "source": [
    "### xDeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "electronic-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import xDeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "expanded-concrete",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdeepfm = xDeepFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "affecting-compiler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "267s - loss:  0.6677 - mse:  0.6676 - val_mse:  0.5041\n",
      "Epoch 2/10\n",
      "262s - loss:  0.4801 - mse:  0.4800 - val_mse:  0.5075\n",
      "Epoch 3/10\n",
      "260s - loss:  0.4634 - mse:  0.4634 - val_mse:  0.4897\n",
      "Epoch 4/10\n",
      "259s - loss:  0.4514 - mse:  0.4513 - val_mse:  0.4937\n",
      "Epoch 5/10\n",
      "266s - loss:  0.4428 - mse:  0.4428 - val_mse:  0.4951\n",
      "Epoch 6/10\n",
      "261s - loss:  0.4348 - mse:  0.4347 - val_mse:  0.4953\n",
      "Epoch 7/10\n",
      "262s - loss:  0.4266 - mse:  0.4264 - val_mse:  0.4972\n",
      "Epoch 8/10\n",
      "253s - loss:  0.4124 - mse:  0.4123 - val_mse:  0.5075\n",
      "Epoch 9/10\n",
      "265s - loss:  0.3919 - mse:  0.3917 - val_mse:  0.5153\n",
      "Epoch 10/10\n",
      "268s - loss:  0.3690 - mse:  0.3688 - val_mse:  0.5356\n"
     ]
    }
   ],
   "source": [
    "xdeepfm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = xdeepfm.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-collins",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "seven-doubt",
   "metadata": {},
   "source": [
    "### Attentional Factorization Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "silver-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import AFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fallen-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "afm = AFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "personalized-logistics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "255s - loss:  2.5075 - mse:  2.5064 - val_mse:  0.6100\n",
      "Epoch 2/10\n",
      "245s - loss:  0.5585 - mse:  0.5580 - val_mse:  0.5407\n",
      "Epoch 3/10\n",
      "250s - loss:  0.5036 - mse:  0.5033 - val_mse:  0.5176\n",
      "Epoch 4/10\n",
      "248s - loss:  0.4790 - mse:  0.4785 - val_mse:  0.5092\n",
      "Epoch 5/10\n",
      "255s - loss:  0.4663 - mse:  0.4658 - val_mse:  0.5048\n",
      "Epoch 6/10\n",
      "251s - loss:  0.4587 - mse:  0.4581 - val_mse:  0.5022\n",
      "Epoch 7/10\n",
      "253s - loss:  0.4536 - mse:  0.4529 - val_mse:  0.5014\n",
      "Epoch 8/10\n",
      "251s - loss:  0.4497 - mse:  0.4490 - val_mse:  0.5012\n",
      "Epoch 9/10\n",
      "256s - loss:  0.4468 - mse:  0.4461 - val_mse:  0.5005\n",
      "Epoch 10/10\n",
      "254s - loss:  0.4443 - mse:  0.4436 - val_mse:  0.5011\n"
     ]
    }
   ],
   "source": [
    "afm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = afm.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-softball",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "handled-blair",
   "metadata": {},
   "source": [
    "### Neural Factorization Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "searching-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import NFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "average-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfm = NFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "terminal-control",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n",
      "Epoch 1/10\n",
      "247s - loss:  0.7533 - mse:  0.7532 - val_mse:  0.5090\n",
      "Epoch 2/10\n",
      "234s - loss:  0.4786 - mse:  0.4785 - val_mse:  0.4960\n",
      "Epoch 3/10\n",
      "246s - loss:  0.4566 - mse:  0.4565 - val_mse:  0.4959\n",
      "Epoch 4/10\n",
      "246s - loss:  0.4432 - mse:  0.4432 - val_mse:  0.4988\n",
      "Epoch 5/10\n",
      "242s - loss:  0.4338 - mse:  0.4337 - val_mse:  0.5024\n",
      "Epoch 6/10\n",
      "248s - loss:  0.4259 - mse:  0.4258 - val_mse:  0.5026\n",
      "Epoch 7/10\n",
      "238s - loss:  0.4191 - mse:  0.4189 - val_mse:  0.5034\n",
      "Epoch 8/10\n",
      "248s - loss:  0.4125 - mse:  0.4123 - val_mse:  0.5059\n",
      "Epoch 9/10\n",
      "236s - loss:  0.4040 - mse:  0.4037 - val_mse:  0.5117\n",
      "Epoch 10/10\n",
      "230s - loss:  0.3946 - mse:  0.3943 - val_mse:  0.5179\n"
     ]
    }
   ],
   "source": [
    "nfm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = nfm.fit(model_input, train_df[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-instruction",
   "metadata": {},
   "source": [
    "### Deep Interest Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "appreciated-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.models import DIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "chronic-peripheral",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_feature_list = np.array([\"cols_0\", \"cols_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "photographic-edmonton",
   "metadata": {},
   "outputs": [],
   "source": [
    "din = DIN(dnn_feature_columns, behavior_feature_list, task='regression', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "verbal-password",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 456227 samples, validate on 114057 samples, 1783 steps per epoch\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'VarLenSparseFeat' object has no attribute 'use_hash'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-c5fe815ca6cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrating\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/deepctr_torch/models/basemodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, initial_epoch, validation_split, validation_data, shuffle, callbacks)\u001b[0m\n\u001b[1;32m    239\u001b[0m                         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/deepctr_torch/models/din.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         sequence_embed_dict = varlen_embedding_lookup(X, self.embedding_dict, self.feature_index,\n\u001b[0;32m---> 95\u001b[0;31m                                                       self.sparse_varlen_feature_columns)\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         sequence_embed_list = get_varlen_pooling_list(sequence_embed_dict, X, self.feature_index,\n",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/deepctr_torch/inputs.py\u001b[0m in \u001b[0;36mvarlen_embedding_lookup\u001b[0;34m(X, embedding_dict, sequence_input_dict, varlen_sparse_feature_columns)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mfeature_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0membedding_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_hash\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m             \u001b[0;31m# lookup_idx = Hash(fc.vocabulary_size, mask_zero=True)(sequence_input_dict[feature_name])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;31m# TODO: add hash function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VarLenSparseFeat' object has no attribute 'use_hash'"
     ]
    }
   ],
   "source": [
    "din.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = din.fit(model_input, train[rating].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-victim",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
